# KoGPT2-Consult-Chatbot
## KoGPT2를 이용한 심리상담 AI 챗봇
KoGPT2 상담 챗봇 Training &amp; Chatting code &amp; Model file

### [데이터 수집 및 전처리 방법]
1. 상담 대화 데이터셋은 AI hub에서 제공하는 “웰니스 대화 스크립트 데이터셋”을 가공하였다.
이것은 강남 세브란스에서 전달받은 상담 데이터를 기준으로 정신건강 상담 주제의 대화 의도 분류별 사용자-챗봇 대화 스크립트를 구축한 데이터셋이다. KoGPT2 상담 챗봇 개발을 위해 실제 환자의 데이터를 기반으로 작성된 고품질의 대화 스크립트가 필요했다. 데이터 구조의 칼럼 이름은 ‘사용자 발화’, ‘챗봇 발화’, ‘감정(구분)’로 되어있었는데, 우선 이를 각각 ‘user’, ‘system’, ‘sentiment’로 변경했다. 그리고 사용자 발화에 따른 챗봇 응답이 1:1 쌍을 이루도록 각 발화들을 대화 차례에 맞추어 재구성하였다. ‘sentiment’는 감정 단어(불안, 무기력 등)를 그대로 사용했지만, 대화 차례에 따른 사용자 발화 중 ‘응’, ‘아니’와 같은 답변을 ‘긍정답변’과 ‘부정답변’으로 다시 라벨링하였다.
(https://aihub.or.kr/aihubdata/data/view.do?currMenu=120&topMenu=100&aihubDataSe=extrldata&dataSetSn=267)

3. 전문 상담 외의 더욱 자연스러운 대화를 위해 “Chit-chat datasets” 일상 대화 데이터셋도 함께 사용하였다.
이것은 다음카페 ‘사랑보다 아름다운 실연’에서 자주 나오는 이야기들을 참고하여 구축한 일상 대화 데이터셋이다. 데이터 구조는 ‘Q’(사용자 발화), ‘A’(챗봇 발화), ‘label’(감정)으로 구성되어 있으며, 감정은 0(일상다반사), 1(이별, 부정), 2(사랑, 긍정)와 같은 숫자로 표현되어 있었다. 이 데이터셋도 웰니스와 마찬가지로 ‘user’, ‘system’, ‘sentiment’로 칼럼 이름을 변경하였다. 그리고 ‘sentiment’데이터를 숫자 대신 한글 언어(‘일상’, ‘사랑’, ‘이별’)로 다시 라벨링하였다.
(https://github.com/songys/Chatbot_data)

### [Fine-tuning 학습을 통한 자체 챗봇 모델 개발]
위 2개의 데이터셋을 user-system-sentiment 구조로 통일하여 하나의 데이터셋으로 합쳤다. 그랬더니 총 48만 행(row)의 데이터를 얻었다. 이렇게 합친 데이터셋을 KoGPT2 모델에 40 epochs 이상 Colab의 GPU를 활용하여 Fine-tuning 시켜 자체 학습한 상담 챗봇 모델을 만들었다. 그 결과, 자체 학습한 KoGPT2 챗봇 모델은 사용자 발화 내용을 이해하고 문맥에 맞는 답변을 생성하여 자연스러운 대화가 가능하다.

### [답변 생성 알고리즘]
<usr> 사용자 발화, <sent> 감정 정보, <sys> 챗봇답변이 주어졌을 때 모델이 sentiment 정보를 생성한 후 그 감정 정보에 해당하는 적절한 답변을 생성한다. 만약 모델이 사용자의 현재 발화 감정 sentiment를 <긍정답변> 혹은 <부정답변>로 예측하면, 현재 발화와 이전 대화 history와 합쳐 다시 input을 생성하여 챗봇 모델에 입력한다. 따라서 대화 맥락을 유지한 채 자연스러운 답변을 생성하며 연속적인 대화 상담을 수행한다.

### [AI 챗봇 모델 개발 발전 과정]

#### ① KoBERT : 
[KETI]의 웰니스 대화 스크립트 데이터셋을 파인튜닝한 KoBERT 모델이다. 사용자의 발화를 심리상담 주제별로 분류하고 해당 심리상담 주제로 라벨링된 답변 3~4개 중 1개를 무작위로 선택한다. 선택된 답변을 챗봇의 답변으로 출력한다. 이러한 모델은 심리 상담에 대한 답변을 높은 완성도로 생성할 수 있다는 장점이 있지만 정해진 답변만 할 수 있어 인위적인 답변으로 이어진다는 단점이 있다. 또한, 단발성 대화밖에 지원하지 않으며 일상 대화가 불가능하다. 이러한 단점을 보완하고자 생성모델인 KoGPT2로 AI 모델을 변경하게 되었다.
<br>
#### ② KoGPT2 (Single-Turn) : 
[AI HUB]의 감성대화 말뭉치 데이터셋을 파인튜닝한 싱글턴 KoGPT2 모델이다. 이 모델은 분류 모델에 비해 적절한 답변을 생성한다. 하지만, 챗봇이 이전 대화를 기억하지 못해 연속된 대화가 불가능하다는 점에서 Multi-Turn을 지원하는 KoGPT2 모델로 발전시켰다.
<br>
#### ③ KoGPT2 (Multi-Turn) : 
[AI HUB]의 감성대화 말뭉치 데이터셋을 파인튜닝한 멀티턴 KoGPT2 모델이다. 사용자의 첫 발화와 이어서 나타나는 최대 3턴 이내의 최근 대화를 기억하여 답변을 생성한다. 이 모델은 이전 대화의 문맥을 이해하고 유지할 수 있어, 대화를 연속적으로 진행할 수 있다. Fine-tuning 학습 방식은 사용자의 첫 발화 뒤에 감정 토큰(<sent>)으로 감정 대분류와 감정 소분류를 붙이고 그에 대한 시스템 답변(<sys>)과 그 뒤에 이어지는 사용자 발화(<usr>)를 차례로 이어 붙여 하나의 string으로 만든다. 대화문에 감정 라벨링, 화자별 토큰을 붙여 학습시킨 결과, 첫 학습 시작할 때의 Loss가 2.045에서 10 epoch 이상 학습 후, 0.4040까지 큰 폭으로 감소했다.
<br><br>
그러나 생각보다 답변 생성 능력이 좋지 않았다. 어떤 경우에는 사용자 발화를 잘 이해하고 적절한 답변을 생성하지만, 어떤 경우는 발화 의도를 이해하지 못해 전혀 상관없는 답변을 내놓았다. 그리고 대화를 시작한 지 얼마 지나지 않고 대화 주제에서 벗어나 엉뚱한 대답을 할 때도 있었다. 이러한 문제가 발생한 이유를 분석해보니, 대표적으로 ‘적은 양의 데이터셋’과 ‘파인튜닝 알고리즘’의 문제였다. 첫째로, 감성대화 말뭉치 데이터셋의 양이 상대적으로 적어서 epoch를 10번 이상 학습시키면 쉽게 과적합 현상이 발생했다. 그래서 모델은 제한된 데이터로만 학습되어 실제 대화에서의 다양한 상황에 대응하기 어려웠다. 둘째로, 파인튜닝 알고리즘 자체의 한계도 문제였다. 사용자 발화와 챗봇 답변 쌍의 여러 개를 차례대로 이어 붙여 파인튜닝한 방식이 어떤 적절한 대답을 생성해야 하는지 학습이 제대로 이루어지지 않았다. 그래서 모델이 대화 문맥을 잘 파악하지 못하고 엉뚱한 답변을 생성한 상황이 발생한 것이다. 이에 대해 더 많고 질 좋은 데이터셋 수집과 파인튜닝 전략의 연구가 필요했다.
<br>
#### ④ KoGPT2 (Multi-Turn, More Datasets, Change chatbot response algorithm) :
이번에는 더 많고 질 좋은 데이터셋을 구하고, 싱글턴과 멀티턴의 알고리즘 방식 모두를 채택하여 모델을 다시 파인튜닝했다. 먼저 ‘감성대화 말뭉치 데이터셋’ 대신 정신건강 상담‘웰니스 대화 스크립트 데이터셋’과 일상 대화 ‘Chit-chat 데이터셋’을 user-system-sentiment 구조로 가공하여 하나로 합쳤다. 새롭게 얻은 데이터셋의 양은 전에 이용한 감성대화 데이터셋 양의 8배 더 많다. 그리고 하나의 대화 주제의 사용자와 챗봇 대화 스크립트를 이어 붙여서 통째로 학습시키는 대신 user 발화, system 답변, sentiment 정보를 1:1:1 쌍으로 학습시켰다. 그랬더니 챗봇이 사용자 발화에 해당하는 감정(sentiment)을 예측하여 그 감정 정보에 해당하는 적절한 답변을 더 잘 생성했다. 만약 모델이 사용자의 현재 발화 감정 sentiment를 <긍정답변> 혹은 <부정답변>로 예측하면, 현재 발화와 이전 대화 history와 합쳐 다시 input을 생성하여 챗봇 모델에 입력하여 답변을 생성하도록 변경하였다. 이와 같이 데이터셋의 질과 양을 향상시키고, 답변 생성 알고리즘을 변경했더니 예전보다 사용자 발화 내용을 잘 이해하여 전보다 더 자연스러운 답변을 생성했다. 그리고 과거 대화 기록을 갱신 및 저장해서 대화 문맥을 고려하여 대화 주제 안에서 전보다 일관적이고 연속적인 대화가 가능하다.
