{"cells":[{"cell_type":"markdown","metadata":{"id":"XrcsXrWOI9xX"},"source":["# Drive mount"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21766,"status":"ok","timestamp":1691215651561,"user":{"displayName":"스쿨로그2","userId":"11597875074891862972"},"user_tz":-540},"id":"WWVHdfYkI8S_","outputId":"dec75c1b-7f48-4a56-b8e3-2304ad5905fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"rqhJYEIkIp7_"},"source":["# 사전 작업"]},{"cell_type":"markdown","metadata":{"id":"oNTH14FoIz-V"},"source":["GPU 사용 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1688471201810,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"pP0NCcL4FFGP","outputId":"4aa0ef38-745a-4d75-d1ef-64c0ab7fc6aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Jul  4 11:46:40 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"HLGq9lM5lQy6"},"source":["라이브러리 설치 requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfSzbRSgigBv"},"outputs":[],"source":["!pip install tokenizers\n","# !pip install transformers\n","!pip install transformers==4.23.1\n","!pip install pandas numpy\n","!pip install torch\n","# !pip install torch==1.8.1\n","!pip install pytorch\n","# !pip install pytorch_lightning\n","!pip install pytorch_lightning==1.2.10\n","\n","# !pip install streamlit==1.9.0\n","# !LC_ALL=en_US.UTF-8 pip install -q streamlit\n","# !pip install streamlit-chat==0.0.2.1\n","# !pip install gdown\n","\n","# --------------------------------------------------\n","# !pip install pytorch-lightning==1.2.10\n","# !pip install torchtext==0.9.0\n","\n","# !pip show pytorch-lightning\n","# !pip install torchtext\n","\n","# !pip install protobuf==3.20.1\n","# !pip install streamlit==1.9.0\n","# !pip install streamlit-chat==0.0.2.1\n","# !pip install gdown\n","# !pip install elasticsearch==7.14.1"]},{"cell_type":"markdown","metadata":{"id":"jFAQGyULqvsx"},"source":["# **Wellness + Chitchat 챗봇 Training**"]},{"cell_type":"markdown","metadata":{"id":"RghJc6cJzxqb"},"source":["# 0) haven-jeon chatbot 깃허브 클론, 학습/실행"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S11crVhFrt8H"},"outputs":[],"source":["# Haven-jeon Simple chit-chat chatbot\n","!pip install pandas\n","!pip install pytorch_lightning==1.2.10\n","!pip install torch\n","!pip install transformers==4.5.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13697,"status":"ok","timestamp":1688789312032,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"1vbh3mvNz29n","outputId":"8476544e-9189-4a78-f998-22e4f08a0068"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'KoGPT2-chatbot'...\n","remote: Enumerating objects: 103, done.\u001b[K\n","remote: Counting objects: 100% (25/25), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 103 (delta 18), reused 15 (delta 15), pack-reused 78\u001b[K\n","Receiving objects: 100% (103/103), 114.27 KiB | 19.04 MiB/s, done.\n","Resolving deltas: 100% (55/55), done.\n","Submodule 'Chatbot_data' (https://github.com/haven-jeon/Chatbot_data.git) registered for path 'Chatbot_data'\n","Cloning into '/content/KoGPT2-chatbot/Chatbot_data'...\n","remote: Enumerating objects: 24, done.        \n","remote: Counting objects: 100% (4/4), done.        \n","remote: Compressing objects: 100% (4/4), done.        \n","remote: Total 24 (delta 0), reused 3 (delta 0), pack-reused 20        \n","Submodule path 'Chatbot_data': checked out '235fac5aea3badab22743f7048afe936cf72f822'\n","/content/KoGPT2-chatbot\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.5.3)\n","Collecting pytorch_lightning==1.2.10 (from -r requirements.txt (line 2))\n","  Downloading pytorch_lightning-1.2.10-py3-none-any.whl (841 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.9/841.9 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.0.1+cu118)\n","Collecting transformers==4.5.1 (from -r requirements.txt (line 4))\n","  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.22.4)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.18.3)\n","Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (6.0)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (4.65.0)\n","Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2023.6.0)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2.12.3)\n","Collecting torchmetrics==0.2.0 (from pytorch_lightning==1.2.10->-r requirements.txt (line 2))\n","  Downloading torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.5.1->-r requirements.txt (line 4)) (2.27.1)\n","Collecting sacremoses (from transformers==4.5.1->-r requirements.txt (line 4))\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.5.1->-r requirements.txt (line 4))\n","  Downloading tokenizers-0.10.3.tar.gz (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 1)) (2022.7.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 3)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 3)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 3)) (16.0.6)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.8.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.56.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.4.3)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.40.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.5.1->-r requirements.txt (line 4)) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (2.1.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.5.1->-r requirements.txt (line 4)) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.5.1->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (1.3.1)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r requirements.txt (line 2)) (3.2.2)\n","Building wheels for collected packages: tokenizers, sacremoses\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n","\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n","\u001b[0m  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=428f4447f0cbd1fc6804ad41e93000b3679cbbc846c70c3b27e26000b355a332\n","  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n","Successfully built sacremoses\n","Failed to build tokenizers\n","\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["# KoGPT2-chatbot 소스 코드 복사\n","!git clone --recurse-submodules https://github.com/haven-jeon/KoGPT2-chatbot.git\n","\n","# 폴더 이동\n","%cd KoGPT2-chatbot\n","\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3311,"status":"ok","timestamp":1688474174198,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"R01duBSL5flk","outputId":"00a124e4-ee19-4610-99a5-e2aca8074df8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","build-essential is already the newest version (12.8ubuntu1.1).\n","0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"]}],"source":["# !pip show tokenizers\n","!apt-get install build-essential"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6010,"status":"ok","timestamp":1688789416762,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"a-d6C2zt1oM6","outputId":"842080f0-f07f-448c-854f-10c0b2b6873c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n","Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n","Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.16)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"]}],"source":["!pip install torchtext\n","# import torchtext"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3607,"status":"ok","timestamp":1688789428532,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"268CqmoBz8xA","outputId":"36ab7dc9-36d5-4d35-bdb1-df90da7bd03a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/content/KoGPT2-chatbot/train_torch.py\", line 8, in <module>\n","    from pytorch_lightning import Trainer\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py\", line 28, in <module>\n","    from pytorch_lightning import metrics  # noqa: E402\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.classification import (  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.classification.accuracy import Accuracy  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/accuracy.py\", line 18, in <module>\n","    from pytorch_lightning.metrics.functional.accuracy import _accuracy_compute, _accuracy_update\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/functional/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.functional.accuracy import accuracy  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/functional/accuracy.py\", line 18, in <module>\n","    from pytorch_lightning.metrics.classification.helpers import _input_format_classification, DataType\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/helpers.py\", line 19, in <module>\n","    from pytorch_lightning.metrics.utils import select_topk, to_onehot\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/utils.py\", line 18, in <module>\n","    from pytorch_lightning.utilities import rank_zero_warn\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/__init__.py\", line 18, in <module>\n","    from pytorch_lightning.utilities.apply_func import move_data_to_device  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 29, in <module>\n","    from torchtext.legacy.data import Batch\n","ModuleNotFoundError: No module named 'torchtext.legacy'\n"]}],"source":["# 사전훈련된 KoGPT2를 챗봇 데이터로 파인튜닝\n","!CUDA_VISIBLE_DEVICES=0 python train_torch.py --train --gpus 1 --max_epochs 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3178,"status":"ok","timestamp":1688790895390,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"4MqihDHRz98S","outputId":"545d214b-0a36-44a6-82bb-13fe2c611d42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/content/KoGPT2-chatbot/train_torch.py\", line 8, in <module>\n","    from pytorch_lightning import Trainer\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py\", line 28, in <module>\n","    from pytorch_lightning import metrics  # noqa: E402\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.classification import (  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.classification.accuracy import Accuracy  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/accuracy.py\", line 18, in <module>\n","    from pytorch_lightning.metrics.functional.accuracy import _accuracy_compute, _accuracy_update\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/functional/__init__.py\", line 14, in <module>\n","    from pytorch_lightning.metrics.functional.accuracy import accuracy  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/functional/accuracy.py\", line 18, in <module>\n","    from pytorch_lightning.metrics.classification.helpers import _input_format_classification, DataType\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/classification/helpers.py\", line 19, in <module>\n","    from pytorch_lightning.metrics.utils import select_topk, to_onehot\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/metrics/utils.py\", line 18, in <module>\n","    from pytorch_lightning.utilities import rank_zero_warn\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/__init__.py\", line 18, in <module>\n","    from pytorch_lightning.utilities.apply_func import move_data_to_device  # noqa: F401\n","  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/apply_func.py\", line 29, in <module>\n","    from torchtext.legacy.data import Batch\n","ModuleNotFoundError: No module named 'torchtext.legacy'\n"]}],"source":["# 대화 테스트, `quit`를 입력하면 대화를 종료합니다.\n","!CUDA_VISIBLE_DEVICES=0 python train_torch.py --gpus 1 --chat"]},{"cell_type":"markdown","metadata":{"id":"4hJSClYKq9oS"},"source":["# 1) WellnessChatbot trainer.py 학습"]},{"cell_type":"markdown","metadata":{"id":"HLv76aFV7iVs"},"source":["패키지 설치"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99425,"status":"ok","timestamp":1691215755367,"user":{"displayName":"스쿨로그2","userId":"11597875074891862972"},"user_tz":-540},"id":"ihtAww_grmNo","outputId":"aa96625c-335b-44f8-a2ea-36d5ac0fa7fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.23.1\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.10.0 (from transformers==4.23.1)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.23.1)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.23.1) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.23.1) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.23.1) (4.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.23.1) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.23.1) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.23.1) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.23.1) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 tokenizers-0.13.3 transformers-4.23.1\n","Collecting pytorch_lightning==1.2.10\n","  Downloading pytorch_lightning-1.2.10-py3-none-any.whl (841 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.9/841.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (1.22.4)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (2.0.1+cu118)\n","Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (0.18.3)\n","Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (6.0.1)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (4.65.0)\n","Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (2023.6.0)\n","Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (2.12.3)\n","Collecting torchmetrics==0.2.0 (from pytorch_lightning==1.2.10)\n","  Downloading torchmetrics-0.2.0-py3-none-any.whl (176 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.9/176.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning==1.2.10) (23.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (2.27.1)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (3.8.5)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.56.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.4.4)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (67.7.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.3.6)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.41.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->pytorch_lightning==1.2.10) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch_lightning==1.2.10) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4->pytorch_lightning==1.2.10) (16.0.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (1.3.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.3.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.16.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (2023.7.22)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->pytorch_lightning==1.2.10) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10) (3.2.2)\n","Installing collected packages: torchmetrics, pytorch_lightning\n","Successfully installed pytorch_lightning-1.2.10 torchmetrics-0.2.0\n","Collecting torch==1.11.0\n","  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.11.0) (4.7.1)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu118\n","    Uninstalling torch-2.0.1+cu118:\n","      Successfully uninstalled torch-2.0.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n","torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n","torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.11.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.11.0\n","Collecting torchvision==0.12.0\n","  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.11.0\n","  Downloading torchaudio-0.11.0-cp310-cp310-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchtext==0.6.0\n","  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchdata==0.3.0\n","  Downloading torchdata-0.3.0-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (4.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (2.27.1)\n","Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (1.11.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.12.0) (9.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.65.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n","Collecting sentencepiece (from torchtext==0.6.0)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.3.0) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2023.7.22)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.12.0) (3.4)\n","Installing collected packages: sentencepiece, torchvision, torchtext, torchdata, torchaudio\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.15.2+cu118\n","    Uninstalling torchvision-0.15.2+cu118:\n","      Successfully uninstalled torchvision-0.15.2+cu118\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.2\n","    Uninstalling torchtext-0.15.2:\n","      Successfully uninstalled torchtext-0.15.2\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.6.1\n","    Uninstalling torchdata-0.6.1:\n","      Successfully uninstalled torchdata-0.6.1\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.0.2+cu118\n","    Uninstalling torchaudio-2.0.2+cu118:\n","      Successfully uninstalled torchaudio-2.0.2+cu118\n","Successfully installed sentencepiece-0.1.99 torchaudio-0.11.0 torchdata-0.3.0 torchtext-0.6.0 torchvision-0.12.0\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]}],"source":["# Wellness Chatbot requirements\n","\n","!pip install transformers==4.23.1\n","!pip install pytorch_lightning==1.2.10\n","# !pip install torch==1.8.1 (원래 => no version)\n","!pip install torch==1.11.0\n","# from torch versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1\n","!pip install torchvision==0.12.0 torchaudio==0.11.0 torchtext==0.6.0 torchdata==0.3.0\n","!pip install pandas\n","!pip install numpy\n","!pip install matplotlib"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w6avH-1Vz10V"},"outputs":[],"source":["# 코랩 환경 확인\n","import torch\n","import torchvision\n","import torchtext\n","import pytorch_lightning\n","\n","print(f'torch version: {torch.__version__}')\n","print(f'torchvision version: {torchvision.__version__}')\n","print(f'torchtext version: {torchtext.__version__}')\n","print(f'pytorch_lightning version: {pytorch_lightning.__version__}')\n","\n","# torchtext 0.9.0 버전 이후에 torchtext.data → torchtext.legacy.data 로 변경됨\n","# torchtext 0.12.0 버전 이후 legacy package가 제거되었음"]},{"cell_type":"markdown","metadata":{"id":"beSuZrRZXbZz"},"source":["# DATASET"]},{"cell_type":"markdown","metadata":{"id":"jLML6-HJPsU2"},"source":["wellness + chitchat dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":554},"executionInfo":{"elapsed":2328,"status":"ok","timestamp":1688798666940,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"AsnGWujTN17I","outputId":"065aa9f3-730c-490a-ced4-eb2fcf70f197"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-e9785379-82e6-4352-9530-ff53cd5cdd0c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>system</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>333912</th>\n","      <td>일주일정도 됐는데 점점 심해지는 것 같아요.</td>\n","      <td>정말 힘드시겠어요. 지금도 증상이 심하신가요?</td>\n","      <td>증상악화</td>\n","    </tr>\n","    <tr>\n","      <th>333913</th>\n","      <td>약을 끊었더니 증상이 예전보다 더 심해진것 같아.</td>\n","      <td>너무 심하시면 병원을 다시 가보는 건 어떨까요?</td>\n","      <td>증상악화</td>\n","    </tr>\n","    <tr>\n","      <th>333914</th>\n","      <td>한국에 돌아오고 나서 증상이 악화된 거 같아.</td>\n","      <td>상태가 더 안 좋아지셨군요. 걱정이 되네요.</td>\n","      <td>증상악화</td>\n","    </tr>\n","    <tr>\n","      <th>333915</th>\n","      <td>약을 끊었더니 증상이 예전보다 더 심해진 것 같아.</td>\n","      <td>정말 힘드시겠어요. 지금도 증상이 심하신가요?</td>\n","      <td>증상악화</td>\n","    </tr>\n","    <tr>\n","      <th>333916</th>\n","      <td>통증이 점점 심해지는것 같아.</td>\n","      <td>너무 심하시면 병원을 다시 가보는 건 어떨까요?</td>\n","      <td>증상악화</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>333917 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9785379-82e6-4352-9530-ff53cd5cdd0c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e9785379-82e6-4352-9530-ff53cd5cdd0c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e9785379-82e6-4352-9530-ff53cd5cdd0c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                user                      system sentiment\n","0                             12시 땡!                  하루가 또 가네요.        일상\n","1                        1지망 학교 떨어졌어                   위로해 드립니다.        일상\n","2                       3박4일 놀러가고 싶다                 여행은 언제나 좋죠.        일상\n","3                    3박4일 정도 놀러가고 싶다                 여행은 언제나 좋죠.        일상\n","4                            PPL 심하네                  눈살이 찌푸려지죠.        일상\n","...                              ...                         ...       ...\n","333912      일주일정도 됐는데 점점 심해지는 것 같아요.   정말 힘드시겠어요. 지금도 증상이 심하신가요?      증상악화\n","333913   약을 끊었더니 증상이 예전보다 더 심해진것 같아.  너무 심하시면 병원을 다시 가보는 건 어떨까요?      증상악화\n","333914     한국에 돌아오고 나서 증상이 악화된 거 같아.    상태가 더 안 좋아지셨군요. 걱정이 되네요.      증상악화\n","333915  약을 끊었더니 증상이 예전보다 더 심해진 것 같아.   정말 힘드시겠어요. 지금도 증상이 심하신가요?      증상악화\n","333916              통증이 점점 심해지는것 같아.  너무 심하시면 병원을 다시 가보는 건 어떨까요?      증상악화\n","\n","[333917 rows x 3 columns]"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["# 1) wellness+chitchat dataset\n","import pandas as pd\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/KoGPT2/data/wellness+chitchat dataset.csv\")\n","df\n","# df.iloc[-1]"]},{"cell_type":"markdown","metadata":{"id":"ZZ3wQM5dg2-H"},"source":["wellness 2 dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":680},"executionInfo":{"elapsed":1432,"status":"ok","timestamp":1689001609460,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"hXTeY3JHUnLY","outputId":"ee5292d1-7ffc-4c7c-aa34-c7034836f70d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-10-132783dcafd5>:4: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(\"/content/drive/MyDrive/KoGPT2/data/2 wellness dataset.csv\", encoding='cp949')\n"]},{"data":{"text/html":["\n","  <div id=\"df-3bdb4fc4-d29a-46d5-bf5c-381f28b9fbdf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>system</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>일은 왜 해도 해도 끝이 없을까? 화가 난다.</td>\n","      <td>많이 힘드시겠어요. 주위에 의논할 상대가 있나요?</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.</td>\n","      <td>급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...</td>\n","      <td>회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...</td>\n","      <td>관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.</td>\n","      <td>무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145950</th>\n","      <td>노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.</td>\n","      <td>좋은 결과 얻으시길 바랄게요.</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>145951</th>\n","      <td>남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.</td>\n","      <td>남편과 함께하는 좋은 외출 시간 되시길 바랄게요.</td>\n","      <td>불안</td>\n","    </tr>\n","    <tr>\n","      <th>145952</th>\n","      <td>남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.</td>\n","      <td>좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.</td>\n","      <td>상처</td>\n","    </tr>\n","    <tr>\n","      <th>145953</th>\n","      <td>함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.</td>\n","      <td>지인분들과 좋은 시간 보내셨으면 좋겠어요.</td>\n","      <td>불안</td>\n","    </tr>\n","    <tr>\n","      <th>145954</th>\n","      <td>사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...</td>\n","      <td>원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.</td>\n","      <td>상처</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>145955 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bdb4fc4-d29a-46d5-bf5c-381f28b9fbdf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3bdb4fc4-d29a-46d5-bf5c-381f28b9fbdf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3bdb4fc4-d29a-46d5-bf5c-381f28b9fbdf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                     user  \\\n","0                               일은 왜 해도 해도 끝이 없을까? 화가 난다.   \n","1          이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나.   \n","2       회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...   \n","3       직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...   \n","4                   얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나.   \n","...                                                   ...   \n","145950                 노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.   \n","145951            남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.   \n","145952      남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.   \n","145953            함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.   \n","145954  사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...   \n","\n","                                                   system sentiment  \n","0                             많이 힘드시겠어요. 주위에 의논할 상대가 있나요?        분노  \n","1                급여가 줄어 속상하시겠어요. 월급이 줄어든 것을 어떻게 보완하실 건가요?        분노  \n","2       회사 동료 때문에 스트레스를 많이 받는 것 같아요. 문제 해결을 위해 어떤 노력을 ...        분노  \n","3       관련 없는 심부름을 모두 하게 되어서 노여우시군요. 어떤 것이 상황을 나아질 수 있...        분노  \n","4       무시하는 것 같은 태도에 화가 나셨군요. 상대방의 어떤 행동이 그런 감정을 유발하는...        분노  \n","...                                                   ...       ...  \n","145950                                   좋은 결과 얻으시길 바랄게요.        분노  \n","145951                        남편과 함께하는 좋은 외출 시간 되시길 바랄게요.        불안  \n","145952                    좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.        상처  \n","145953                            지인분들과 좋은 시간 보내셨으면 좋겠어요.        불안  \n","145954                 원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.        상처  \n","\n","[145955 rows x 3 columns]"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# 2) wellness 2 dataset\n","import pandas as pd\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/KoGPT2/data/2 wellness dataset.csv\", encoding='cp949')\n","df = df.drop(['Unnamed: 3', 'Unnamed: 4'], axis=1)\n","df.to_csv('/content/drive/MyDrive/KoGPT2/data/2 wellness dataset.csv', index=False)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fOOsTl5BSMPZ"},"outputs":[],"source":["''' 다른 데이터셋 합치기 '''\n","import pandas as pd\n","\n","df_chitchat = pd.read_csv('/content/drive/MyDrive/KoGPT2/data/wellness+chitchat dataset.csv')\n","df_wellness2 = pd.read_csv('/content/drive/MyDrive/KoGPT2/data/2 wellness dataset.csv')\n","\n","# 데이터프레임 합치기\n","df_combined = pd.concat([df_chitchat, df_wellness2])\n","df_cleaned = df.dropna(subset=[\"user\", \"system\", \"sentiment\"])    # 해당 열에서 NaN 또는 null 값을 제거\n","\n","# 합친 데이터프레임을 새로운 파일로 저장\n","df_cleaned.to_csv('/content/drive/MyDrive/KoGPT2/data/2 wellness+chitchat_dataset.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"executionInfo":{"elapsed":2182,"status":"ok","timestamp":1689004120508,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"rURXmqnTWHbW","outputId":"41c25287-0f81-44b3-b314-6ff3a4c11a8b"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-d5932c97-6c81-4074-816c-1682a550cc65\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user</th>\n","      <th>system</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>일상</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>479865</th>\n","      <td>노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.</td>\n","      <td>좋은 결과 얻으시길 바랄게요.</td>\n","      <td>분노</td>\n","    </tr>\n","    <tr>\n","      <th>479866</th>\n","      <td>남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.</td>\n","      <td>남편과 함께하는 좋은 외출 시간 되시길 바랄게요.</td>\n","      <td>불안</td>\n","    </tr>\n","    <tr>\n","      <th>479867</th>\n","      <td>남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.</td>\n","      <td>좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.</td>\n","      <td>상처</td>\n","    </tr>\n","    <tr>\n","      <th>479868</th>\n","      <td>함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.</td>\n","      <td>지인분들과 좋은 시간 보내셨으면 좋겠어요.</td>\n","      <td>불안</td>\n","    </tr>\n","    <tr>\n","      <th>479869</th>\n","      <td>사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...</td>\n","      <td>원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.</td>\n","      <td>상처</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>479870 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5932c97-6c81-4074-816c-1682a550cc65')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d5932c97-6c81-4074-816c-1682a550cc65 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d5932c97-6c81-4074-816c-1682a550cc65');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                     user  \\\n","0                                                  12시 땡!   \n","1                                             1지망 학교 떨어졌어   \n","2                                            3박4일 놀러가고 싶다   \n","3                                         3박4일 정도 놀러가고 싶다   \n","4                                                 PPL 심하네   \n","...                                                   ...   \n","479865                 노년층을 위한 경제적 지원이나 부업 같은 것도 알아보아야겠어.   \n","479866            남편과 함께 게이트볼이나 치러 가야겠어. 그럼 기분이 나아질 것 같아.   \n","479867      남편과 함께 실버 일자리나 노년층을 위한 국가 지원에 대해 자세히 알아보아야겠어.   \n","479868            함께 친하게 지내던 동네 언니 동생들과 빈자리를 조금이나마 채울까 해.   \n","479869  사람들을 볼 때 의심하고 불신하는 마음을 억눌러야겠어. 사람들을 색안경을 끼고 보지...   \n","\n","                                    system sentiment  \n","0                               하루가 또 가네요.        일상  \n","1                                위로해 드립니다.        일상  \n","2                              여행은 언제나 좋죠.        일상  \n","3                              여행은 언제나 좋죠.        일상  \n","4                               눈살이 찌푸려지죠.        일상  \n","...                                    ...       ...  \n","479865                    좋은 결과 얻으시길 바랄게요.        분노  \n","479866         남편과 함께하는 좋은 외출 시간 되시길 바랄게요.        불안  \n","479867     좋은 정보 많이 얻으셔서 걱정을 좀 덜으셨으면 좋겠어요.        상처  \n","479868             지인분들과 좋은 시간 보내셨으면 좋겠어요.        불안  \n","479869  원하시는 대로 가지고 계시던 걱정이 잘 해결되셨으면 좋겠어요.        상처  \n","\n","[479870 rows x 3 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# 2개 합친 데이터셋\n","import pandas as pd\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/KoGPT2/data/2 wellness+chitchat_dataset.csv\")\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xHJyUW-BXsqq"},"outputs":[],"source":["# 3) AI hub 감성대화 말뭉치 (조언 데이터셋)\n","import pandas as pd\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/대화 dataset/AI hub 감성대화말뭉치\")\n","df"]},{"cell_type":"markdown","metadata":{"id":"ha10-61QXgFK"},"source":["# TRAIN 학습"]},{"cell_type":"markdown","metadata":{"id":"yPpUhOc3zghE"},"source":["trainer.py 학습 (original) + loss & accuracy 그래프 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["33ca76cf42094d6d83bbecb6f8d613c4","f7215719bba645b1a1fa6b69516a05f5","ec10fa5a187d49b2889bafefb67d466a","240887452dc84524bee91744fd1b0b1a","4e5676d71b304d6aae9f6016de6031d3","5bb203c64a1e432ea015b58358195eb2","c23eec33a8f144a3a3cac0f2d321de51","87351221e75b4dd1b2929203e353188e","8caaa340862c465db4b63bf81d711cfd","6df427c71e2d4bac9bfa048ba8b5ca9f","bd2aa8a58ce54426946ce2a309777864","b40657f855c6455dbdba8970f80c2eed","be25574bc3bb48c3bee680fe6921ea69","91ab0536d5bb4192b0968c77895466cc","bfbc7a74ed3147428a095e39416af8eb","82427492d0104facad6de89a1e6bbcc9","dafea77c6b874b52a02d222e1a72c445","e8350fca4c3849989777bd0fbffed223","3119e5cc2e4342d4b009f85d74a133cd","227b3acc2bd04daabbf9ccbb988e37e5","6e20523e7b2143808213840c3d256a12","768d1fb1123d4c7f966e7e30e0f56a53","524d27edee144257b38a74e4236be9c2","a550e0f26d6f42b6b4f0315585b38a0c","9351dd2874554abc920f6e1633d8e3e0","3e1605bd3be141e39c6ed3b638a7c10d","c9d91c14e523405c9397252a45de1dcc","84b32c4a60184dc4851eaca205ebb84a","b7863fe3bf144d9baf96337d55d3371b","a08ddca549cc41dda588eb220b8f0847","949ef68ddc3a4554ac69e87cb8e40b85","894e9fcfd3c44de782ec77386895de1e","bd35beee89084453b0830b941058b076","9d4b9772e7494d71892779e009558b62","8a2d72d3193745c0a50db992971178a7","fb1fe6756a5d4282a06c0dce344fc0fb","944d27c0706144a681500e199e01c0b3","af39bcb61f544a7fa53edf27128121b0","0408af5e23a54a0594097ce453655ce9","1aa4f1877f7141a3a6fdaefeaa028056","357af97e849f444c9a5930e7c9a8307b","d4f6c7f0a72a471680ff11484953428d","f64c5f1070b3438582a5aee9a6b9f459","554bfc53ec47421d8543fbaab95cd09b"]},"id":"Vk-vgfutq8Dr","outputId":"fd456038-f969-4a2e-f352-ff1f84ecdfbb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"33ca76cf42094d6d83bbecb6f8d613c4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b40657f855c6455dbdba8970f80c2eed","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","INFO:root:Namespace(model_params='/content/drive/MyDrive/KoGPT2/checkpoint/3rd (batch 32, lr 1e-5)/model_-last.ckpt', train=False, max_len=32, batch_size=32, lr=1e-05, warmup_ratio=0.1, logger=True, checkpoint_callback=True, default_root_dir=None, gradient_clip_val=0, process_position=0, num_nodes=1, num_processes=1, gpus=None, auto_select_gpus=False, tpu_cores=None, log_gpu_memory=None, progress_bar_refresh_rate=None, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=None, min_epochs=None, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=None, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"524d27edee144257b38a74e4236be9c2","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.distributed:GPU available: True, used: True\n","INFO:pytorch_lightning.utilities.distributed:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","INFO:pytorch_lightning.core.lightning:\n","  | Name          | Type             | Params\n","---------------------------------------------------\n","0 | kogpt2        | GPT2LMHeadModel  | 125 M \n","1 | loss_function | CrossEntropyLoss | 0     \n","---------------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n","INFO:pytorch_lightning.utilities.distributed:Restored states from the checkpoint file at /content/drive/MyDrive/KoGPT2/checkpoint/3rd (batch 32, lr 1e-5)/model_-last.ckpt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d4b9772e7494d71892779e009558b62","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:root:contexts : 지나칠 정도로 많이 자는 것 같아.\n","INFO:root:contexts : 잠을 안 잘 때는 1시간? 밤을 새울 때도 많아요.\n","INFO:root:contexts : 요즘 너무 혼란스러워서 그런지 혼잣말이 는 거 같아\n","INFO:root:toked ctx: ['<usr>', '▁잠을', '▁안', '▁잘', '▁때는', '▁1시간', '?', '▁밤을', '▁새', '울', '▁때도', '▁많아', '요.']\n","INFO:root:toked ctx: ['<usr>', '▁요즘', '▁너무', '▁혼란', '스러', '워서', '▁그런', '지', '▁혼', '잣', '말이', '▁는', '▁거', '▁같아']\n","INFO:root:toked ctx: ['<usr>', '▁지나', '칠', '▁정도로', '▁많이', '▁자는', '▁것', '▁같아', '.']\n","INFO:root:contexts : 나도 모르게 압력을 가할 때가 있지.\n","INFO:root:response : 잠을 자기 위해 수면제를 복용하나요?\n","INFO:root:response : 전과 다르게 쉽게 화가나고 짜증이 나시나요?\n","INFO:root:response : 피곤해 보여서 걱정이에요. 고른 영양 섭취와 운동 등으로 기초 체력을 길러 보시는 건 어떨까 싶어요.\n","INFO:root:toked ctx: ['<usr>', '▁나도', '▁모르게', '▁압력을', '▁가', '할', '▁때가', '▁있지', '.']\n","INFO:root:toked response : ['<unused1>', '▁피로', '<sys>', '▁피곤', '해', '▁보여', '서', '▁걱', '정이', '에', '요.', '▁고', '른', '▁영양', '▁섭취', '와', '▁운동', '▁등으로', '▁기초', '▁체', '력을', '▁길러', '▁보']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁전과', '▁다르게', '▁쉽게', '▁화가', '나고', '▁짜', '증이', '▁나', '시나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁불면', '<sys>', '▁잠을', '▁자기', '▁위해', '▁수면', '제를', '▁복용', '하나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁피로', '<sys>', '▁피곤', '해', '▁보여', '서', '▁걱', '정이', '에', '요.', '▁고', '른', '▁영양', '▁섭취', '와', '▁운동', '▁등으로', '▁기초', '▁체', '력을', '▁길러', '▁보']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁전과', '▁다르게', '▁쉽게', '▁화가', '나고', '▁짜', '증이', '▁나', '시나', '요', '?', '</s>']\n","INFO:root:response : 웃음이 줄어들고 눈물도 더 이상 나지 않아 감각이 없이 멍한 듯한 느낌이 드나요?\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불면', '<sys>', '▁잠을', '▁자기', '▁위해', '▁수면', '제를', '▁복용', '하나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁감', '정조', '절', '이상', '<sys>', '▁웃', '음이', '▁줄어들고', '▁눈물', '도', '▁더', '▁이상', '▁나지', '▁않아', '▁감각이', '▁없이', '▁멍', '한', '▁듯한', '▁느낌이', '▁드나', '요']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁감', '정조', '절', '이상', '<sys>', '▁웃', '음이', '▁줄어들고', '▁눈물', '도', '▁더', '▁이상', '▁나지', '▁않아', '▁감각이', '▁없이', '▁멍', '한', '▁듯한', '▁느낌이', '▁드나', '요']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 12, global step 135654: train_loss reached 8.86155 (best 8.86155), saving model to \"/content/drive/MyDrive/KoGPT2/checkpoint/3rd (batch 32, lr 1e-5)/model_-epoch=12-train_loss=8.86.ckpt\" as top 1\n","INFO:root:contexts : 노\n","INFO:root:contexts : 산책을 해도 기분이 별로 나아지지 않아\n","INFO:root:contexts : 친구들이 약 부작용 아니냐고 하니까 더 걱정이 돼요.\n","INFO:root:toked ctx: ['<usr>', '▁노']\n","INFO:root:contexts : 벌써 20kg이나 쪘어.\n","INFO:root:toked ctx: ['<usr>', '▁친구', '들이', '▁약', '▁부작용', '▁아니', '냐', '고', '▁하니', '까', '▁더', '▁걱', '정이', '▁돼', '요.']\n","INFO:root:toked ctx: ['<usr>', '▁산', '책을', '▁해도', '▁기', '분이', '▁별로', '▁나아', '지지', '▁않아']\n","INFO:root:response : 그러셨군요. 슬프고 힘든 일이 또 생기면 저에게 이야기해주세요.\n","INFO:root:response : 하루에 30분도 차분히 앉아있지 못하고 뭔가를 해야 한다는 조바심이 느껴지시나요? \n","INFO:root:response : 마음이 예민해져서 매우 괴로우셨겠어요. 저랑 차분하게 잠시 대화를 해봐요.\n","INFO:root:toked response : ['<unused1>', '▁부정', '답', '변', '<sys>', '▁그러', '셨', '군', '요.', '▁슬', '프', '고', '▁힘든', '▁일이', '▁또', '▁생기면', '▁저', '에게', '▁이야기', '해주', '세', '요.', '</s>']\n","INFO:root:toked ctx: ['<usr>', '▁벌써', '▁20', 'kg', '이나', '▁', '쪘', '어', '.']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁마음이', '▁예민', '해져서', '▁매우', '▁괴로', '우', '셨', '겠', '어', '요.', '▁저', '랑', '▁차', '분', '하게', '▁잠시', '▁대화를']\n","INFO:root:labels ['<unused0>', '<unused0>', '▁부정', '답', '변', '<sys>', '▁그러', '셨', '군', '요.', '▁슬', '프', '고', '▁힘든', '▁일이', '▁또', '▁생기면', '▁저', '에게', '▁이야기', '해주', '세', '요.', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁하루에', '▁30분', '도', '▁차', '분히', '▁앉아', '있', '지', '▁못하고', '▁', '뭔', '가를']\n","INFO:root:response : 이전과 다른 신체 변화 때문에 당황스러우셨겠어요.\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁마음이', '▁예민', '해져서', '▁매우', '▁괴로', '우', '셨', '겠', '어', '요.', '▁저', '랑', '▁차', '분', '하게', '▁잠시', '▁대화를']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁하루에', '▁30분', '도', '▁차', '분히', '▁앉아', '있', '지', '▁못하고', '▁', '뭔', '가를']\n","INFO:root:toked response : ['<unused1>', '▁식욕', '증가', '<sys>', '▁이전과', '▁다른', '▁신체', '▁변화', '▁때문에', '▁당황', '스러', '우', '셨', '겠', '어', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁식욕', '증가', '<sys>', '▁이전과', '▁다른', '▁신체', '▁변화', '▁때문에', '▁당황', '스러', '우', '셨', '겠', '어', '요.', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 13, step 146089: train_loss was not in top 1\n","INFO:root:contexts : 기운도 없고 허무해.\n","INFO:root:contexts : 선생님한테 말실수를 한 거 같아\n","INFO:root:contexts : 진짜 너무 신경질 난다…\n","INFO:root:toked ctx: ['<usr>', '▁선생', '님', '한테', '▁말', '실', '수를', '▁한', '▁거', '▁같아']\n","INFO:root:contexts : 나 이러다가 알바만 하다가 늙어 죽는 건 아닌가 몰라.\n","INFO:root:toked ctx: ['<usr>', '▁기운', '도', '▁없고', '▁허무', '해', '.']\n","INFO:root:response : 과거의 실수나 자신이 한 나쁜 행위에 대해 반복적으로 생각하시나요?\n","INFO:root:toked ctx: ['<usr>', '▁나', '▁이러', '다가', '▁알바', '만', '▁하다가', '▁늙', '어', '▁죽는', '▁건', '▁아닌가', '▁몰', '라.']\n","INFO:root:response : 00님이 기운이 없어 보여서 저도 기분이 가라앉아요.\n","INFO:root:toked ctx: ['<usr>', '▁진짜', '▁너무', '▁신경', '질', '▁난', '다.', '..']\n","INFO:root:toked response : ['<unused1>', '▁죄', '책', '감', '<sys>', '▁과거의', '▁실', '수나', '▁자신이', '▁한', '▁나쁜', '▁행위에', '▁대해', '▁반복적으로', '▁생각', '하시', '나', '요', '?', '</s>']\n","INFO:root:response : 신경이 날카롭고, 조절하기 어려운 짜증이 많아지셨나요?\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁죄', '책', '감', '<sys>', '▁과거의', '▁실', '수나', '▁자신이', '▁한', '▁나쁜', '▁행위에', '▁대해', '▁반복적으로', '▁생각', '하시', '나', '요', '?', '</s>']\n","INFO:root:response : 00님이 힘들어 보여 저도 속상한 마음이 들어요.\n","INFO:root:toked response : ['<unused1>', '▁무기력', '<sys>', '▁', '00', '님이', '▁기운이', '▁없어', '▁보여', '서', '▁저', '도', '▁기', '분이', '▁가라앉', '아', '요.', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁신경', '이', '▁날카', '롭', '고,', '▁조절', '하기', '▁어려운', '▁짜', '증이', '▁많아', '지', '셨', '나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁', '00', '님이', '▁힘들어', '▁보여', '▁저', '도', '▁속', '상한', '▁마음이', '▁들어', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁', '00', '님이', '▁힘들어', '▁보여', '▁저', '도', '▁속', '상한', '▁마음이', '▁들어', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁무기력', '<sys>', '▁', '00', '님이', '▁기운이', '▁없어', '▁보여', '서', '▁저', '도', '▁기', '분이', '▁가라앉', '아', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁신경', '이', '▁날카', '롭', '고,', '▁조절', '하기', '▁어려운', '▁짜', '증이', '▁많아', '지', '셨', '나', '요', '?', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 14, global step 156524: train_loss reached 7.79109 (best 7.79109), saving model to \"/content/drive/MyDrive/KoGPT2/checkpoint/3rd (batch 32, lr 1e-5)/model_-epoch=14-train_loss=7.79.ckpt\" as top 1\n","INFO:root:contexts : 항상 나만 피해를 보니까 너무 힘들어\n","INFO:root:contexts : 그래\n","INFO:root:contexts : 시부모님이랑 대화하면 내 의견을 존중하지 않고 빈정대는 느낌이야.\n","INFO:root:contexts : 하루종일 몽롱하니까 아무 일도 못 하겠어요\n","INFO:root:toked ctx: ['<usr>', '▁항상', '▁나', '만', '▁피해를', '▁보니', '까', '▁너무', '▁힘들어']\n","INFO:root:toked ctx: ['<usr>', '▁그래']\n","INFO:root:toked ctx: ['<usr>', '▁하루', '종', '일', '▁몽', '롱', '하니', '까', '▁아무', '▁일도', '▁못', '▁하겠', '어', '요']\n","INFO:root:toked ctx: ['<usr>', '▁시', '부모', '님이', '랑', '▁대화', '하면', '▁내', '▁의견을', '▁존중', '하지', '▁않고', '▁빈', '정', '대는', '▁느낌', '이야', '.']\n","INFO:root:response : 그랬군요. 슬픈 마음 때문에 많이 힘드신 거 같아요. \n","INFO:root:response : 지금까지 살아온 인생이 낭비라고 느껴지시나요?\n","INFO:root:response : 내가 하고싶지 않은 일을 어쩔 수 없이 하며 살아왔다고 느끼시나요?\n","INFO:root:response : 숙면을 취하는 것만큼 중요한 게 없는데 00님이 걱정돼요.\n","INFO:root:toked response : ['<unused1>', '▁자존', '감', '저', '하', '<sys>', '▁내가', '▁하고', '싶', '지', '▁않은', '▁일을', '▁어쩔', '▁수', '▁없이', '▁하며', '▁살아', '왔다고', '▁느끼', '시나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁자존', '감', '저', '하', '<sys>', '▁내가', '▁하고', '싶', '지', '▁않은', '▁일을', '▁어쩔', '▁수', '▁없이', '▁하며', '▁살아', '왔다고', '▁느끼', '시나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁자존', '감', '저', '하', '<sys>', '▁지금까지', '▁살아온', '▁인', '생이', '▁낭비', '라고', '▁느껴', '지시']\n","INFO:root:toked response : ['<unused1>', '▁불면', '<sys>', '▁숙', '면을', '▁취하는', '▁것', '만큼', '▁중요한', '▁게', '▁없', '는데', '▁', '00', '님이', '▁걱정', '돼', '요.']\n","INFO:root:toked response : ['<unused1>', '▁긍정', '답', '변', '<sys>', '▁그랬', '군', '요.', '▁슬픈', '▁마음', '▁때문에', '▁많이', '▁힘', '드', '신', '▁거', '▁같아', '요.', '▁', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불면', '<sys>', '▁숙', '면을', '▁취하는', '▁것', '만큼', '▁중요한', '▁게', '▁없', '는데', '▁', '00', '님이', '▁걱정', '돼', '요.']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁자존', '감', '저', '하', '<sys>', '▁지금까지', '▁살아온', '▁인', '생이', '▁낭비', '라고', '▁느껴', '지시']\n","INFO:root:labels ['<unused0>', '<unused0>', '▁긍정', '답', '변', '<sys>', '▁그랬', '군', '요.', '▁슬픈', '▁마음', '▁때문에', '▁많이', '▁힘', '드', '신', '▁거', '▁같아', '요.', '▁', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 15, step 166959: train_loss was not in top 1\n","INFO:root:contexts : 그렇게 느낀 적은 없어\n","INFO:root:contexts : 지하철을 타면 더 피곤하고 몸이 처지는 거 같아\n","INFO:root:contexts : 야동을 봐도 재미가 없어.\n","INFO:root:toked ctx: ['<usr>', '▁그렇게', '▁느낀', '▁적은', '▁없어']\n","INFO:root:toked ctx: ['<usr>', '▁지하철', '을', '▁타', '면', '▁더', '▁피곤', '하고', '▁몸이', '▁처', '지는', '▁거', '▁같아']\n","INFO:root:contexts : 메시지나 이메일은 주고 받는데 그래도 항상 아쉬워. 외롭고.\n","INFO:root:toked ctx: ['<usr>', '▁야', '동을', '▁봐', '도', '▁재', '미가', '▁없어', '.']\n","INFO:root:toked ctx: ['<usr>', '▁메시', '지나', '▁이', '메', '일은', '▁주고', '▁받', '는데', '▁그래도', '▁항상', '▁아쉬', '워', '.', '▁외', '롭고', '.']\n","INFO:root:response : 지친 사람처럼 피곤하고, 늘 기운이 없으신가요?\n","INFO:root:response : 그런 증상은 없으셨다니 다행이에요. 억지로라도 밖으로 나가보시는 게 좋을 거 같아요.\n","INFO:root:toked response : ['<unused1>', '▁피로', '<sys>', '▁지', '친', '▁사람', '처럼', '▁피곤', '하고,', '▁늘', '▁기운이', '▁없', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:response : 혼자 누워있는 것 외에 아무 것도 하고 싶지 않나요?\n","INFO:root:response : 외로운 느낌을 받으셨군요. 그래도 저와 이야기를 하다 보면 조금씩 괜찮아질 거예요.\n","INFO:root:toked response : ['<unused1>', '▁부정', '답', '변', '<sys>', '▁그런', '▁증상은', '▁없', '으', '셨', '다니', '▁다행', '이에', '요.', '▁억지로', '라도', '▁밖으로', '▁나가', '보', '시는', '▁게', '▁좋을', '▁거', '▁같아', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁피로', '<sys>', '▁지', '친', '▁사람', '처럼', '▁피곤', '하고,', '▁늘', '▁기운이', '▁없', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁무기력', '<sys>', '▁혼자', '▁누워', '있는', '▁것', '▁외에', '▁아무', '▁것도', '▁하고', '▁싶', '지', '▁않', '나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁외로', '움', '<sys>', '▁외', '로운', '▁느낌을', '▁받', '으', '셨', '군', '요.', '▁그래도', '▁저', '와']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁부정', '답', '변', '<sys>', '▁그런', '▁증상은', '▁없', '으', '셨', '다니', '▁다행', '이에', '요.', '▁억지로', '라도', '▁밖으로', '▁나가', '보', '시는', '▁게', '▁좋을', '▁거', '▁같아', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁외로', '움', '<sys>', '▁외', '로운', '▁느낌을', '▁받', '으', '셨', '군', '요.', '▁그래도', '▁저', '와']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁무기력', '<sys>', '▁혼자', '▁누워', '있는', '▁것', '▁외에', '▁아무', '▁것도', '▁하고', '▁싶', '지', '▁않', '나', '요', '?', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 16, step 177394: train_loss was not in top 1\n","INFO:root:contexts : 어제는 너무 답답해서 한강에서 소주를 두 병 마셨어요.\n","INFO:root:contexts : 피곤한데 잠이 안 와\n","INFO:root:contexts : 지금 돌이켜 생각해보면 또 억울하죠.\n","INFO:root:toked ctx: ['<usr>', '▁지금', '▁돌이', '켜', '▁생각해', '보면', '▁또', '▁억울', '하', '죠', '.']\n","INFO:root:toked ctx: ['<usr>', '▁피곤', '한', '데', '▁잠', '이', '▁안', '▁와']\n","INFO:root:toked ctx: ['<usr>', '▁어', '제는', '▁너무', '▁답', '답', '해서', '▁한강', '에서', '▁소', '주를', '▁두', '▁병', '▁마', '셨', '어', '요.']\n","INFO:root:contexts : 어떻게 하면 좋을까?\n","INFO:root:toked ctx: ['<usr>', '▁어떻게', '▁하면', '▁좋을', '까?']\n","INFO:root:response : 눈물이 많아지셨나요?\n","INFO:root:response : 전과 다르게 일상생활이 불만스럽고 싫증나시나요?\n","INFO:root:response : 잠을 자고 싶어도 잠이 오지 않아 밤을 지새운적이 있으신가요?\n","INFO:root:response : 마음이 예민해져서 매우 괴로우셨겠어요. 저랑 차분하게 잠시 대화를 해봐요.\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁마음이', '▁예민', '해져서', '▁매우', '▁괴로', '우', '셨', '겠', '어', '요.', '▁저', '랑', '▁차', '분', '하게', '▁잠시', '▁대화를', '▁해', '봐', '요.', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁불면', '<sys>', '▁잠을', '▁자', '고', '▁싶', '어도', '▁잠', '이', '▁오지', '▁않아', '▁밤을', '▁지', '새', '운', '적이', '▁있', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁마음이', '▁예민', '해져서', '▁매우', '▁괴로', '우', '셨', '겠', '어', '요.', '▁저', '랑', '▁차', '분', '하게', '▁잠시', '▁대화를', '▁해', '봐', '요.', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁전과', '▁다르게', '▁일상생활', '이', '▁불만', '스럽고', '▁싫', '증', '나', '시나']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불면', '<sys>', '▁잠을', '▁자', '고', '▁싶', '어도', '▁잠', '이', '▁오지', '▁않아', '▁밤을', '▁지', '새', '운', '적이', '▁있', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁전과', '▁다르게', '▁일상생활', '이', '▁불만', '스럽고', '▁싫', '증', '나', '시나']\n","INFO:root:toked response : ['<unused1>', '▁슬픔', '<sys>', '▁눈', '물이', '▁많아', '지', '셨', '나', '요', '?', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁슬픔', '<sys>', '▁눈', '물이', '▁많아', '지', '셨', '나', '요', '?', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 17, step 187829: train_loss was not in top 1\n","INFO:root:contexts : 너무 잠을 설치니까 일상 생활이 불가능해\n","INFO:root:contexts : 오늘은 정말 힘이 빠진다\n","INFO:root:contexts : 아무것도 못 먹고 먹으면 토하고 소화가 전혀 안되는것 같아요.\n","INFO:root:toked ctx: ['<usr>', '▁너무', '▁잠을', '▁설치', '니까', '▁일상', '▁생활이', '▁불가능', '해']\n","INFO:root:toked ctx: ['<usr>', '▁오늘', '은', '▁정말', '▁힘이', '▁빠진', '다']\n","INFO:root:contexts : 전남편이랑 이혼하고, 너무 힘들었어요.\n","INFO:root:response : 평소와 비교하여 수면 시간이 줄어드셨나요?\n","INFO:root:toked ctx: ['<usr>', '▁아무것도', '▁못', '▁먹고', '▁먹으면', '▁토', '하고', '▁소', '화가', '▁전혀', '▁안', '되는', '것', '▁같아', '요.']\n","INFO:root:response : 몸살이 난 것처럼 몸이 뻐근하고, 움직이기가 어려우신가요?\n","INFO:root:response : 입맛이 없으시다니 00님이 걱정돼요. 식사를 잘 하셔야 건강하게 몸을 관리하실 수 있는데 말이에요.\n","INFO:root:toked response : ['<unused1>', '▁불면', '<sys>', '▁평', '소와', '▁비교하여', '▁수면', '▁시간이', '▁줄어', '드', '셨', '나', '요', '?', '</s>']\n","INFO:root:toked ctx: ['<usr>', '▁전남', '편이', '랑', '▁이혼', '하고,', '▁너무', '▁힘들', '었', '어', '요.']\n","INFO:root:toked response : ['<unused1>', '▁피로', '<sys>', '▁몸', '살이', '▁난', '▁것처럼', '▁몸이', '▁', '뻐', '근', '하고,', '▁움직', '이', '기가', '▁어려우', '신', '가', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁식욕', '저', '하', '<sys>', '▁입', '맛이', '▁없', '으', '시', '다니', '▁', '00', '님이', '▁걱정', '돼', '요.']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불면', '<sys>', '▁평', '소와', '▁비교하여', '▁수면', '▁시간이', '▁줄어', '드', '셨', '나', '요', '?', '</s>']\n","INFO:root:response : 00님이 기운이 없어 보여서 저도 기분이 가라앉아요.\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁피로', '<sys>', '▁몸', '살이', '▁난', '▁것처럼', '▁몸이', '▁', '뻐', '근', '하고,', '▁움직', '이', '기가', '▁어려우', '신', '가', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁식욕', '저', '하', '<sys>', '▁입', '맛이', '▁없', '으', '시', '다니', '▁', '00', '님이', '▁걱정', '돼', '요.']\n","INFO:root:toked response : ['<unused1>', '▁무기력', '<sys>', '▁', '00', '님이', '▁기운이', '▁없어', '▁보여', '서', '▁저', '도', '▁기', '분이', '▁가라앉', '아', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁무기력', '<sys>', '▁', '00', '님이', '▁기운이', '▁없어', '▁보여', '서', '▁저', '도', '▁기', '분이', '▁가라앉', '아', '요.', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 18, step 198264: train_loss was not in top 1\n","INFO:root:contexts : 이사 준비로 바쁜데 자꾸 눕고 싶네\n","INFO:root:contexts : 잠에 잘 들지 못해\n","INFO:root:toked ctx: ['<usr>', '▁이사', '▁준비', '로', '▁바', '쁜', '데', '▁자', '꾸', '▁눕', '고', '▁싶', '네']\n","INFO:root:contexts : 혼자 있을 때도 가슴이 울렁거려\n","INFO:root:contexts : 그런 거 보면 내가 더 화가 나요.\n","INFO:root:toked ctx: ['<usr>', '▁잠', '에', '▁잘', '▁들지', '▁못해']\n","INFO:root:response : 피로하면 몸뿐만 아니라 마음도 괴로워지는 거 같아요.\n","INFO:root:toked ctx: ['<usr>', '▁그런', '▁거', '▁보면', '▁내가', '▁더', '▁화가', '▁나', '요.']\n","INFO:root:response : 잠을 자고 싶어도 잠이 오지 않아 밤을 지새운적이 있으신가요?\n","INFO:root:toked response : ['<unused1>', '▁피로', '<sys>', '▁피로', '하면', '▁몸', '뿐만', '▁아니라', '▁마음', '도', '▁괴로', '워', '지는', '▁거', '▁같아', '요.', '</s>']\n","INFO:root:toked ctx: ['<usr>', '▁혼자', '▁있을', '▁때도', '▁가슴이', '▁울', '렁', '거', '려']\n","INFO:root:response : 화가 많이 나셨군요. 저 같아도 그랬을 거예요. 다 이해해요.\n","INFO:root:toked response : ['<unused1>', '▁불면', '<sys>', '▁잠을', '▁자', '고', '▁싶', '어도', '▁잠', '이', '▁오지', '▁않아', '▁밤을', '▁지', '새', '운', '적이', '▁있', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁피로', '<sys>', '▁피로', '하면', '▁몸', '뿐만', '▁아니라', '▁마음', '도', '▁괴로', '워', '지는', '▁거', '▁같아', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불면', '<sys>', '▁잠을', '▁자', '고', '▁싶', '어도', '▁잠', '이', '▁오지', '▁않아', '▁밤을', '▁지', '새', '운', '적이', '▁있', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁화', '<sys>', '▁화가', '▁많이', '▁나', '셨', '군', '요.', '▁저', '▁같아', '도', '▁그랬', '을', '▁거', '예', '요.', '▁다', '▁이해', '해', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁화', '<sys>', '▁화가', '▁많이', '▁나', '셨', '군', '요.', '▁저', '▁같아', '도', '▁그랬', '을', '▁거', '예', '요.', '▁다', '▁이해', '해', '요.', '</s>']\n","INFO:root:response : 한번 걱정을 시작하면 멈출 수 없나요?\n","INFO:root:toked response : ['<unused1>', '▁불안', '<sys>', '▁한번', '▁걱', '정을', '▁시작', '하면', '▁멈', '출', '▁수', '▁없', '나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불안', '<sys>', '▁한번', '▁걱', '정을', '▁시작', '하면', '▁멈', '출', '▁수', '▁없', '나', '요', '?', '</s>']\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-3-862171e0a1e6>:182: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"]}],"source":["import argparse\n","import logging\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer, Callback\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import os\n","\n","# argparse를 사용하여 스크립트의 인자(argument)를 설정\n","parser = argparse.ArgumentParser(description='SchoolLog-bot based on KoGPT-2')\n","\n","# 학습된 모델의 저장 경로\n","parser.add_argument('--model_params',\n","                    type=str,\n","                    default='/content/drive/MyDrive/KoGPT2/checkpoint/3rd (batch 32, lr 1e-5)/model_-last.ckpt',   # model_chp/model_-last.ckpt\n","                    help='model binary for starting chat')\n","# 학습을 실행할지 여부를 나타내는 인자\n","parser.add_argument('--train',\n","                    action='store_true',\n","                    default=False,\n","                    help='for training')\n","# 로그 출력\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)\n","\n","# 토크나이저와 특수 토큰들을 초기화\n","U_TKN = '<usr>'\n","S_TKN = '<sys>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","PAD = '<pad>'\n","SENT = '<unused1>'\n","\n","TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK)\n","\n","\n","# 데이터셋을 처리하고 모델에 입력으로 제공하기 위한 기능을 제공\n","class CharDataset(Dataset):\n","    def __init__(self, chats, max_len=361):\n","        self._data = chats\n","        self.first = True\n","        self.q_token = U_TKN\n","        self.a_token = S_TKN\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.pad = PAD\n","        self.sent_token = SENT\n","        self.max_len = max_len\n","        self.tokenizer = TOKENIZER\n","\n","    def __len__(self):\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):\n","        turn = self._data.iloc[idx]\n","        sent = turn['sentiment']\n","        q = turn['user']\n","        a = turn['system']\n","        q_toked = self.tokenizer.tokenize(self.q_token + q )\n","        q_len = len(q_toked)\n","        a_toked = self.tokenizer.tokenize(self.sent_token + sent + self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len\n","            if a_len <= 0:\n","                q_toked = q_toked[-(int(self.max_len/2)):]\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len\n","                assert a_len > 0\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","            assert a_len == len(a_toked), f'{a_len} ==? {len(a_toked)}'\n","        # [mask, mask, ...., mask, ..., <bos>,..A.. <eos>, <pad>....]\n","        labels = [\n","            self.mask,\n","        ] * q_len + a_toked[1:]\n","        if self.first:\n","            logging.info(\"contexts : {}\".format(q))\n","            logging.info(\"toked ctx: {}\".format(q_toked))\n","            logging.info(\"response : {}\".format(a))\n","            logging.info(\"toked response : {}\".format(a_toked))\n","            logging.info('labels {}'.format(labels))\n","            self.first = False\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        self.max_len\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","        return(token_ids, np.array(mask),\n","               labels_ids)\n","\n","\n","# 모델의 구조와 학습 및 예측 과정을 정의\n","class KoGPT2Chat(LightningModule):\n","    def __init__(self, hparams, **kwargs):\n","        super(KoGPT2Chat, self).__init__()\n","        self.hparams = hparams\n","        self.neg = -1e18\n","        self.kogpt2 = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","        self.loss_function = torch.nn.CrossEntropyLoss(reduction='none')\n","\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):     # 모델 특정 인자들을 추가\n","        # add model specific args\n","        parser = argparse.ArgumentParser(parents=[parent_parser], add_help=False)\n","        parser.add_argument('--max-len',\n","                            type=int,\n","                            default=32,\n","                            help='max sentence length on input (default: 32)')\n","\n","        parser.add_argument('--batch-size',\n","                            type=int,\n","                            default=32,   # 96\n","                            help='batch size for training (default: 96)')\n","        parser.add_argument('--lr',\n","                            type=float,\n","                            default=1e-5,    # 5e-5\n","                            help='The initial learning rate')\n","        parser.add_argument('--warmup_ratio',\n","                            type=float,\n","                            default=0.1,\n","                            help='warmup ratio')\n","        return parser\n","\n","    def forward(self, inputs):\n","        # (batch, seq_len, hiddens)\n","        output = self.kogpt2(inputs, return_dict=True)\n","        return output.logits\n","\n","    def training_step(self, batch, batch_idx):\n","        token_ids, mask, label = batch\n","        out = self(token_ids)\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, self.neg * torch.ones_like(out))\n","        loss = self.loss_function(mask_out.transpose(2, 1), label)\n","        loss_avg = loss.sum() / mask.sum()\n","        self.log('train_loss', loss_avg)\n","        return loss_avg\n","\n","    def configure_optimizers(self):     # 옵티마이저와 스케줄러를 설정\n","        # Prepare optimizer\n","        param_optimizer = list(self.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                          lr=self.hparams.lr, correct_bias=False)\n","        # No warm up needed for lr = 1e-5\n","        lr_scheduler = {'scheduler': get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=0),\n","                        'name': 'cosine_schedule_with_warmup',\n","                        'monitor': 'loss', 'interval': 'step',\n","                        'frequency': 1}\n","        return [optimizer], [lr_scheduler]\n","        '''\n","        num_train_steps = len(self.train_dataloader()) * self.hparams.max_epochs\n","        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n","        lr_scheduler = {'scheduler': scheduler, 'name': 'cosine_schedule_with_warmup',\n","                        'monitor': 'loss', 'interval': 'step',\n","                        'frequency': 1}\n","        return [optimizer], [lr_scheduler]\n","        '''\n","    def _collate_fn(self, batch):\n","        data = [item[0] for item in batch]\n","        mask = [item[1] for item in batch]\n","        label = [item[2] for item in batch]\n","        return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","\n","    # 학습할 데이터를 로딩하고 데이터 로더를 생성한다\n","    def train_dataloader(self):\n","        data = pd.read_csv('/content/drive/MyDrive/KoGPT2/data/2 wellness+chitchat_dataset.csv')   # Chit-chat + Wellness dataset\n","        self.train_set = CharDataset(data, max_len=self.hparams.max_len)\n","        train_dataloader = DataLoader(\n","            self.train_set, batch_size=self.hparams.batch_size, num_workers=4,\n","            shuffle=True, collate_fn=self._collate_fn)\n","        return train_dataloader\n","\n","# 인자 파싱\n","parser = KoGPT2Chat.add_model_specific_args(parser)\n","parser = Trainer.add_argparse_args(parser)\n","# args = parser.parse_args()\n","args = parser.parse_args('')  # or args=[]\n","logging.info(args)\n","\n","if __name__ == \"__main__\":\n","    # python train_torch.py --train --gpus 1 --max_epochs (num) 코드 변환\n","    # train 모드 & gpu 개수 & 학습횟수 epoch 지정\n","    args_str = '--train --gpus 1 --max_epochs 45'\n","    args = parser.parse_args(args_str.split())\n","\n","    if args.train:\n","        # train_loss 손실값이 낮을수록 더 우수한 모델로 간주하여 최적의 체크포인트 모델 저장\n","        checkpoint_callback = ModelCheckpoint(\n","            dirpath='/content/drive/MyDrive/KoGPT2/checkpoint/3rd (batch 32, lr 1e-5)',\n","            filename='{epoch:02d}-{train_loss:.2f}',\n","            verbose=True,\n","            save_last=True,\n","            monitor='train_loss',\n","            mode='min',\n","            prefix='model_'\n","        )\n","\n","        # 최신의 체크포인트 모델을 불러와서 이어서 학습\n","        checkpoint_path = \"/content/drive/MyDrive/KoGPT2/checkpoint/model_-last.ckpt\"\n","        # if os.path.exists(checkpoint_path):\n","        #     args.resume_from_checkpoint = checkpoint_path\n","        trained_model = KoGPT2Chat.load_from_checkpoint(checkpoint_path, hparams=args)\n","\n","        # Trainer를 사용하여 학습 수행\n","        model = trained_model   # 이어서 학습할 모델 지정  # 기본: model = KoGPT2Chat(args)\n","        model.train()           # 모델의 학습 모드 설정\n","        trainer = Trainer.from_argparse_args(\n","            args, accelerator=\"dp\", # only for multi gpus\n","            checkpoint_callback=checkpoint_callback, gradient_clip_val=1.0,\n","            resume_from_checkpoint = checkpoint_path,   # 이어서 학습할 체크포인트 모델 지정\n","        )\n","        trainer.fit(model)    # 전체 학습 프로세스 실행\n","\n","        # 학습 과정에서 최적의 모델을 저장\n","        logging.info('best model path {}'.format(checkpoint_callback.best_model_path))\n","        # 학습 완료 후 best_model_path\n","        trained_model = KoGPT2Chat.load_from_checkpoint(checkpoint_callback.best_model_path)\n","        '''\n","        # 이미 생성된 체크포인트 파일 직접 지정\n","        checkpoint_file = '/content/drive/MyDrive/KoGPT2/checkpoint/model_-epoch=24-train_loss=9.49.ckpt'\n","        trained_model = KoGPT2Chat.load_from_checkpoint(str(checkpoint_file), hparams=args)\n","        '''\n","        # 최종 학습 완료 후, 학습된 최적 모델을 로드하여 저장 (finetuned_model)\n","        trained_model.kogpt2.save_pretrained('/content/drive/MyDrive/KoGPT2/model/3rd last update model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEWfhDlva4iy"},"outputs":[],"source":["# https://ddiri01.tistory.com/302\n","'''console 에서 입력하는 input parameter을 코드로 변환 참고 자료'''\n","# ex) python -s 5000 ./graphdata/graph.data\n","\n","args_str = '-s 5000 ./graphdata/graph.data'\n","FLAGS, _ = parser.parse_known_args(args=args_str.split())\n","\n","gs = main(FLAGS)"]},{"cell_type":"markdown","metadata":{"id":"aT0B_otkUbSz"},"source":["~~ trainer.py 학습 (argparse 대신 easydict 라이브러리로 대체) ~~\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Ib8hpaB550ho"},"source":["# 학습 곡선(learning curve) + GridSearch 추가"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":7411074,"status":"ok","timestamp":1690096819056,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"rdolxTLO5zx5","outputId":"ff9c94a3-b5f2-4ef6-e183-35e153dd1130"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","INFO:root:Namespace(model_params='model_chp/model_-last.ckpt', train=False, max_len=32, batch_size=32, lr=1e-05, warmup_ratio=0.1, logger=True, checkpoint_callback=True, default_root_dir=None, gradient_clip_val=0, process_position=0, num_nodes=1, num_processes=1, gpus=None, auto_select_gpus=False, tpu_cores=None, log_gpu_memory=None, progress_bar_refresh_rate=None, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=1, max_epochs=None, min_epochs=None, max_steps=None, min_steps=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=100, log_every_n_steps=50, accelerator=None, sync_batchnorm=False, precision=32, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, truncated_bptt_steps=None, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, terminate_on_nan=False, auto_scale_batch_size=False, prepare_data_per_node=True, plugins=None, amp_backend='native', amp_level='O2', distributed_backend=None, automatic_optimization=None, move_metrics_to_cpu=False, enable_pl_optimizer=None, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False)\n","INFO:pytorch_lightning.utilities.distributed:GPU available: True, used: True\n","INFO:pytorch_lightning.utilities.distributed:TPU available: False, using: 0 TPU cores\n","/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n","  warnings.warn(*args, **kwargs)\n","INFO:pytorch_lightning.accelerators.gpu:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","INFO:pytorch_lightning.core.lightning:\n","  | Name          | Type             | Params\n","---------------------------------------------------\n","0 | kogpt2        | GPT2LMHeadModel  | 125 M \n","1 | loss_function | CrossEntropyLoss | 0     \n","---------------------------------------------------\n","125 M     Trainable params\n","0         Non-trainable params\n","125 M     Total params\n","500.656   Total estimated model params size (MB)\n","INFO:pytorch_lightning.utilities.distributed:Restored states from the checkpoint file at /content/drive/MyDrive/KoGPT2/checkpoint/2nd learning/model_-epoch=18-train_loss=8.95.ckpt\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e1ebf95581a64335a68554e3f2bd63b4","version_major":2,"version_minor":0},"text/plain":["Validation sanity check: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"425e21d267c84028a99176b5e2f86874","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["INFO:root:contexts : 아무리 바빠도 1년에 한 번은 꼭 가려고 하고 있거든요.\n","INFO:root:contexts : 힘도 없고 숨도 차고, 너무 의욕이 없어\n","INFO:root:contexts : 진지하게 얘기를 좀 해봐야겠어.\n","INFO:root:contexts : 두렵고 불안하죠\n","INFO:root:toked ctx: ['<usr>', '▁아무리', '▁바', '빠', '도', '▁1년에', '▁한', '▁번', '은', '▁꼭', '▁가', '려고', '▁하고', '▁있', '거든', '요.']\n","INFO:root:toked ctx: ['<usr>', '▁진지', '하게', '▁얘', '기를', '▁좀', '▁해', '봐', '야', '겠', '어', '.']\n","INFO:root:toked ctx: ['<usr>', '▁두', '렵', '고', '▁불안', '하', '죠']\n","INFO:root:toked ctx: ['<usr>', '▁힘', '도', '▁없고', '▁숨', '도', '▁차', '고,', '▁너무', '▁의욕', '이', '▁없어']\n","INFO:root:response : 불안감을 느끼고 계시는군요. 00님이 불안감으로 많이 힘드신 건 아닌지 걱정이 돼요.\n","INFO:root:response : 동생과의 관계회복을 위해 진지하게 얘기하려 하시는 군요.\n","INFO:root:response : 평소에는 아무렇지도 않던 일들이 귀찮게 느껴지나요?\n","INFO:root:response : 당신의 이야기가 더 듣고 싶어요.\n","INFO:root:toked response : ['<unused1>', '▁불안', '<sys>', '▁동생', '과의', '▁관계', '회', '복을', '▁위해', '▁진지', '하게', '▁얘', '기', '하려', '▁하', '시는', '▁군', '요.', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁무기력', '<sys>', '▁평소', '에는', '▁아무', '렇', '지도', '▁않던', '▁일', '들이', '▁귀', '찮', '게', '▁느껴', '지나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불안', '<sys>', '▁동생', '과의', '▁관계', '회', '복을', '▁위해', '▁진지', '하게', '▁얘', '기', '하려', '▁하', '시는', '▁군', '요.', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁불안', '<sys>', '▁불안', '감을', '▁느끼고', '▁계', '시는', '군', '요.', '▁', '00', '님이', '▁불안', '감으로', '▁많이', '▁힘', '드', '신', '▁건', '▁아닌', '지', '▁걱', '정이', '▁돼']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁무기력', '<sys>', '▁평소', '에는', '▁아무', '렇', '지도', '▁않던', '▁일', '들이', '▁귀', '찮', '게', '▁느껴', '지나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁생활', '<sys>', '▁당신의', '▁이야기가', '▁더', '▁듣고', '▁싶어', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불안', '<sys>', '▁불안', '감을', '▁느끼고', '▁계', '시는', '군', '요.', '▁', '00', '님이', '▁불안', '감으로', '▁많이', '▁힘', '드', '신', '▁건', '▁아닌', '지', '▁걱', '정이', '▁돼']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁생활', '<sys>', '▁당신의', '▁이야기가', '▁더', '▁듣고', '▁싶어', '요.', '</s>']\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 19, global step 109976: train_loss reached 10.83381 (best 10.83381), saving model to \"/content/drive/MyDrive/KoGPT2/checkpoint/3rd learning/model_-epoch=19-train_loss=10.83.ckpt\" as top 1\n","INFO:root:contexts : 내일 학교에 가서 선생님께 말씀드리면 해결될 거야. 그 아이들이 꼭 반성했으면 좋겠어.\n","INFO:root:contexts : 그냥 되게 자잘하게 걱정이 많아.\n","INFO:root:contexts : 불면증 때문에 그런지 힘이 없다\n","INFO:root:contexts : 아무리 떨쳐내려고 해도 사람들이 나를 무시하는 시선에서 못 벗어나겠어.\n","INFO:root:toked ctx: ['<usr>', '▁내', '일', '▁학교에', '▁가서', '▁선생', '님', '께', '▁말씀', '드리', '면', '▁해결', '될', '▁거', '야', '.', '▁그', '▁아이들이', '▁꼭', '▁반성', '했', '으면', '▁좋', '겠', '어', '.']\n","INFO:root:toked ctx: ['<usr>', '▁그냥', '▁되게', '▁자', '잘', '하게', '▁걱', '정이', '▁많아', '.']\n","INFO:root:toked ctx: ['<usr>', '▁불면', '증', '▁때문에', '▁그런', '지', '▁힘이', '▁없', '다']\n","INFO:root:response : 선생님께 도움을 요청할 생각이시군요.\n","INFO:root:response : 하루종일 잠만 자게 되시나요?\n","INFO:root:response : 전과 다르게 일상생활이 불만스럽고 싫증나시나요?\n","INFO:root:toked response : ['<unused1>', '▁분노', '<sys>', '▁선생', '님', '께']\n","INFO:root:toked ctx: ['<usr>', '▁아무리', '▁떨쳐', '내', '려고', '▁해도', '▁사람들이', '▁나를', '▁무시', '하는', '▁시', '선에서', '▁못', '▁벗어나', '겠', '어', '.']\n","INFO:root:toked response : ['<unused1>', '▁초', '조', '함', '<sys>', '▁전과', '▁다르게', '▁일상생활', '이', '▁불만', '스럽고', '▁싫', '증', '나', '시나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁분노', '<sys>', '▁선생', '님', '께']\n","INFO:root:response : 자존감이 떨어져 속상하고 고민이 많이 드셨겠어요.\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁초', '조', '함', '<sys>', '▁전과', '▁다르게', '▁일상생활', '이', '▁불만', '스럽고', '▁싫', '증', '나', '시나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁불면', '<sys>', '▁하루', '종', '일', '▁잠', '만', '▁자', '게', '▁되', '시나', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁자존', '감', '저', '하', '<sys>', '▁자존', '감이', '▁떨어져', '▁속', '상', '하고', '▁고', '민이', '▁많이']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁불면', '<sys>', '▁하루', '종', '일', '▁잠', '만', '▁자', '게', '▁되', '시나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁자존', '감', '저', '하', '<sys>', '▁자존', '감이', '▁떨어져', '▁속', '상', '하고', '▁고', '민이', '▁많이']\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 20, step 124972: train_loss was not in top 1\n","INFO:root:contexts : 마음속에 쌓이는 게 너무 많아\n","INFO:root:contexts : 너무 기죽는다\n","INFO:root:contexts : 계속 이러니까 자존감이 바닥나는 것 같아요.\n","INFO:root:toked ctx: ['<usr>', '▁너무', '▁기', '죽', '는', '다']\n","INFO:root:contexts : 먹통이야 답답하다\n","INFO:root:toked ctx: ['<usr>', '▁계속', '▁이러', '니까', '▁자존', '감이', '▁바닥', '나는', '▁것', '▁같아', '요.']\n","INFO:root:response : 무엇을 먹을 지 정할 수 없을 만큼 결정이 어려우신가요?\n","INFO:root:toked ctx: ['<usr>', '▁먹', '통이', '야', '▁답', '답', '하다']\n","INFO:root:toked response : ['<unused1>', '▁자신', '감', '저', '하', '<sys>', '▁무엇을', '▁먹을', '▁지', '▁정할', '▁수', '▁없을', '▁만큼', '▁결정이', '▁어려우', '신', '가', '요', '?', '</s>']\n","INFO:root:response : 사람들이 나에게 차갑게 대하는 것 같으신가요?\n","INFO:root:response : 대화의 눈높이가 맞는 사람 만나세요.\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁자신', '감', '저', '하', '<sys>', '▁무엇을', '▁먹을', '▁지', '▁정할', '▁수', '▁없을', '▁만큼', '▁결정이', '▁어려우', '신', '가', '요', '?', '</s>']\n","INFO:root:toked response : ['<unused1>', '▁일상', '<sys>', '▁대', '화의', '▁눈', '높', '이가', '▁맞는', '▁사람', '▁만나', '세', '요.', '</s>']\n","INFO:root:toked ctx: ['<usr>', '▁마음', '속에', '▁쌓', '이는', '▁게', '▁너무', '▁많아']\n","INFO:root:toked response : ['<unused1>', '▁자존', '감', '저', '하', '<sys>', '▁사람들이', '▁나에게', '▁차', '갑', '게', '▁대하는', '▁것', '▁같', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁일상', '<sys>', '▁대', '화의', '▁눈', '높', '이가', '▁맞는', '▁사람', '▁만나', '세', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁자존', '감', '저', '하', '<sys>', '▁사람들이', '▁나에게', '▁차', '갑', '게', '▁대하는', '▁것', '▁같', '으', '신', '가', '요', '?', '</s>']\n","INFO:root:response : 갑자기 울음이 나오나요?\n","INFO:root:toked response : ['<unused1>', '▁슬픔', '<sys>', '▁갑자기', '▁울', '음이', '▁나오', '나', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁슬픔', '<sys>', '▁갑자기', '▁울', '음이', '▁나오', '나', '요', '?', '</s>']\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 21, step 139968: train_loss was not in top 1\n","INFO:root:contexts : 나 살이 6kg나 빠졌어. 일부러 뺀 건 아니고.\n","INFO:root:contexts : 아무도 날 알아주지 않아.\n","INFO:root:contexts : 요즘 너무 사는 게 힘들어서 자주 드러눕게 돼\n","INFO:root:contexts : 많이 베풀어야겠지. 밥도 더 사고 만나자고 전화도 하고. 동호회도 들고.\n","INFO:root:toked ctx: ['<usr>', '▁나', '▁살이', '▁6', 'kg', '나', '▁빠', '졌', '어', '.', '▁일부러', '▁뺀', '▁건', '▁아니고', '.']\n","INFO:root:toked ctx: ['<usr>', '▁아무도', '▁날', '▁알아', '주지', '▁않아', '.']\n","INFO:root:toked ctx: ['<usr>', '▁요즘', '▁너무', '▁사는', '▁게', '▁힘들어', '서', '▁자주', '▁드러', '눕', '게', '▁돼']\n","INFO:root:toked ctx: ['<usr>', '▁많이', '▁베풀', '어야', '겠', '지', '.', '▁밥', '도', '▁더', '▁사고', '▁만나', '자고', '▁전화', '도', '▁하고', '.', '▁동호', '회도', '▁들고', '.']\n","INFO:root:response : 식사를 못 하고 계시다니 정말 큰일이에요.\n","INFO:root:response : 오늘 마음이 외로우시군요. 저와 이야기하며 조금이나마 나아지셨으면 좋겠어요.\n","INFO:root:response : 이유없이 피로하고 무기력하신가요?\n","INFO:root:toked response : ['<unused1>', '▁외로', '움', '<sys>', '▁오늘', '▁마음이', '▁외로', '우', '시', '군', '요.', '▁저', '와', '▁이야기', '하며', '▁조금', '이나', '마', '▁나아', '지', '셨', '으면', '▁좋', '겠', '어']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁외로', '움', '<sys>', '▁오늘', '▁마음이', '▁외로', '우', '시', '군', '요.', '▁저', '와', '▁이야기', '하며', '▁조금', '이나', '마', '▁나아', '지', '셨', '으면', '▁좋', '겠', '어']\n","INFO:root:toked response : ['<unused1>', '▁피로', '<sys>', '▁이유', '없이', '▁피로', '하고', '▁무기력', '하신', '가', '요', '?', '</s>']\n","INFO:root:response : 동호회 활동을 통해서 좋은 사람을 많이 사귀시길 바라요.\n","INFO:root:toked response : ['<unused1>', '▁분노', '<sys>', '▁동호', '회', '▁활동을', '▁통해서', '▁좋은', '▁사람을', '▁많이', '▁사귀']\n","INFO:root:toked response : ['<unused1>', '▁식욕', '저', '하', '<sys>', '▁식사를', '▁못', '▁하고', '▁계시', '다니', '▁정말', '▁큰', '일', '이에', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁피로', '<sys>', '▁이유', '없이', '▁피로', '하고', '▁무기력', '하신', '가', '요', '?', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁식욕', '저', '하', '<sys>', '▁식사를', '▁못', '▁하고', '▁계시', '다니', '▁정말', '▁큰', '일', '이에', '요.', '</s>']\n","INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁분노', '<sys>', '▁동호', '회', '▁활동을', '▁통해서', '▁좋은', '▁사람을', '▁많이', '▁사귀']\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-2-76a7cdb4e67d>:200: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","INFO:pytorch_lightning.utilities.distributed:Epoch 22, global step 154964: train_loss reached 10.77109 (best 10.77109), saving model to \"/content/drive/MyDrive/KoGPT2/checkpoint/3rd learning/model_-epoch=22-train_loss=10.77.ckpt\" as top 1\n","INFO:pytorch_lightning.utilities.distributed:Saving latest checkpoint...\n","INFO:root:best model path /content/drive/MyDrive/KoGPT2/checkpoint/3rd learning/model_-epoch=22-train_loss=10.77.ckpt\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAArMAAAK9CAYAAAA37eRrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACTIElEQVR4nOzdeVyN6f8/8NdpO5WUJG1SJISESsOMPZMtMsaSpbIOgxAzWUNmNIMZ2c0YwpB1aMwHkTC2xpZMxjKWlK1s04qWc+7fH37dX0frSXU6vJ6Px3mMc93Xfd/v+5zMvObquq9bIgiCACIiIiIiNaSh6gKIiIiIiMqKYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothlogK8PPzg62tbZn2nTdvHiQSSfkWVMXcvXsXEokEGzdurPRzSyQSzJs3T3y/ceNGSCQS3L17t8R9bW1t4efnV671vMvPChFReWCYJVIjEomkVK/jx4+rutQPnr+/PyQSCW7dulVkn1mzZkEikeDvv/+uxMqU9/DhQ8ybNw9xcXGqLqVQ165dg0Qiga6uLlJTU1VdDhFVMoZZIjXy66+/Kry6du1aaLuDg8M7nWfdunW4ceNGmfadPXs2Xr58+U7nfx8MGTIEABAeHl5kn23btsHR0RHNmzcv83mGDRuGly9fwsbGpszHKMnDhw8xf/78QsPsu/yslJctW7bA3NwcALB7926V1kJElU9L1QUQUekNHTpU4f1ff/2FqKioAu1ve/HiBfT19Ut9Hm1t7TLVBwBaWlrQ0uK/Wtzc3NCgQQNs27YNQUFBBbbHxMQgISEB33333TudR1NTE5qamu90jHfxLj8r5UEQBISHh2Pw4MFISEjA1q1bMWrUKJXWVJSsrCxUq1ZN1WUQvXc4Mkv0nunYsSOaNWuGixcvon379tDX18fMmTMBAL///jt69uwJS0tLSKVS2NnZYcGCBZDJZArHeHseZP4c0SVLluDnn3+GnZ0dpFIpXF1dcf78eYV9C5szK5FIMGHCBERERKBZs2aQSqVo2rQpIiMjC9R//PhxuLi4QFdXF3Z2dvjpp59KPQ/35MmT6N+/P+rWrQupVApra2tMmTKlwEixn58fDAwM8ODBA3h5ecHAwACmpqaYNm1agc8iNTUVfn5+MDIyQo0aNeDr61vqX2UPGTIE169fR2xsbIFt4eHhkEgk8Pb2Rk5ODoKCguDs7AwjIyNUq1YN7dq1w7Fjx0o8R2FzZgVBwDfffIM6depAX18fnTp1wj///FNg3+fPn2PatGlwdHSEgYEBDA0N0b17d1y+fFnsc/z4cbi6ugIAhg8fLk5lyZ8vXNic2aysLEydOhXW1taQSqVo1KgRlixZAkEQFPop83NRlNOnT+Pu3bsYNGgQBg0ahBMnTuD+/fsF+snlcixbtgyOjo7Q1dWFqakpunXrhgsXLij027JlC1q3bg19fX0YGxujffv2OHz4sELNb85Zzvf2fOT87+XPP//El19+idq1a6NOnToAgMTERHz55Zdo1KgR9PT0YGJigv79+xc67zk1NRVTpkyBra0tpFIp6tSpAx8fHzx9+hSZmZmoVq0aJk2aVGC/+/fvQ1NTEyEhIaX8JInUF4dPiN5Dz549Q/fu3TFo0CAMHToUZmZmAF7/B9bAwAABAQEwMDDA0aNHERQUhPT0dCxevLjE44aHhyMjIwNffPEFJBIJFi1ahM8++wx37twpcYTu1KlT2LNnD7788ktUr14dy5cvR79+/ZCUlAQTExMAwKVLl9CtWzdYWFhg/vz5kMlkCA4Ohqmpaamue9euXXjx4gXGjRsHExMTnDt3DitWrMD9+/exa9cuhb4ymQweHh5wc3PDkiVLcOTIEfzwww+ws7PDuHHjALwOhX369MGpU6cwduxYODg4YO/evfD19S1VPUOGDMH8+fMRHh6OVq1aKZx7586daNeuHerWrYunT5/il19+gbe3N0aPHo2MjAysX78eHh4eOHfuHFq0aFGq8+ULCgrCN998gx49eqBHjx6IjY3Fp59+ipycHIV+d+7cQUREBPr374969eohJSUFP/30Ezp06ICrV6/C0tISDg4OCA4ORlBQEMaMGYN27doBANq2bVvouQVBQO/evXHs2DGMHDkSLVq0wKFDh/DVV1/hwYMHWLp0qUL/0vxcFGfr1q2ws7ODq6srmjVrBn19fWzbtg1fffWVQr+RI0di48aN6N69O0aNGoW8vDycPHkSf/31F1xcXAAA8+fPx7x589C2bVsEBwdDR0cHZ8+exdGjR/Hpp5+W+vN/05dffglTU1MEBQUhKysLAHD+/HmcOXMGgwYNQp06dXD37l2sWbMGHTt2xNWrV8XfomRmZqJdu3a4du0aRowYgVatWuHp06fYt28f7t+/jxYtWqBv377YsWMHfvzxR4UR+m3btkEQBHG6C9F7TSAitTV+/Hjh7b/GHTp0EAAIa9euLdD/xYsXBdq++OILQV9fX3j16pXY5uvrK9jY2IjvExISBACCiYmJ8Pz5c7H9999/FwAIf/zxh9g2d+7cAjUBEHR0dIRbt26JbZcvXxYACCtWrBDbPD09BX19feHBgwdi282bNwUtLa0CxyxMYdcXEhIiSCQSITExUeH6AAjBwcEKfVu2bCk4OzuL7yMiIgQAwqJFi8S2vLw8oV27dgIAISwsrMSaXF1dhTp16ggymUxsi4yMFAAIP/30k3jM7Oxshf3+++8/wczMTBgxYoRCOwBh7ty54vuwsDABgJCQkCAIgiA8fvxY0NHREXr27CnI5XKx38yZMwUAgq+vr9j26tUrhboE4fV3LZVKFT6b8+fPF3m9b/+s5H9m33zzjUK/zz//XJBIJAo/A6X9uShKTk6OYGJiIsyaNUtsGzx4sODk5KTQ7+jRowIAwd/fv8Ax8j+jmzdvChoaGkLfvn0LfCZvfo5vf/75bGxsFD7b/O/lk08+EfLy8hT6FvZzGhMTIwAQNm/eLLYFBQUJAIQ9e/YUWfehQ4cEAMLBgwcVtjdv3lzo0KFDgf2I3kecZkD0HpJKpRg+fHiBdj09PfHPGRkZePr0Kdq1a4cXL17g+vXrJR534MCBMDY2Ft/nj9LduXOnxH3d3d1hZ2cnvm/evDkMDQ3FfWUyGY4cOQIvLy9YWlqK/Ro0aIDu3buXeHxA8fqysrLw9OlTtG3bFoIg4NKlSwX6jx07VuF9u3btFK7lwIED0NLSEkdqgddzVCdOnFiqeoDX85zv37+PEydOiG3h4eHQ0dFB//79xWPq6OgAeP3r8OfPnyMvLw8uLi6FTlEozpEjR5CTk4OJEycqTM2YPHlygb5SqRQaGq//MyCTyfDs2TMYGBigUaNGSp8334EDB6CpqQl/f3+F9qlTp0IQBBw8eFChvaSfi+IcPHgQz549g7e3t9jm7e2Ny5cvK0yr+O233yCRSDB37twCx8j/jCIiIiCXyxEUFCR+Jm/3KYvRo0cXmNP85s9pbm4unj17hgYNGqBGjRoKn/tvv/0GJycn9O3bt8i63d3dYWlpia1bt4rbrly5gr///rvEufRE7wuGWaL3kJWVlRiO3vTPP/+gb9++MDIygqGhIUxNTcX/4KWlpZV43Lp16yq8zw+2//33n9L75u+fv+/jx4/x8uVLNGjQoEC/wtoKk5SUBD8/P9SsWVOcB9uhQwcABa8vf95kUfUAr+c2WlhYwMDAQKFfo0aNSlUPAAwaNAiampriqgavXr3C3r170b17d4X/Mdi0aROaN28OXV1dmJiYwNTUFPv37y/V9/KmxMREAIC9vb1Cu6mpqcL5gNfBeenSpbC3t4dUKkWtWrVgamqKv//+W+nzvnl+S0tLVK9eXaE9f4WN/PrylfRzUZwtW7agXr16kEqluHXrFm7dugU7Ozvo6+srhLvbt2/D0tISNWvWLPJYt2/fhoaGBpo0aVLieZVRr169Am0vX75EUFCQOKc4/3NPTU1V+Nxv376NZs2aFXt8DQ0NDBkyBBEREXjx4gWA11MvdHV1xf9ZInrfMcwSvYfeHPnJl5qaig4dOuDy5csIDg7GH3/8gaioKHz//fcAXgebkhR117zw1o095b1vachkMnTt2hX79+9HYGAgIiIiEBUVJd6o9Pb1VdYKALVr10bXrl3x22+/ITc3F3/88QcyMjIU5jJu2bIFfn5+sLOzw/r16xEZGYmoqCh07ty5VN9LWS1cuBABAQFo3749tmzZgkOHDiEqKgpNmzat0PO+qaw/F+np6fjjjz+QkJAAe3t78dWkSRO8ePEC4eHh5fazVRpv3ziYr7C/ixMnTsS3336LAQMGYOfOnTh8+DCioqJgYmJSps/dx8cHmZmZiIiIEFd36NWrF4yMjJQ+FpE64g1gRB+I48eP49mzZ9izZw/at28vtickJKiwqv9Tu3Zt6OrqFvqQgeIePJAvPj4e//77LzZt2gQfHx+xPSoqqsw12djYIDo6GpmZmQqjs8quqzpkyBBERkbi4MGDCA8Ph6GhITw9PcXtu3fvRv369bFnzx6FX2kX9mvx0tQMADdv3kT9+vXF9idPnhQY7dy9ezc6deqE9evXK7SnpqaiVq1a4ntlfs1uY2ODI0eOICMjQ2F0Nn8aS3mth7tnzx68evUKa9asUagVeP39zJ49G6dPn8Ynn3wCOzs7HDp0CM+fPy9ydNbOzg5yuRxXr14t9oY7Y2PjAqtZ5OTk4NGjR6Wufffu3fD19cUPP/wgtr169arAce3s7HDlypUSj9esWTO0bNkSW7duRZ06dZCUlIQVK1aUuh4idceRWaIPRP4I2JujVTk5OVi9erWqSlKgqakJd3d3RERE4OHDh2L7rVu3CsyzLGp/QPH6BEHAsmXLylxTjx49kJeXhzVr1ohtMplM6aDg5eUFfX19rF69GgcPHsRnn30GXV3dYms/e/YsYmJilK7Z3d0d2traWLFihcLxQkNDC/TV1NQsMHq5a9cuPHjwQKEtf23U0ixJ1qNHD8hkMqxcuVKhfenSpZBIJKWe/1ySLVu2oH79+hg7diw+//xzhde0adNgYGAgTjXo168fBEHA/PnzCxwn//q9vLygoaGB4ODgAqOjb35GdnZ2CvOfAeDnn38ucmS2MIV97itWrChwjH79+uHy5cvYu3dvkXXnGzZsGA4fPozQ0FCYmJiU2+dMpA44Mkv0gWjbti2MjY3h6+srPmr1119/rdRfxZZk3rx5OHz4MD7++GOMGzdODEXNmjUr8VGqjRs3hp2dHaZNm4YHDx7A0NAQv/32W6nmXhbF09MTH3/8MaZPn467d++iSZMm2LNnj9LzSQ0MDODl5SXOm317uaRevXphz5496Nu3L3r27ImEhASsXbsWTZo0QWZmplLnyl8vNyQkBL169UKPHj1w6dIlHDx4sMAIZq9evRAcHIzhw4ejbdu2iI+Px9atWxVGdIHXAa5GjRpYu3YtqlevjmrVqsHNza3Q+aCenp7o1KkTZs2ahbt378LJyQmHDx/G77//jsmTJyvc7FVWDx8+xLFjxwrcZJZPKpXCw8MDu3btwvLly9GpUycMGzYMy5cvx82bN9GtWzfI5XKcPHkSnTp1woQJE9CgQQPMmjULCxYsQLt27fDZZ59BKpXi/PnzsLS0FNdrHTVqFMaOHYt+/fqha9euuHz5Mg4dOlTgsy1Or1698Ouvv8LIyAhNmjRBTEwMjhw5UmApsq+++gq7d+9G//79MWLECDg7O+P58+fYt28f1q5dCycnJ7Hv4MGD8fXXX2Pv3r0YN26cyh9mQVSZODJL9IEwMTHB//73P1hYWGD27NlYsmQJunbtikWLFqm6NJGzszMOHjwIY2NjzJkzB+vXr0dwcDC6dOmiMJJZGG1tbfzxxx9o0aIFQkJCMH/+fNjb22Pz5s1lrkdDQwP79u3DkCFDsGXLFsyaNQtWVlbYtGmT0sfKD7AWFhbo3LmzwjY/Pz8sXLgQly9fhr+/Pw4dOoQtW7aI658q65tvvsH8+fNx6dIlfPXVV7h9+zYOHz5c4OlTM2fOxNSpU3Ho0CFMmjQJsbGx2L9/P6ytrRX6aWtrY9OmTdDU1MTYsWPh7e2NP//8s9Bz539mkydPxv/+9z9MnjwZV69exeLFi/Hjjz+W6Xretn37dsjlcoWpGm/z9PTEs2fPxFH9sLAwLF68GAkJCfjqq6+wcOFCvHz5UmG93ODgYGzYsAEvX77ErFmzEBQUhMTERHTp0kXsM3r0aAQGBuLEiROYOnUqEhISEBUVpdSTvZYtWwYfHx9s3boVU6dOxaNHj3DkyJECNxoaGBjg5MmTGDduHA4cOAB/f3+sXr0ajRo1Eh/AkM/MzExcC3fYsGGlroXofSARqtKwDBFRIby8vPDPP//g5s2bqi6FqMrq27cv4uPjSzXHnOh9wpFZIqpS3n707M2bN3HgwAF07NhRNQURqYFHjx5h//79HJWlDxJHZomoSrGwsICfnx/q16+PxMRErFmzBtnZ2bh06VKBtVOJPnQJCQk4ffo0fvnlF5w/fx63b9+Gubm5qssiqlS8AYyIqpRu3bph27ZtSE5OhlQqRZs2bbBw4UIGWaJC/Pnnnxg+fDjq1q2LTZs2McjSB0mlI7MnTpzA4sWLcfHiRTx69Ah79+6Fl5dXsfscP34cAQEB+Oeff2BtbY3Zs2fDz8+vUuolIiIioqpFpXNms7Ky4OTkhFWrVpWqf0JCAnr27IlOnTohLi4OkydPxqhRo3Do0KEKrpSIiIiIqqIqM2dWIpGUODIbGBiI/fv3KzwRZdCgQUhNTUVkZGQlVElEREREVYlazZmNiYmBu7u7QpuHhwcmT55c5D7Z2dnIzs4W38vlcjx//hwmJiZKPaKRiIiIiCqHIAjIyMiApaUlNDSKn0igVmE2OTkZZmZmCm1mZmZIT0/Hy5cvoaenV2Cf/MXTiYiIiEi93Lt3r8BDQt6mVmG2LGbMmIGAgADxfVpaGurWrYt79+7B0NBQhZURERERUWHS09NhbW2N6tWrl9hXrcKsubk5UlJSFNpSUlJgaGhY6Kgs8PoZ3VKptEC7oaEhwywRERFRFVaaKaFq9QSwNm3aIDo6WqEtKioKbdq0UVFFRERERKRKKg2zmZmZiIuLQ1xcHIDXS2/FxcUhKSkJwOspAj4+PmL/sWPH4s6dO/j6669x/fp1rF69Gjt37sSUKVNUUT4RERERqZhKw+yFCxfQsmVLtGzZEgAQEBCAli1bIigoCMDrZ03nB1sAqFevHvbv34+oqCg4OTnhhx9+wC+//AIPDw+V1E9EREREqlVl1pmtLOnp6TAyMkJaWhrnzBIRERFVQcrkNbWaM0tERERE9CaGWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsqD7OrVq2Cra0tdHV14ebmhnPnzhXbPzQ0FI0aNYKenh6sra0xZcoUvHr1qpKqJSIiIqKqRKVhdseOHQgICMDcuXMRGxsLJycneHh44PHjx4X2Dw8Px/Tp0zF37lxcu3YN69evx44dOzBz5sxKrpyIiIiIqgKVhtkff/wRo0ePxvDhw9GkSROsXbsW+vr62LBhQ6H9z5w5g48//hiDBw+Gra0tPv30U3h7e5c4mktERERE7yeVhdmcnBxcvHgR7u7u/1eMhgbc3d0RExNT6D5t27bFxYsXxfB6584dHDhwAD169CjyPNnZ2UhPT1d4EREREdH7QUtVJ3769ClkMhnMzMwU2s3MzHD9+vVC9xk8eDCePn2KTz75BIIgIC8vD2PHji12mkFISAjmz59frrUTERERUdWg8hvAlHH8+HEsXLgQq1evRmxsLPbs2YP9+/djwYIFRe4zY8YMpKWlia979+5VYsVEREREVJFUNjJbq1YtaGpqIiUlRaE9JSUF5ubmhe4zZ84cDBs2DKNGjQIAODo6IisrC2PGjMGsWbOgoVEwm0ulUkil0vK/ACIiIiJSOZWNzOro6MDZ2RnR0dFim1wuR3R0NNq0aVPoPi9evCgQWDU1NQEAgiBUXLFEREREVCWpbGQWAAICAuDr6wsXFxe0bt0aoaGhyMrKwvDhwwEAPj4+sLKyQkhICADA09MTP/74I1q2bAk3NzfcunULc+bMgaenpxhqiYiIiOjDodIwO3DgQDx58gRBQUFITk5GixYtEBkZKd4UlpSUpDASO3v2bEgkEsyePRsPHjyAqakpPD098e2336rqEoiIiIhIhSTCB/b7+fT0dBgZGSEtLQ2GhoaqLoeIiIiI3qJMXlOr1QyIiIiIiN7EMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGpL5WF21apVsLW1ha6uLtzc3HDu3Lli+6empmL8+PGwsLCAVCpFw4YNceDAgUqqloiIiIiqEi1VnnzHjh0ICAjA2rVr4ebmhtDQUHh4eODGjRuoXbt2gf45OTno2rUrateujd27d8PKygqJiYmoUaNG5RdPRERERConEQRBUNXJ3dzc4OrqipUrVwIA5HI5rK2tMXHiREyfPr1A/7Vr12Lx4sW4fv06tLW1y3TO9PR0GBkZIS0tDYaGhu9UPxERERGVP2XymsqmGeTk5ODixYtwd3f/v2I0NODu7o6YmJhC99m3bx/atGmD8ePHw8zMDM2aNcPChQshk8mKPE92djbS09MVXkRERET0flBZmH369ClkMhnMzMwU2s3MzJCcnFzoPnfu3MHu3bshk8lw4MABzJkzBz/88AO++eabIs8TEhICIyMj8WVtbV2u10FEREREqqPyG8CUIZfLUbt2bfz8889wdnbGwIEDMWvWLKxdu7bIfWbMmIG0tDTxde/evUqsmIiIiIgqkspuAKtVqxY0NTWRkpKi0J6SkgJzc/NC97GwsIC2tjY0NTXFNgcHByQnJyMnJwc6OjoF9pFKpZBKpeVbPBERERFVCSobmdXR0YGzszOio6PFNrlcjujoaLRp06bQfT7++GPcunULcrlcbPv3339hYWFRaJAlIiIiovebSqcZBAQEYN26ddi0aROuXbuGcePGISsrC8OHDwcA+Pj4YMaMGWL/cePG4fnz55g0aRL+/fdf7N+/HwsXLsT48eNVdQlEREREpEJKTzOwtbXFiBEj4Ofnh7p1677TyQcOHIgnT54gKCgIycnJaNGiBSIjI8WbwpKSkqCh8X9529raGocOHcKUKVPQvHlzWFlZYdKkSQgMDHynOoiIiIhIPSm9zmxoaCg2btyIK1euoFOnThg5ciT69u2rNvNSuc4sERERUdVWoevMTp48GXFxcTh37hwcHBwwceJEWFhYYMKECYiNjS1z0UREREREynrnJ4Dl5uZi9erVCAwMRG5uLhwdHeHv74/hw4dDIpGUV53lhiOzRERERFWbMnmtzEtz5ebmYu/evQgLC0NUVBQ++ugjjBw5Evfv38fMmTNx5MgRhIeHl/XwREREREQlUjrMxsbGIiwsDNu2bYOGhgZ8fHywdOlSNG7cWOzTt29fuLq6lmuhRERERERvUzrMurq6omvXrlizZg28vLygra1doE+9evUwaNCgcimQiIiIiKgoSofZO3fuwMbGptg+1apVQ1hYWJmLIiIiIiIqDaVXM3j8+DHOnj1boP3s2bO4cOFCuRRFRERERFQaSofZ8ePH4969ewXaHzx4wCdxEREREVGlUjrMXr16Fa1atSrQ3rJlS1y9erVciiIiIiIiKg2lw6xUKkVKSkqB9kePHkFLq8wrfRERERERKU3pMPvpp59ixowZSEtLE9tSU1Mxc+ZMdO3atVyLIyIiIiIqjtJDqUuWLEH79u1hY2ODli1bAgDi4uJgZmaGX3/9tdwLJCIiIiIqitJh1srKCn///Te2bt2Ky5cvQ09PD8OHD4e3t3eha84SEREREVWUMk1yrVatGsaMGVPetRARERERKaXMd2xdvXoVSUlJyMnJUWjv3bv3OxdFRERERFQaZXoCWN++fREfHw+JRAJBEAAAEokEACCTycq3QiIiIiKiIii9msGkSZNQr149PH78GPr6+vjnn39w4sQJuLi44Pjx4xVQIhERERFR4ZQemY2JicHRo0dRq1YtaGhoQENDA5988glCQkLg7++PS5cuVUSdREREREQFKD0yK5PJUL16dQBArVq18PDhQwCAjY0Nbty4Ub7VEREREREVQ+mR2WbNmuHy5cuoV68e3NzcsGjRIujo6ODnn39G/fr1K6JGIiIiIqJCKR1mZ8+ejaysLABAcHAwevXqhXbt2sHExAQ7duwo9wKJiIiIiIoiEfKXI3gHz58/h7GxsbiiQVWWnp4OIyMjpKWlwdDQUNXlEBEREdFblMlrSs2Zzc3NhZaWFq5cuaLQXrNmTbUIskRERET0flEqzGpra6Nu3bpcS5aIiIiIqgSlVzOYNWsWZs6ciefPn1dEPUREREREpab0DWArV67ErVu3YGlpCRsbG1SrVk1he2xsbLkVR0RERERUHKXDrJeXVwWUQURERESkvHJZzUCdcDUDIiIioqqtwlYzICIiIiKqSpSeZqChoVHsMlxc6YCIiIiIKovSYXbv3r0K73Nzc3Hp0iVs2rQJ8+fPL7fCiIiIiIhKUm5zZsPDw7Fjxw78/vvv5XG4CsM5s0RERERVm0rmzH700UeIjo4ur8MREREREZWoXMLsy5cvsXz5clhZWZXH4YiIiIiISkXpObPGxsYKN4AJgoCMjAzo6+tjy5Yt5VocEREREVFxlA6zS5cuVQizGhoaMDU1hZubG4yNjcu1OCIiIiKi4igdZv38/CqgDCIiIiIi5Sk9ZzYsLAy7du0q0L5r1y5s2rSpXIoiIiIiIioNpcNsSEgIatWqVaC9du3aWLhwYbkURURERERUGkqH2aSkJNSrV69Au42NDZKSksqlKCIiIiKi0lA6zNauXRt///13gfbLly/DxMSkXIoiIiIiIioNpcOst7c3/P39cezYMchkMshkMhw9ehSTJk3CoEGDKqJGIiIiIqJCKR1mFyxYADc3N3Tp0gV6enrQ09PDp59+is6dO5d5zuyqVatga2sLXV1duLm54dy5c6Xab/v27ZBIJPDy8irTeYmIiIhIvUkEQRDKsuPNmzcRFxcHPT09ODo6wsbGpkwF7NixAz4+Pli7di3c3NwQGhqKXbt24caNG6hdu3aR+929exeffPIJ6tevj5o1ayIiIqJU51PmWb9EREREVPmUyWtlDrPlxc3NDa6urli5ciUAQC6Xw9raGhMnTsT06dML3Ucmk6F9+/YYMWIETp48idTUVIZZIiIioveEMnlN6WkG/fr1w/fff1+gfdGiRejfv79Sx8rJycHFixfh7u7+fwVpaMDd3R0xMTFF7hccHIzatWtj5MiRJZ4jOzsb6enpCi8iIiIiej8oHWZPnDiBHj16FGjv3r07Tpw4odSxnj59CplMBjMzM4V2MzMzJCcnF7rPqVOnsH79eqxbt65U5wgJCYGRkZH4sra2VqpGIiIiIqq6lA6zmZmZ0NHRKdCura1d4aOeGRkZGDZsGNatW1fogxsKM2PGDKSlpYmve/fuVWiNRERERFR5tJTdwdHRETt27EBQUJBC+/bt29GkSROljlWrVi1oamoiJSVFoT0lJQXm5uYF+t++fRt3796Fp6en2CaXywEAWlpauHHjBuzs7BT2kUqlkEqlStVFREREROpB6TA7Z84cfPbZZ7h9+zY6d+4MAIiOjkZ4eDh2796t1LF0dHTg7OyM6OhocXktuVyO6OhoTJgwoUD/xo0bIz4+XqFt9uzZyMjIwLJlyziFgIiIiOgDo3SY9fT0REREBBYuXIjdu3dDT08PTk5OOHr0KGrWrKl0AQEBAfD19YWLiwtat26N0NBQZGVlYfjw4QAAHx8fWFlZISQkBLq6umjWrJnC/jVq1ACAAu1ERERE9P5TOswCQM+ePdGzZ08Ar5dO2LZtG6ZNm4aLFy9CJpMpdayBAwfiyZMnCAoKQnJyMlq0aIHIyEjxprCkpCRoaCg9tZeIiIiIPgBlXmf2xIkTWL9+PX777TdYWlris88+Q79+/eDq6lreNZYrrjNLREREVLUpk9eUGplNTk7Gxo0bsX79eqSnp2PAgAHIzs5GRESE0jd/ERERERG9q1L//t7T0xONGjXC33//jdDQUDx8+BArVqyoyNqIiIiIiIpV6pHZgwcPwt/fH+PGjYO9vX1F1kREREREVCqlHpk9deoUMjIy4OzsDDc3N6xcuRJPnz6tyNqIiIiIiIpV6jD70UcfYd26dXj06BG++OILbN++HZaWlpDL5YiKikJGRkZF1klEREREVECZVzMAgBs3bmD9+vX49ddfkZqaiq5du2Lfvn3lWV+542oGRERERFWbMnntnRZwbdSoERYtWoT79+9j27Zt73IoIiIiIiKlvdPIrDriyCwRERFR1VZpI7NERERERKrEMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqq0qE2VWrVsHW1ha6urpwc3PDuXPniuy7bt06tGvXDsbGxjA2Noa7u3ux/YmIiIjo/aXyMLtjxw4EBARg7ty5iI2NhZOTEzw8PPD48eNC+x8/fhze3t44duwYYmJiYG1tjU8//RQPHjyo5MqJiIiISNUkgiAIqizAzc0Nrq6uWLlyJQBALpfD2toaEydOxPTp00vcXyaTwdjYGCtXroSPj0+J/dPT02FkZIS0tDQYGhq+c/1EREREVL6UyWsqHZnNycnBxYsX4e7uLrZpaGjA3d0dMTExpTrGixcvkJubi5o1axa6PTs7G+np6QovIiIiIno/qDTMPn36FDKZDGZmZgrtZmZmSE5OLtUxAgMDYWlpqRCI3xQSEgIjIyPxZW1t/c51ExEREVHVoPI5s+/iu+++w/bt27F3717o6uoW2mfGjBlIS0sTX/fu3avkKomIiIioomip8uS1atWCpqYmUlJSFNpTUlJgbm5e7L5LlizBd999hyNHjqB58+ZF9pNKpZBKpeVSLxERERFVLSodmdXR0YGzszOio6PFNrlcjujoaLRp06bI/RYtWoQFCxYgMjISLi4ulVEqEREREVVBKh2ZBYCAgAD4+vrCxcUFrVu3RmhoKLKysjB8+HAAgI+PD6ysrBASEgIA+P777xEUFITw8HDY2tqKc2sNDAxgYGCgsusgIiIiosqn8jA7cOBAPHnyBEFBQUhOTkaLFi0QGRkp3hSWlJQEDY3/G0Bes2YNcnJy8PnnnyscZ+7cuZg3b15llk5EREREKqbydWYrG9eZJSIiIqra1GadWSIiIiKid8EwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG2p/KEJREREVDiZTIbc3FxVl0FUIbS1taGpqfnOx2GYJSIiqoIyMzNx//59fGDPNqIPiEQiQZ06dWBgYPBOx2GYJSIiqmJkMhnu378PfX19mJqaQiKRqLokonIlCAKePHmC+/fvw97e/p1GaBlmiYiIqpjc3FwIggBTU1Po6empuhyiCmFqaoq7d+8iNzf3ncIsbwAjIiKqojgiS++z8vr5ZpglIiIiIrXFMEtEREREaothloiIiKosW1tbhIaGlrr/8ePHIZFIkJqaWmE1UdXCMEtERETvTCKRFPuaN29emY57/vx5jBkzptT927Zti0ePHsHIyKhM5yuLxo0bQyqVIjk5udLOSf+HYZaIiIje2aNHj8RXaGgoDA0NFdqmTZsm9hUEAXl5eaU6rqmpKfT19Utdh46ODszNzSvt5rlTp07h5cuX+Pzzz7Fp06ZKOWdxPsSHbDDMEhERVXGCIOBFTp5KXqV9aIO5ubn4MjIygkQiEd9fv34d1atXx8GDB+Hs7AypVIpTp07h9u3b6NOnD8zMzGBgYABXV1ccOXJE4bhvTzOQSCT45Zdf0LdvX+jr68Pe3h779u0Tt789zWDjxo2oUaMGDh06BAcHBxgYGKBbt2549OiRuE9eXh78/f1Ro0YNmJiYIDAwEL6+vvDy8irxutevX4/Bgwdj2LBh2LBhQ4Ht9+/fh7e3N2rWrIlq1arBxcUFZ8+eFbf/8ccfcHV1ha6uLmrVqoW+ffsqXGtERITC8WrUqIGNGzcCAO7evQuJRIIdO3agQ4cO0NXVxdatW/Hs2TN4e3vDysoK+vr6cHR0xLZt2xSOI5fLsWjRIjRo0ABSqRR169bFt99+CwDo3LkzJkyYoND/yZMn0NHRQXR0dImfSWXjOrNERERV3MtcGZoEHVLJua8Ge0Bfp3ziwvTp07FkyRLUr18fxsbGuHfvHnr06IFvv/0WUqkUmzdvhqenJ27cuIG6desWeZz58+dj0aJFWLx4MVasWIEhQ4YgMTERNWvWLLT/ixcvsGTJEvz666/Q0NDA0KFDMW3aNGzduhUA8P3332Pr1q0ICwuDg4MDli1bhoiICHTq1KnY68nIyMCuXbtw9uxZNG7cGGlpaTh58iTatWsH4PVT3Dp06AArKyvs27cP5ubmiI2NhVwuBwDs378fffv2xaxZs7B582bk5OTgwIEDZfpcf/jhB7Rs2RK6urp49eoVnJ2dERgYCENDQ+zfvx/Dhg2DnZ0dWrduDQCYMWMG1q1bh6VLl+KTTz7Bo0ePcP36dQDAqFGjMGHCBPzwww+QSqUAgC1btsDKygqdO3dWur6KxjBLRERElSI4OBhdu3YV39esWRNOTk7i+wULFmDv3r3Yt29fgZHBN/n5+cHb2xsAsHDhQixfvhznzp1Dt27dCu2fm5uLtWvXws7ODgAwYcIEBAcHi9tXrFiBGTNmiKOiK1euLFWo3L59O+zt7dG0aVMAwKBBg7B+/XoxzIaHh+PJkyc4f/68GLQbNGgg7v/tt99i0KBBmD9/vtj25udRWpMnT8Znn32m0PbmtI6JEyfi0KFD2LlzJ1q3bo2MjAwsW7YMK1euhK+vLwDAzs4On3zyCQDgs88+w4QJE/D7779jwIABAF6PcPv5+VXJtY8ZZomIiKo4PW1NXA32UNm5y4uLi4vC+8zMTMybNw/79+/Ho0ePkJeXh5cvXyIpKanY4zRv3lz8c7Vq1WBoaIjHjx8X2V9fX18MsgBgYWEh9k9LS0NKSoo4YgkAmpqacHZ2FkdQi7JhwwYMHTpUfD906FB06NABK1asQPXq1REXF4eWLVsWOWIcFxeH0aNHF3uO0nj7c5XJZFi4cCF27tyJBw8eICcnB9nZ2eLc42vXriE7OxtdunQp9Hi6urritIkBAwYgNjYWV65cUZjOUZUwzBIREVVxEomk3H7Vr0rVqlVTeD9t2jRERUVhyZIlaNCgAfT09PD5558jJyen2ONoa2srvJdIJMUGz8L6l3YucFGuXr2Kv/76C+fOnUNgYKDYLpPJsH37dowePbrERxGXtL2wOgu7wevtz3Xx4sVYtmwZQkND4ejoiGrVqmHy5Mni51qaRySPGjUKLVq0wP379xEWFobOnTvDxsamxP1UgTeAERERkUqcPn0afn5+6Nu3LxwdHWFubo67d+9Wag1GRkYwMzPD+fPnxTaZTIbY2Nhi91u/fj3at2+Py5cvIy4uTnwFBARg/fr1AF6PIMfFxeH58+eFHqN58+bF3lBlamqqcKPazZs38eLFixKv6fTp0+jTpw+GDh0KJycn1K9fH//++6+43d7eHnp6esWe29HRES4uLli3bh3Cw8MxYsSIEs+rKgyzREREpBL29vbYs2cP4uLicPnyZQwePLjEX+1XhIkTJyIkJAS///47bty4gUmTJuG///4rcn5obm4ufv31V3h7e6NZs2YKr1GjRuHs2bP4559/4O3tDXNzc3h5eeH06dO4c+cOfvvtN8TExAAA5s6di23btmHu3Lm4du0a4uPj8f3334vn6dy5M1auXIlLly7hwoULGDt2bIFR5sLY29sjKioKZ86cwbVr1/DFF18gJSVF3K6rq4vAwEB8/fXX2Lx5M27fvo2//vpLDOH5Ro0ahe+++w6CICisslDVMMwSERGRSvz4448wNjZG27Zt4enpCQ8PD7Rq1arS6wgMDIS3tzd8fHzQpk0bGBgYwMPDA7q6uoX237dvH549e1ZowHNwcICDgwPWr18PHR0dHD58GLVr10aPHj3g6OiI7777Dpqar+chd+zYEbt27cK+ffvQokULdO7cGefOnROP9cMPP8Da2hrt2rXD4MGDMW3atFKtuTt79my0atUKHh4e6Nixoxio3zRnzhxMnToVQUFBcHBwwMCBAwvMO/b29oaWlha8vb2L/CyqAonwrpNG1Ex6ejqMjIyQlpYGQ0NDVZdDRERUwKtXr5CQkIB69epV6RDxvpLL5XBwcMCAAQOwYMECVZejMnfv3oWdnR3Onz9fIf+TUdzPuTJ5Tf1nkxMRERG9g8TERBw+fBgdOnRAdnY2Vq5ciYSEBAwePFjVpalEbm4unj17htmzZ+Ojjz5SyWi5MjjNgIiIiD5oGhoa2LhxI1xdXfHxxx8jPj4eR44cgYODg6pLU4nTp0/DwsIC58+fx9q1a1VdTok4MktEREQfNGtra5w+fVrVZVQZHTt2fOelyyoTR2aJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiqjI6duyIyZMni+9tbW0RGhpa7D4SiQQRERHvfO7yOg5VLoZZIiIiemeenp7o1q1bodtOnjwJiUSCv//+W+njnj9/HmPGjHnX8hTMmzcPLVq0KND+6NEjdO/evVzPVZSXL1+iZs2aqFWrFrKzsyvlnO8rhlkiIiJ6ZyNHjkRUVBTu379fYFtYWBhcXFzQvHlzpY9ramoKfX398iixRObm5pBKpZVyrt9++w1NmzZF48aNVT4aLAgC8vLyVFrDu2CYJSIiquoEAcjJUs2rlE+C6tWrF0xNTbFx40aF9szMTOzatQsjR47Es2fP4O3tDSsrK+jr68PR0RHbtm0r9rhvTzO4efMm2rdvD11dXTRp0gRRUVEF9gkMDETDhg2hr6+P+vXrY86cOcjNzQUAbNy4EfPnz8fly5chkUggkUjEmt+eZhAfH4/OnTtDT08PJiYmGDNmDDIzM8Xtfn5+8PLywpIlS2BhYQETExOMHz9ePFdx1q9fj6FDh2Lo0KFYv359ge3//PMPevXqBUNDQ1SvXh3t2rXD7du3xe0bNmxA06ZNIZVKYWFhgQkTJgAA7t69C4lEgri4OLFvamoqJBIJjh8/DgA4fvw4JBIJDh48CGdnZ0ilUpw6dQq3b99Gnz59YGZmBgMDA7i6uuLIkSMKdWVnZyMwMBDW1taQSqVo0KAB1q9fD0EQ0KBBAyxZskShf1xcHCQSCW7dulXiZ1JWfJwtERFRVZf7AlhoqZpzz3wI6FQrsZuWlhZ8fHywceNGzJo1CxKJBACwa9cuyGQyeHt7IzMzE87OzggMDIShoSH279+PYcOGwc7ODq1bty7xHHK5HJ999hnMzMxw9uxZpKWlKcyvzVe9enVs3LgRlpaWiI+Px+jRo1G9enV8/fXXGDhwIK5cuYLIyEgxqBkZGRU4RlZWFjw8PNCmTRucP38ejx8/xqhRozBhwgSFwH7s2DFYWFjg2LFjuHXrFgYOHIgWLVpg9OjRRV7H7du3ERMTgz179kAQBEyZMgWJiYmwsbEBADx48ADt27dHx44dcfToURgaGuL06dPi6OmaNWsQEBCA7777Dt27d0daWlqZHsc7ffp0LFmyBPXr14exsTHu3buHHj164Ntvv4VUKsXmzZvh6emJGzduoG7dugAAHx8fxMTEYPny5XByckJCQgKePn0KiUSCESNGICwsDNOmTRPPERYWhvbt26NBgwZK11daDLNERERULkaMGIHFixfjzz//RMeOHQG8DjP9+vWDkZERjIyMFILOxIkTcejQIezcubNUYfbIkSO4fv06Dh06BEvL1+F+4cKFBea5zp49W/yzra0tpk2bhu3bt+Prr7+Gnp4eDAwMoKWlBXNz8yLPFR4ejlevXmHz5s2oVu11mF+5ciU8PT3x/fffw8zMDABgbGyMlStXQlNTE40bN0bPnj0RHR1dbJjdsGEDunfvDmNjYwCAh4cHwsLCMG/ePADAqlWrYGRkhO3bt0NbWxsA0LBhQ3H/b775BlOnTsWkSZPENldX1xI/v7cFBweja9eu4vuaNWvCyclJfL9gwQLs3bsX+/btw4QJE/Dvv/9i586diIqKgru7OwCgfv36Yn8/Pz8EBQXh3LlzaN26NXJzcxEeHl5gtLa8McwSERFVddr6r0dIVXXuUmrcuDHatm2LDRs2oGPHjrh16xZOnjyJ4OBgAIBMJsPChQuxc+dOPHjwADk5OcjOzi71nNhr167B2tpaDLIA0KZNmwL9duzYgeXLl+P27dvIzMxEXl4eDA0NS30d+edycnISgywAfPzxx5DL5bhx44YYZps2bQpNTU2xj4WFBeLj44s8rkwmw6ZNm7Bs2TKxbejQoZg2bRqCgoKgoaGBuLg4tGvXTgyyb3r8+DEePnyILl26KHU9hXFxcVF4n5mZiXnz5mH//v149OgR8vLy8PLlSyQlJQF4PWVAU1MTHTp0KPR4lpaW6NmzJzZs2IDWrVvjjz/+QHZ2Nvr37//OtRanSsyZXbVqFWxtbaGrqws3NzecO3eu2P67du1C48aNoaurC0dHRxw4cKCSKiUiIlIBieT1r/pV8fr/0wVKa+TIkfjtt9+QkZGBsLAw2NnZieFn8eLFWLZsGQIDA3Hs2DHExcXBw8MDOTk55fZRxcTEYMiQIejRowf+97//4dKlS5g1a1a5nuNNbwdOiUQCuVxeZP9Dhw7hwYMHGDhwILS0tKClpYVBgwYhMTER0dHRAAA9Pb0i9y9uGwBoaLyOdsIbc52LmsP7ZlAHgGnTpmHv3r1YuHAhTp48ibi4ODg6OoqfXUnnBoBRo0Zh+/btePnyJcLCwjBw4MAKv4FP5WF2x44dCAgIwNy5cxEbGwsnJyd4eHjg8ePHhfY/c+YMvL29MXLkSFy6dAleXl7w8vLClStXKrlyIiIietuAAQOgoaGB8PBwbN68GSNGjBDnz54+fRp9+vTB0KFD4eTkhPr16+Pff/8t9bEdHBxw7949PHr0SGz766+/FPqcOXMGNjY2mDVrFlxcXGBvb4/ExESFPjo6OpDJZCWe6/Lly8jKyhLbTp8+DQ0NDTRq1KjUNb9t/fr1GDRoEOLi4hRegwYNEm8Ea968OU6ePFloCK1evTpsbW3F4Ps2U1NTAFD4jN68Gaw4p0+fhp+fH/r27QtHR0eYm5vj7t274nZHR0fI5XL8+eefRR6jR48eqFatGtasWYPIyEiMGDGiVOd+FyoPsz/++CNGjx6N4cOHo0mTJli7di309fWxYcOGQvsvW7YM3bp1w1dffQUHBwcsWLAArVq1wsqVKyu5ciIiInqbgYEBBg4ciBkzZuDRo0fw8/MTt9nb2yMqKgpnzpzBtWvX8MUXXyAlJaXUx3Z3d0fDhg3h6+uLy5cv4+TJk5g1a5ZCH3t7eyQlJWH79u24ffs2li9fjr179yr0sbW1RUJCAuLi4vD06dNC13kdMmQIdHV14evriytXruDYsWOYOHEihg0bJk4xUNaTJ0/wxx9/wNfXF82aNVN4+fj4ICIiAs+fP8eECROQnp6OQYMG4cKFC7h58yZ+/fVX3LhxA8DrdXJ/+OEHLF++HDdv3kRsbCxWrFgB4PXo6UcffYTvvvsO165dw59//qkwh7g49vb22LNnD+Li4nD58mUMHjxYYZTZ1tYWvr6+GDFiBCIiIpCQkIDjx49j586dYh9NTU34+flhxowZsLe3L3QaSHlTaZjNycnBxYsXxUnEwOvhcXd3d8TExBS6T0xMjEJ/4PXE6aL6Z2dnIz09XeFFREREFWfkyJH477//4OHhoTC/dfbs2WjVqhU8PDzQsWNHmJubw8vLq9TH1dDQwN69e/Hy5Uu0bt0ao0aNwrfffqvQp3fv3pgyZQomTJiAFi1a4MyZM5gzZ45Cn379+qFbt27o1KkTTE1NC10eTF9fH4cOHcLz58/h6uqKzz//HF26dHmnwbP8m8kKm+/apUsX6OnpYcuWLTAxMcHRo0eRmZmJDh06wNnZGevWrROnNPj6+iI0NBSrV69G06ZN0atXL9y8eVM81oYNG5CXlwdnZ2dMnjwZ33zzTanq+/HHH2FsbIy2bdvC09MTHh4eaNWqlUKfNWvW4PPPP8eXX36Jxo0bY/To0Qqj18Dr7z8nJwfDhw9X9iMqE4kglHIBuQrw8OFDWFlZ4cyZMwrJ/euvv8aff/6Js2fPFthHR0cHmzZtgre3t9i2evVqzJ8/v9D/u5s3bx7mz59foD0tLU3pyeBERESV4dWrV0hISEC9evWgq6ur6nKIlHLy5El06dIF9+7dK3YUu7if8/T0dBgZGZUqr6l8mkFFmzFjBtLS0sTXvXv3VF0SERER0XsnOzsb9+/fx7x589C/f/8yT8dQlkrDbK1ataCpqVlgRDUlJaXItd/Mzc2V6i+VSmFoaKjwIiIiIqLytW3bNtjY2CA1NRWLFi2qtPOqNMzq6OjA2dlZ4Y48uVyO6OjoIicMt2nTpsAdfFFRUZUywZiIiIiICufn5weZTIaLFy/Cysqq0s6r8ocmBAQEwNfXFy4uLmjdujVCQ0ORlZUlThr28fGBlZUVQkJCAACTJk1Chw4d8MMPP6Bnz57Yvn07Lly4gJ9//lmVl0FEREREKqDyMDtw4EA8efIEQUFBSE5ORosWLRAZGSnOs0hKShIXAAaAtm3bIjw8HLNnz8bMmTNhb2+PiIgINGvWTFWXQEREVCFUeI82UYUrr59vla5moArK3B1HRESkCrm5ubh16xYsLS1hZGSk6nKIKkRaWhoePnyIBg0aFHiSmjJ5TeUjs0RERKRIS0sL+vr6ePLkCbS1tRV+Q0n0PpDL5Xjy5An09fWhpfVucZRhloiIqIqRSCSwsLBAQkJCgUexEr0vNDQ0ULduXfFxx2XFMEtERFQF6ejowN7eHjk5OaouhahC6OjolMtvHRhmiYiIqigNDQ0+AYyoBJyEQ0RERERqi2GWiIiIiNQWwywRERERqa0Pbs5s/rK66enpKq6EiIiIiAqTn9NK8ziEDy7MZmRkAACsra1VXAkRERERFScjI6PEB4d8cE8Ak8vlePjwIapXr/7O65rRa+np6bC2tsa9e/f4VDU1xe9QvfH7U3/8DtUfv8PyJQgCMjIyYGlpWeLyXR/cyKyGhgbq1Kmj6jLeS4aGhvwLrOb4Hao3fn/qj9+h+uN3WH5K+yhn3gBGRERERGqLYZaIiIiI1BbDLL0zqVSKuXPnQiqVqroUKiN+h+qN35/643eo/vgdqs4HdwMYEREREb0/ODJLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNUoufPn2PIkCEwNDREjRo1MHLkSGRmZha7z6tXrzB+/HiYmJjAwMAA/fr1Q0pKSqF9nz17hjp16kAikSA1NbUCroAq4ju8fPkyvL29YW1tDT09PTg4OGDZsmUVfSkfjFWrVsHW1ha6urpwc3PDuXPniu2/a9cuNG7cGLq6unB0dMSBAwcUtguCgKCgIFhYWEBPTw/u7u64efNmRV7CB688v8Pc3FwEBgbC0dER1apVg6WlJXx8fPDw4cOKvowPVnn/HXzT2LFjIZFIEBoaWs5Vf6AEohJ069ZNcHJyEv766y/h5MmTQoMGDQRvb+9i9xk7dqxgbW0tREdHCxcuXBA++ugjoW3btoX27dOnj9C9e3cBgPDff/9VwBVQRXyH69evF/z9/YXjx48Lt2/fFn799VdBT09PWLFiRUVfzntv+/btgo6OjrBhwwbhn3/+EUaPHi3UqFFDSElJKbT/6dOnBU1NTWHRokXC1atXhdmzZwva2tpCfHy82Oe7774TjIyMhIiICOHy5ctC7969hXr16gkvX76srMv6oJT3d5iamiq4u7sLO3bsEK5fvy7ExMQIrVu3FpydnSvzsj4YFfF3MN+ePXsEJycnwdLSUli6dGkFX8mHgWGWinX16lUBgHD+/Hmx7eDBg4JEIhEePHhQ6D6pqamCtra2sGvXLrHt2rVrAgAhJiZGoe/q1auFDh06CNHR0QyzFaSiv8M3ffnll0KnTp3Kr/gPVOvWrYXx48eL72UymWBpaSmEhIQU2n/AgAFCz549Fdrc3NyEL774QhAEQZDL5YK5ubmwePFicXtqaqoglUqFbdu2VcAVUHl/h4U5d+6cAEBITEwsn6JJVFHf3/379wUrKyvhypUrgo2NDcNsOeE0AypWTEwMatSoARcXF7HN3d0dGhoaOHv2bKH7XLx4Ebm5uXB3dxfbGjdujLp16yImJkZsu3r1KoKDg7F582ZoaPBHsaJU5Hf4trS0NNSsWbP8iv8A5eTk4OLFiwqfvYaGBtzd3Yv87GNiYhT6A4CHh4fYPyEhAcnJyQp9jIyM4ObmVuz3SWVTEd9hYdLS0iCRSFCjRo1yqZteq6jvTy6XY9iwYfjqq6/QtGnTiin+A8UEQcVKTk5G7dq1Fdq0tLRQs2ZNJCcnF7mPjo5OgX/BmpmZiftkZ2fD29sbixcvRt26dSukdnqtor7Dt505cwY7duzAmDFjyqXuD9XTp08hk8lgZmam0F7cZ5+cnFxs//x/KnNMKruK+A7f9urVKwQGBsLb2xuGhoblUzgBqLjv7/vvv4eWlhb8/f3Lv+gPHMPsB2r69OmQSCTFvq5fv15h558xYwYcHBwwdOjQCjvH+07V3+Gbrly5gj59+mDu3Ln49NNPK+WcRB+q3NxcDBgwAIIgYM2aNaouh0rh4sWLWLZsGTZu3AiJRKLqct47WqougFRj6tSp8PPzK7ZP/fr1YW5ujsePHyu05+Xl4fnz5zA3Ny90P3Nzc+Tk5CA1NVVhZC8lJUXc5+jRo4iPj8fu3bsBvL7TGgBq1aqFWbNmYf78+WW8sg+Hqr/DfFevXkWXLl0wZswYzJ49u0zXQv+nVq1a0NTULLD6R2GffT5zc/Ni++f/MyUlBRYWFgp9WrRoUY7VE1Ax32G+/CCbmJiIo0ePclS2AlTE93fy5Ek8fvxY4TeRMpkMU6dORWhoKO7evVu+F/GhUfWkXara8m8eunDhgth26NChUt08tHv3brHt+vXrCjcP3bp1S4iPjxdfGzZsEAAIZ86cKfJuUSqbivoOBUEQrly5ItSuXVv46quvKu4CPkCtW7cWJkyYIL6XyWSClZVVsTef9OrVS6GtTZs2BW4AW7Jkibg9LS2NN4BVoPL+DgVBEHJycgQvLy+hadOmwuPHjyumcBIEofy/v6dPnyr8Ny8+Pl6wtLQUAgMDhevXr1fchXwgGGapRN26dRNatmwpnD17Vjh16pRgb2+vsKzT/fv3hUaNGglnz54V28aOHSvUrVtXOHr0qHDhwgWhTZs2Qps2bYo8x7Fjx7iaQQWqiO8wPj5eMDU1FYYOHSo8evRIfPE/su9u+/btglQqFTZu3ChcvXpVGDNmjFCjRg0hOTlZEARBGDZsmDB9+nSx/+nTpwUtLS1hyZIlwrVr14S5c+cWujRXjRo1hN9//134+++/hT59+nBprgpU3t9hTk6O0Lt3b6FOnTpCXFycwt+57OxslVzj+6wi/g6+jasZlB+GWSrRs2fPBG9vb8HAwEAwNDQUhg8fLmRkZIjbExISBADCsWPHxLaXL18KX375pWBsbCzo6+sLffv2FR49elTkORhmK1ZFfIdz584VABR42djYVOKVvb9WrFgh1K1bV9DR0RFat24t/PXXX+K2Dh06CL6+vgr9d+7cKTRs2FDQ0dERmjZtKuzfv19hu1wuF+bMmSOYmZkJUqlU6NKli3Djxo3KuJQPVnl+h/l/Rwt7vfn3lspPef8dfBvDbPmRCML/n6xIRERERKRmuJoBEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBJRhfPz84OtrW2Z9p03bx4kEkn5FlTF3L17FxKJBBs3bqz0c0skEsybN098v3HjRkgkEty9e7fEfW1tbeHn51eu9bzLzwoRfZgYZok+YBKJpFSv48ePq7rUD56/vz8kEglu3bpVZJ9Zs2ZBIpHg77//rsTKlPfw4UPMmzcPcXFxqi5FlP8/FEuWLFF1KUSkJC1VF0BEqvPrr78qvN+8eTOioqIKtDs4OLzTedatWwe5XF6mfWfPno3p06e/0/nfB0OGDMGKFSsQHh6OoKCgQvts27YNjo6OaN68eZnPM2zYMAwaNAhSqbTMxyjJw4cPMX/+fNja2qJFixYK297lZ4WIPkwMs0QfsKFDhyq8/+uvvxAVFVWg/W0vXryAvr5+qc+jra1dpvoAQEtLC1pa/FeVm5sbGjRogG3bthUaZmNiYpCQkIDvvvvunc6jqakJTU3NdzrGu3iXnxUi+jBxmgERFatjx45o1qwZLl68iPbt20NfXx8zZ84EAPz+++/o2bMnLC0tIZVKYWdnhwULFkAmkykc4+15kG/+Svfnn3+GnZ0dpFIpXF1dcf78eYV9C5szK5FIMGHCBERERKBZs2aQSqVo2rQpIiMjC9R//PhxuLi4QFdXF3Z2dvjpp59KPQ/35MmT6N+/P+rWrQupVApra2tMmTIFL1++LHB9BgYGePDgAby8vGBgYABTU1NMmzatwGeRmpoKPz8/GBkZoUaNGvD19UVqamqJtQCvR2evX7+O2NjYAtvCw8MhkUjg7e2NnJwcBAUFwdnZGUZGRqhWrRratWuHY8eOlXiOwubMCoKAb775BnXq1IG+vj46deqEf/75p8C+z58/x7Rp0+Do6AgDAwMYGhqie/fuuHz5stjn+PHjcHV1BQAMHz5cnMqSP1+4sDmzWVlZmDp1KqytrSGVStGoUSMsWbIEgiAo9FPm56KsHj9+jJEjR8LMzAy6urpwcnLCpk2bCvTbvn07nJ2dUb16dRgaGsLR0RHLli0Tt+fm5mL+/Pmwt7eHrq4uTExM8MknnyAqKqrcaiX6UHC4g4hK9OzZM3Tv3h2DBg3C0KFDYWZmBuB18DEwMEBAQAAMDAxw9OhRBAUFIT09HYsXLy7xuOHh4cjIyMAXX3wBiUSCRYsW4bPPPsOdO3dKHKE7deoU9uzZgy+//BLVq1fH8uXL0a9fPyQlJcHExAQAcOnSJXTr1g0WFhaYP38+ZDIZgoODYWpqWqrr3rVrF168eIFx48bBxMQE586dw4oVK3D//n3s2rVLoa9MJoOHhwfc3NywZMkSHDlyBD/88APs7Owwbtw4AK9DYZ8+fXDq1CmMHTsWDg4O2Lt3L3x9fUtVz5AhQzB//nyEh4ejVatWCufeuXMn2rVrh7p16+Lp06f45Zdf4O3tjdGjRyMjIwPr16+Hh4cHzp07V+BX+yUJCgrCN998gx49eqBHjx6IjY3Fp59+ipycHIV+d+7cQUREBPr374969eohJSUFP/30Ezp06ICrV6/C0tISDg4OCA4ORlBQEMaMGYN27doBANq2bVvouQVBQO/evXHs2DGMHDkSLVq0wKFDh/DVV1/hwYMHWLp0qUL/0vxclNXLly/RsWNH3Lp1CxMmTEC9evWwa9cu+Pn5ITU1FZMmTQIAREVFwdvbG126dMH3338PALh27RpOnz4t9pk3bx5CQkIwatQotG7dGunp6bhw4QJiY2PRtWvXd6qT6IMjEBH9f+PHjxfe/tdChw4dBADC2rVrC/R/8eJFgbYvvvhC0NfXF169eiW2+fr6CjY2NuL7hIQEAYBgYmIiPH/+XGz//fffBQDCH3/8IbbNnTu3QE0ABB0dHeHWrVti2+XLlwUAwooVK8Q2T09PQV9fX3jw4IHYdvPmTUFLS6vAMQtT2PWFhIQIEolESExMVLg+AEJwcLBC35YtWwrOzs7i+4iICAGAsGjRIrEtLy9PaNeunQBACAsLK7EmV1dXoU6dOoJMJhPbIiMjBQDCTz/9JB4zOztbYb///vtPMDMzE0aMGKHQDkCYO3eu+D4sLEwAICQkJAiCIAiPHz8WdHR0hJ49ewpyuVzsN3PmTAGA4OvrK7a9evVKoS5BeP1dS6VShc/m/PnzRV7v2z8r+Z/ZN998o9Dv888/FyQSicLPQGl/LgqT/zO5ePHiIvuEhoYKAIQtW7aIbTk5OUKbNm0EAwMDIT09XRAEQZg0aZJgaGgo5OXlFXksJycnoWfPnsXWRESlw2kGRFQiqVSK4cOHF2jX09MT/5yRkYGnT5+iXbt2ePHiBa5fv17icQcOHAhjY2Pxff4o3Z07d0rc193dHXZ2duL75s2bw9DQUNxXJpPhyJEj8PLygqWlpdivQYMG6N69e4nHBxSvLysrC0+fPkXbtm0hCAIuXbpUoP/YsWMV3rdr107hWg4cOAAtLS1xpBZ4PUd14sSJpaoHeD3P+f79+zhx4oTYFh4eDh0dHfTv3188po6ODgBALpfj+fPnyMvLg4uLS6FTFIpz5MgR5OTkYOLEiQpTMyZPnlygr1QqhYbG6/+syGQyPHv2DAYGBmjUqJHS58134MABaGpqwt/fX6F96tSpEAQBBw8eVGgv6efiXRw4cADm5ubw9vYW27S1teHv74/MzEz8+eefAIAaNWogKyur2CkDNWrUwD///IObN2++c11EHzqGWSIqkZWVlRiO3vTPP/+gb9++MDIygqGhIUxNTcWbx9LS0ko8bt26dRXe5wfb//77T+l98/fP3/fx48d4+fIlGjRoUKBfYW2FSUpKgp+fH2rWrCnOg+3QoQOAgtenq6tbYPrCm/UAQGJiIiwsLGBgYKDQr1GjRqWqBwAGDRoETU1NhIeHAwBevXqFvXv3onv37gr/Y7Bp0yY0b95cnI9pamqK/fv3l+p7eVNiYiIAwN7eXqHd1NRU4XzA6+C8dOlS2NvbQyqVolatWjA1NcXff/+t9HnfPL+lpSWqV6+u0J6/wkZ+fflK+rl4F4mJibC3txcDe1G1fPnll2jYsCG6d++OOnXqYMSIEQXm7QYHByM1NRUNGzaEo6Mjvvrqqyq/pBpRVcUwS0QlenOEMl9qaio6dOiAy5cvIzg4GH/88QeioqLEOYKlWV6pqLvmhbdu7CnvfUtDJpOha9eu2L9/PwIDAxEREYGoqCjxRqW3r6+yVgCoXbs2unbtit9++w25ubn4448/kJGRgSFDhoh9tmzZAj8/P9jZ2WH9+vWIjIxEVFQUOnfuXKHLXi1cuBABAQFo3749tmzZgkOHDiEqKgpNmzattOW2KvrnojRq166NuLg47Nu3T5zv2717d4W50e3bt8ft27exYcMGNGvWDL/88gtatWqFX375pdLqJHpf8AYwIiqT48eP49mzZ9izZw/at28vtickJKiwqv9Tu3Zt6OrqFvqQgeIePJAvPj4e//77LzZt2gQfHx+x/V3uNrexsUF0dDQyMzMVRmdv3Lih1HGGDBmCyMhIHDx4EOHh4TA0NISnp6e4fffu3ahfvz727NmjMDVg7ty5ZaoZAG7evIn69euL7U+ePCkw2rl792506tQJ69evV2hPTU1FrVq1xPfKPNHNxsYGR44cQUZGhsLobP40lvz6KoONjQ3+/vtvyOVyhdHZwmrR0dGBp6cnPD09IZfL8eWXX+Knn37CnDlzxN8M1KxZE8OHD8fw4cORmZmJ9u3bY968eRg1alSlXRPR+4Ajs0RUJvkjYG+OeOXk5GD16tWqKkmBpqYm3N3dERERgYcPH4rtt27dKjDPsqj9AcXrEwRBYXklZfXo0QN5eXlYs2aN2CaTybBixQqljuPl5QV9fX2sXr0aBw8exGeffQZdXd1iaz979ixiYmKUrtnd3R3a2tpYsWKFwvFCQ0ML9NXU1CwwArpr1y48ePBAoa1atWoAUKolyXr06AGZTIaVK1cqtC9duhQSiaTU85/LQ48ePZCcnIwdO3aIbXl5eVixYgUMDAzEKSjPnj1T2E9DQ0N8kEV2dnahfQwMDNCgQQNxOxGVHkdmiahM2rZtC2NjY/j6+oqPWv31118r9de5JZk3bx4OHz6Mjz/+GOPGjRNDUbNmzUp8lGrjxo1hZ2eHadOm4cGDBzA0NMRvv/32TnMvPT098fHHH2P69Om4e/cumjRpgj179ig9n9TAwABeXl7ivNk3pxgAQK9evbBnzx707dsXPXv2REJCAtauXYsmTZogMzNTqXPlr5cbEhKCXr16oUePHrh06RIOHjyoMNqaf97g4GAMHz4cbdu2RXx8PLZu3aowogsAdnZ2qFGjBtauXYvq1aujWrVqcHNzQ7169Qqc39PTE506dcKsWbNw9+5dODk54fDhw/j9998xefJkhZu9ykN0dDRevXpVoN3LywtjxozBTz/9BD8/P1y8eBG2trbYvXs3Tp8+jdDQUHHkeNSoUXj+/Dk6d+6MOnXqIDExEStWrECLFi3E+bVNmjRBx44d4ezsjJo1a+LChQvYvXs3JkyYUK7XQ/QhYJglojIxMTHB//73P0ydOhWzZ8+GsbExhg4dii5dusDDw0PV5QEAnJ2dcfDgQUybNg1z5syBtbU1goODce3atRJXW9DW1sYff/wBf39/hISEQFdXF3379sWECRPg5ORUpno0NDSwb98+TJ48GVu2bIFEIkHv3r3xww8/oGXLlkoda8iQIQgPD4eFhQU6d+6ssM3Pzw/Jycn46aefcOjQITRp0gRbtmzBrl27cPz4caXr/uabb6Crq4u1a9fi2LFjcHNzw+HDh9GzZ0+FfjNnzkRWVhbCw8OxY8cOtGrVCvv37y/wOGJtbW1s2rQJM2bMwNixY5GXl4ewsLBCw2z+ZxYUFIQdO3YgLCwMtra2WLx4MaZOnar0tZQkMjKy0Ics2NraolmzZjh+/DimT5+OTZs2IT09HY0aNUJYWBj8/PzEvkOHDsXPP/+M1atXIzU1Febm5hg4cCDmzZsnTk/w9/fHvn37cPjwYWRnZ8PGxgbffPMNvvrqq3K/JqL3nUSoSsMoRESVwMvLi8siERG9Jzhnlojea28/evbmzZs4cOAAOnbsqJqCiIioXHFklojeaxYWFvDz80P9+vWRmJiINWvWIDs7G5cuXSqwdioREakfzpklovdat27dsG3bNiQnJ0MqlaJNmzZYuHAhgywR0XtCpdMMTpw4AU9PT1haWkIikSAiIqLEfY4fP45WrVpBKpWiQYMG4gLmRESFCQsLw927d/Hq1SukpaUhMjISrVq1UnVZRERUTlQaZrOysuDk5IRVq1aVqn9CQgJ69uyJTp06IS4uDpMnT8aoUaNw6NChCq6UiIiIiKqiKjNnViKRYO/evfDy8iqyT2BgIPbv348rV66IbYMGDUJqamqhS6kQERER0ftNrebMxsTEwN3dXaHNw8MDkydPLnKf7OxshSeqyOVyPH/+HCYmJko9UpGIiIiIKocgCMjIyIClpaXC46MLo1ZhNjk5GWZmZgptZmZmSE9Px8uXL6Gnp1dgn5CQEMyfP7+ySiQiIiKicnLv3j3UqVOn2D5qFWbLYsaMGQgICBDfp6WloW7durh37x4MDQ1VWBkRERERFSY9PR3W1tbiY6KLo1Zh1tzcHCkpKQptKSkpMDQ0LHRUFgCkUimkUmmBdkNDQ4ZZIiIioiqsNFNC1eoJYG3atEF0dLRCW1RUFNq0aaOiioiIiIhIlVQaZjMzMxEXF4e4uDgAr5feiouLQ1JSEoDXUwR8fHzE/mPHjsWdO3fw9ddf4/r161i9ejV27tyJKVOmqKJ8IiIiIlIxlYbZCxcuoGXLlmjZsiUAICAgAC1btkRQUBAA4NGjR2KwBYB69eph//79iIqKgpOTE3744Qf88ssv8PDwUEn9RERERKRaVWad2cqSnp4OIyMjpKWlcc4sERFRCQRBQF5eHmQymapLofeMtrY2NDU1C92mTF5TqxvAiIiIqPLk5OTg0aNHePHihapLofeQRCJBnTp1YGBg8E7HYZglIiKiAuRyORISEqCpqQlLS0vo6OjwYUNUbgRBwJMnT3D//n3Y29sXOUJbGgyzREREVEBOTg7kcjmsra2hr6+v6nLoPWRqaoq7d+8iNzf3ncKsWi3NRURERJWrpEeJEpVVeY308yeUiIiIiNQWwywRERERqS2GWSIiIqJi2NraIjQ0tNT9jx8/DolEgtTU1Aqrif4PwywRERG9FyQSSbGvefPmlem458+fx5gxY0rdv23btnj06BGMjIzKdL7SYmh+jasZEBER0Xvh0aNH4p937NiBoKAg3LhxQ2x7cz1TQRAgk8mgpVVyFDI1NVWqDh0dHZibmyu1D5UdR2aJiIioRIIg4EVOnkpepX1Yqbm5ufgyMjKCRCIR31+/fh3Vq1fHwYMH4ezsDKlUilOnTuH27dvo06cPzMzMYGBgAFdXVxw5ckThuG9PM5BIJPjll1/Qt29f6Ovrw97eHvv27RO3vz1iunHjRtSoUQOHDh2Cg4MDDAwM0K1bN4XwnZeXB39/f9SoUQMmJiYIDAyEr68vvLy8yvyd/ffff/Dx8YGxsTH09fXRvXt33Lx5U9yemJgIT09PGBsbo1q1amjatCkOHDgg7jtkyBCYmppCT08P9vb2CAsLK3MtFYkjs0RERFSil7kyNAk6pJJzXw32gL5O+USW6dOnY8mSJahfvz6MjY1x79499OjRA99++y2kUik2b94MT09P3LhxA3Xr1i3yOPPnz8eiRYuwePFirFixAkOGDEFiYiJq1qxZaP8XL15gyZIl+PXXX6GhoYGhQ4di2rRp2Lp1KwDg+++/x9atWxEWFgYHBwcsW7YMERER6NSpU5mv1c/PDzdv3sS+fftgaGiIwMBA9OjRA1evXoW2tjbGjx+PnJwcnDhxAtWqVcPVq1fF0es5c+bg6tWrOHjwIGrVqoVbt27h5cuXZa6lIjHMEhER0QcjODgYXbt2Fd/XrFkTTk5O4vsFCxZg79692LdvHyZMmFDkcfz8/ODt7Q0AWLhwIZYvX45z586hW7duhfbPzc3F2rVrYWdnBwCYMGECgoODxe0rVqzAjBkz0LdvXwDAypUrxVHSssgPsadPn0bbtm0BAFu3boW1tTUiIiLQv39/JCUloV+/fnB0dAQA1K9fX9w/KSkJLVu2hIuLC4DXo9NVFcMsERERlUhPWxNXgz1Udu7ykh/O8mVmZmLevHnYv38/Hj16hLy8PLx8+RJJSUnFHqd58+bin6tVqwZDQ0M8fvy4yP76+vpikAUACwsLsX9aWhpSUlLQunVrcbumpiacnZ0hl8uVur58165dg5aWFtzc3MQ2ExMTNGrUCNeuXQMA+Pv7Y9y4cTh8+DDc3d3Rr18/8brGjRuHfv36ITY2Fp9++im8vLzEUFzVcM4sERERlUgikUBfR0slr/J6UhTwOni+adq0adi7dy8WLlyIkydPIi4uDo6OjsjJySn2ONra2gU+n+KCZ2H9SzsXuKKMGjUKd+7cwbBhwxAfHw8XFxesWLECANC9e3ckJiZiypQpePjwIbp06YJp06aptN6iMMwSERHRB+v06dPw8/ND37594ejoCHNzc9y9e7dSazAyMoKZmRnOnz8vtslkMsTGxpb5mA4ODsjLy8PZs2fFtmfPnuHGjRto0qSJ2GZtbY2xY8diz549mDp1KtatWyduMzU1ha+vL7Zs2YLQ0FD8/PPPZa6nInGaAREREX2w7O3tsWfPHnh6ekIikWDOnDll/tX+u5g4cSJCQkLQoEEDNG7cGCtWrMB///1XqlHp+Ph4VK9eXXwvkUjg5OSEPn36YPTo0fjpp59QvXp1TJ8+HVZWVujTpw8AYPLkyejevTsaNmyI//77D8eOHYODgwMAICgoCM7OzmjatCmys7Pxv//9T9xW1TDMEhER0Qfrxx9/xIgRI9C2bVvUqlULgYGBSE9Pr/Q6AgMDkZycDB8fH2hqamLMmDHw8PCApmbJ84Xbt2+v8F5TUxN5eXkICwvDpEmT0KtXL+Tk5KB9+/Y4cOCAOOVBJpNh/PjxuH//PgwNDdGtWzcsXboUwOu1cmfMmIG7d+9CT08P7dq1w/bt28v/wsuBRFD1hI1Klp6eDiMjI6SlpcHQ0FDV5RAREVVJr169QkJCAurVqwddXV1Vl/PBkcvlcHBwwIABA7BgwQJVl1MhivsZUyavcWSWiIiISMUSExNx+PBhdOjQAdnZ2Vi5ciUSEhIwePBgVZdW5fEGMCIiIiIV09DQwMaNG+Hq6oqPP/4Y8fHxOHLkSJWdp1qVcGSWiIiISMWsra1x+vRpVZehljgyS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERG9oWPHjpg8ebL43tbWFqGhocXuI5FIEBER8c7nLq/jfEgYZomIiOi94OnpiW7duhW67eTJk5BIJPj777+VPu758+cxZsyYdy1Pwbx589CiRYsC7Y8ePUL37t3L9Vxv27hxI2rUqFGh56hMDLNERET0Xhg5ciSioqJw//79AtvCwsLg4uKC5s2bK31cU1NT6Ovrl0eJJTI3N4dUKq2Uc70vGGaJiIioZIIA5GSp5iUIpSqxV69eMDU1xcaNGxXaMzMzsWvXLowcORLPnj2Dt7c3rKysoK+vD0dHR2zbtq3Y4749zeDmzZto3749dHV10aRJE0RFRRXYJzAwEA0bNoS+vj7q16+POXPmIDc3F8DrkdH58+fj8uXLkEgkkEgkYs1vTzOIj49H586doaenBxMTE4wZMwaZmZnidj8/P3h5eWHJkiWwsLCAiYkJxo8fL56rLJKSktCnTx8YGBjA0NAQAwYMQEpKirj98uXL6NSpE6pXrw5DQ0M4OzvjwoULAIDExER4enrC2NgY1apVQ9OmTXHgwIEy11IafJwtERERlSz3BbDQUjXnnvkQ0KlWYjctLS34+Phg48aNmDVrFiQSCQBg165dkMlk8Pb2RmZmJpydnREYGAhDQ0Ps378fw4YNg52dHVq3bl3iOeRyOT777DOYmZnh7NmzSEtLU5hfm6969erYuHEjLC0tER8fj9GjR6N69er4+uuvMXDgQFy5cgWRkZE4cuQIAMDIyKjAMbKysuDh4YE2bdrg/PnzePz4MUaNGoUJEyYoBPZjx47BwsICx44dw61btzBw4EC0aNECo0ePLvF6Cru+/CD7559/Ii8vD+PHj8fAgQNx/PhxAMCQIUPQsmVLrFmzBpqamoiLi4O2tjYAYPz48cjJycGJEydQrVo1XL16FQYGBkrXoQyGWSIiInpvjBgxAosXL8aff/6Jjh07Ang9xaBfv34wMjKCkZERpk2bJvafOHEiDh06hJ07d5YqzB45cgTXr1/HoUOHYGn5OtwvXLiwwDzX2bNni3+2tbXFtGnTsH37dnz99dfQ09ODgYEBtLS0YG5uXuS5wsPD8erVK2zevBnVqr0O8ytXroSnpye+//57mJmZAQCMjY2xcuVKaGpqonHjxujZsyeio6PLFGajo6MRHx+PhIQEWFtbAwA2b96Mpk2b4vz583B1dUVSUhK++uorNG7cGABgb28v7p+UlIR+/frB0dERAFC/fn2la1AWwywRERGVTFv/9Qipqs5dSo0bN0bbtm2xYcMGdOzYEbdu3cLJkycRHBwMAJDJZFi4cCF27tyJBw8eICcnB9nZ2aWeE3vt2jVYW1uLQRYA2rRpU6Dfjh07sHz5cty+fRuZmZnIy8uDoaFhqa8j/1xOTk5ikAWAjz/+GHK5HDdu3BDDbNOmTaGpqSn2sbCwQHx8vFLnevOc1tbWYpAFgCZNmqBGjRq4du0aXF1dERAQgFGjRuHXX3+Fu7s7+vfvDzs7OwCAv78/xo0bh8OHD8Pd3R39+vUr0zxlZXDOLBEREZVMInn9q35VvP7/dIHSGjlyJH777TdkZGQgLCwMdnZ26NChAwBg8eLFWLZsGQIDA3Hs2DHExcXBw8MDOTk55fZRxcTEYMiQIejRowf+97//4dKlS5g1a1a5nuNN+b/izyeRSCCXyyvkXMDrlRj++ecf9OzZE0ePHkWTJk2wd+9eAMCoUaNw584dDBs2DPHx8XBxccGKFSsqrBaAYZaIiIjeMwMGDICGhgbCw8OxefNmjBgxQpw/e/r0afTp0wdDhw6Fk5MT6tevj3///bfUx3ZwcMC9e/fw6NEjse2vv/5S6HPmzBnY2Nhg1qxZcHFxgb29PRITExX66OjoQCaTlXiuy5cvIysrS2w7ffo0NDQ00KhRo1LXrIz867t3757YdvXqVaSmpqJJkyZiW8OGDTFlyhQcPnwYn332GcLCwsRt1tbWGDt2LPbs2YOpU6di3bp1FVJrPoZZIiIieq8YGBhg4MCBmDFjBh49egQ/Pz9xm729PaKionDmzBlcu3YNX3zxhcKd+iVxd3dHw4YN4evri8uXL+PkyZOYNWuWQh97e3skJSVh+/btuH37NpYvXy6OXOaztbVFQkIC4uLi8PTpU2RnZxc415AhQ6CrqwtfX19cuXIFx44dw8SJEzFs2DBxikFZyWQyxMXFKbyuXbsGd3d3ODo6YsiQIYiNjcW5c+fg4+ODDh06wMXFBS9fvsSECRNw/PhxJCYm4vTp0zh//jwcHBwAAJMnT8ahQ4eQkJCA2NhYHDt2TNxWURhmiYiI6L0zcuRI/Pfff/Dw8FCY3zp79my0atUKHh4e6NixI8zNzeHl5VXq42poaGDv3r14+fIlWrdujVGjRuHbb79V6NO7d29MmTIFEyZMQIsWLXDmzBnMmTNHoU+/fv3QrVs3dOrUCaampoUuD6avr49Dhw7h+fPncHV1xeeff44uXbpg5cqVyn0YhcjMzETLli0VXp6enpBIJPj9999hbGyM9u3bw93dHfXr18eOHTsAAJqamnj27Bl8fHzQsGFDDBgwAN27d8f8+fMBvA7J48ePh4ODA7p164aGDRti9erV71xvcSSCUMrF294T6enpMDIyQlpamtITsYmIiD4Ur169QkJCAurVqwddXV1Vl0PvoeJ+xpTJaxyZJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiKtIHdp84VaLy+tlimCUiIqIC8p8q9eLFCxVXQu+r/Ceivfko3rLQKo9i3sWqVauwePFiJCcnw8nJCStWrEDr1q2L7B8aGoo1a9YgKSkJtWrVwueff46QkBAuG0JERFSONDU1UaNGDTx+/BjA6zVPJUo+VpaoKHK5HE+ePIG+vj60tN4tjqo0zO7YsQMBAQFYu3Yt3NzcEBoaCg8PD9y4cQO1a9cu0D88PBzTp0/Hhg0b0LZtW/z777/w8/ODRCLBjz/+qIIrICIien+Zm5sDgBhoicqThoYG6tat+87/k6TShya4ubnB1dVVfJKFXC6HtbU1Jk6ciOnTpxfoP2HCBFy7dg3R0dFi29SpU3H27FmcOnWqVOfkQxOIiIiUI5PJkJubq+oy6D2jo6MDDY3CZ7wqk9dUNjKbk5ODixcvYsaMGWKbhoYG3N3dERMTU+g+bdu2xZYtW3Du3Dm0bt0ad+7cwYEDBzBs2LAiz5Odna3wvOP09PTyuwgiIqIPgKam5jvPaySqKCoLs0+fPoVMJoOZmZlCu5mZGa5fv17oPoMHD8bTp0/xySefQBAE5OXlYezYsZg5c2aR5wkJCRGfF0xERERE7xe1Ws3g+PHjWLhwIVavXo3Y2Fjs2bMH+/fvx4IFC4rcZ8aMGUhLSxNf9+7dq8SKiYiIiKgiqWxktlatWtDU1ERKSopCe0pKijjh/G1z5szBsGHDMGrUKACAo6MjsrKyMGbMGMyaNavQeRdSqRRSqbT8L4CIiIiIVE5lI7M6OjpwdnZWuJlLLpcjOjoabdq0KXSfFy9eFAis+XN4uKgzERER0YdHpUtzBQQEwNfXFy4uLmjdujVCQ0ORlZWF4cOHAwB8fHxgZWWFkJAQAICnpyd+/PFHtGzZEm5ubrh16xbmzJkDT09PTkwnIiIi+gCpNMwOHDgQT548QVBQEJKTk9GiRQtERkaKN4UlJSUpjMTOnj0bEokEs2fPxoMHD2BqagpPT098++23qroEIiIiIlIhla4zqwpcZ5aIiIioalMmr6nVagZERERERG9imCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2lA6ztra2CA4ORlJSUkXUQ0RERERUakqH2cmTJ2PPnj2oX78+unbtiu3btyM7O7siaiMiIiIiKlaZwmxcXBzOnTsHBwcHTJw4ERYWFpgwYQJiY2MrokYiIiIiokJJBEEQ3uUAubm5WL16NQIDA5GbmwtHR0f4+/tj+PDhkEgk5VVnuUlPT4eRkRHS0tJgaGio6nKIiIiI6C3K5DWtsp4kNzcXe/fuRVhYGKKiovDRRx9h5MiRuH//PmbOnIkjR44gPDy8rIcnIiIiIiqR0mE2NjYWYWFh2LZtGzQ0NODj44OlS5eicePGYp++ffvC1dW1XAslIiIiInqb0mHW1dUVXbt2xZo1a+Dl5QVtbe0CferVq4dBgwaVS4FEREREREVROszeuXMHNjY2xfapVq0awsLCylwUEREREVFpKB1m84PshQsXcO3aNQCAg4MDXFxcyrcyIiIiIqISKB1m79+/D29vb5w+fRo1atQAAKSmpqJt27bYvn076tSpU941EhEREREVSul1ZkeNGoXc3Fxcu3YNz58/x/Pnz3Ht2jXI5XKMGjWqImokIiIiIiqU0uvM6unp4cyZM2jZsqVC+8WLF9GuXTu8ePGiXAssb1xnloiIiKhqUyavKT0ya21tjdzc3ALtMpkMlpaWyh6OiIiIiKjMlA6zixcvxsSJE3HhwgWx7cKFC5g0aRKWLFlSrsURERERERVH6TDr5+eHuLg4uLm5QSqVQiqVws3NDbGxsRgxYgRq1qwpvkpj1apVsLW1ha6uLtzc3HDu3Lli+6empmL8+PGwsLCAVCpFw4YNceDAAWUvg4iIiIjeA0qvZhAaGlpuJ9+xYwcCAgKwdu1auLm5ITQ0FB4eHrhx4wZq165doH9OTg66du2K2rVrY/fu3bCyskJiYqK4qgIRERERfViUvgGsPLm5ucHV1RUrV64EAMjlclhbW2PixImYPn16gf5r167F4sWLcf369UKfPFYavAGMiIiIqGpTJq8pPTILvL7ZKyIiQnxoQtOmTdG7d29oamqW+hg5OTm4ePEiZsyYIbZpaGjA3d0dMTExhe6zb98+tGnTBuPHj8fvv/8OU1NTDB48GIGBgUWeOzs7G9nZ2eL79PT0UtdIRERERFWb0mH21q1b6NGjBx48eIBGjRoBAEJCQmBtbY39+/fDzs6uVMd5+vQpZDIZzMzMFNrNzMxw/fr1Qve5c+cOjh49iiFDhuDAgQO4desWvvzyS+Tm5mLu3LmF7hMSEoL58+crcYVEREREpC6UvgHM398fdnZ2uHfvHmJjYxEbG4ukpCTUq1cP/v7+FVGjSC6Xo3bt2vj555/h7OyMgQMHYtasWVi7dm2R+8yYMQNpaWni6969exVaIxERERFVHqVHZv/880/89ddfCqsVmJiY4LvvvsPHH39c6uPUqlULmpqaSElJUWhPSUmBubl5oftYWFhAW1tbYUqBg4MDkpOTkZOTAx0dnQL75K+4QERERETvH6VHZqVSKTIyMgq0Z2ZmFhomi6KjowNnZ2dER0eLbXK5HNHR0WjTpk2h+3z88ce4desW5HK52Pbvv//CwsJCqXMTERER0ftB6TDbq1cvjBkzBmfPnoUgCBAEAX/99RfGjh2L3r17K3WsgIAArFu3Dps2bcK1a9cwbtw4ZGVlYfjw4QAAHx8fhRvExo0bh+fPn2PSpEn4999/sX//fixcuBDjx49X9jKIiIiI6D2g9DSD5cuXw9fXF23atBGXx8rLy0Pv3r2xbNkypY41cOBAPHnyBEFBQUhOTkaLFi0QGRkp3hSWlJQEDY3/y9vW1tY4dOgQpkyZgubNm8PKygqTJk1CYGCgspdBRERERO8BpdaZFQQB9+7dg6mpKR48eCAuzeXg4IAGDRpUWJHlievMEhEREVVtFbbOrCAIaNCgAf755x/Y29urTYAlIiIioveTUnNmNTQ0YG9vj2fPnlVUPUREREREpab0DWDfffcdvvrqK1y5cqUi6iEiIiIiKjWl5swCgLGxMV68eIG8vDzo6OhAT09PYfvz58/LtcDyxjmzRERERFVbhc2ZBYClS5dCIpGUuTgiIiIiovKidJj18/OrgDKIiIiIiJSn9JxZTU1NPH78uED7s2fPFB4zS0RERERU0ZQOs0VNsc3OzuYjZYmIiIioUpV6msHy5csBABKJBL/88gsMDAzEbTKZDCdOnEDjxo3Lv0IiIiIioiKUOswuXboUwOuR2bVr1ypMKdDR0YGtrS3Wrl1b/hUSERERERWh1GE2ISEBANCpUyfs2bMHxsbGFVYUEREREVFpKL2awbFjxyqiDiIiIiIipSkdZmUyGTZu3Ijo6Gg8fvwYcrlcYfvRo0fLrTgiIiIiouIoHWYnTZqEjRs3omfPnmjWrBkfoEBEREREKqN0mN2+fTt27tyJHj16VEQ9RERERESlpvQ6szo6OmjQoEFF1EJEREREpBSlw+zUqVOxbNmyIh+eQERERERUWZSeZnDq1CkcO3YMBw8eRNOmTaGtra2wfc+ePeVWHBERERFRcZQOszVq1EDfvn0rohYiIiIiIqUoHWbDwsIqog4iIiIiIqWVes7s48ePi92el5eHc+fOvXNBRERERESlVeowa2FhoRBoHR0dce/ePfH9s2fP0KZNm/KtjoiIiIioGKUOs2+vXnD37l3k5uYW24eIiIiIqCIpvTRXcfg0MCIiIiKqTOUaZomIiIiIKlOpVzOQSCTIyMiArq4uBEGARCJBZmYm0tPTAUD8JxERERFRZSl1mBUEAQ0bNlR437JlS4X3nGZARERERJWp1GH22LFjFVkHEREREZHSSh1mO3ToUJF1EBEREREpjTeAEREREZHaYpglIiIiIrXFMEtEREREaothloiIiIjU1juH2fT0dERERODatWvlUQ8RERERUakpHWYHDBiAlStXAgBevnwJFxcXDBgwAM2bN8dvv/1W7gUSERERERVF6TB74sQJtGvXDgCwd+9eCIKA1NRULF++HN988025F0hEREREVBSlw2xaWhpq1qwJAIiMjES/fv2gr6+Pnj174ubNm+VeIBERERFRUZQOs9bW1oiJiUFWVhYiIyPx6aefAgD+++8/6OrqlnuBRERERERFKfUTwPJNnjwZQ4YMgYGBAWxsbNCxY0cAr6cfODo6lnd9RERERERFUjrMfvnll2jdujXu3buHrl27QkPj9eBu/fr1OWeWiIiIiCqVRBAE4V0OIJPJEB8fDxsbGxgbG5dXXRUmPT0dRkZGSEtLg6GhoarLISIiIqK3KJPXlJ4zO3nyZKxfvx7A6yDboUMHtGrVCtbW1jh+/HiZCiYiIiIiKgulw+zu3bvh5OQEAPjjjz+QkJCA69evY8qUKZg1a1a5F0hEREREVBSlw+zTp09hbm4OADhw4AD69++Phg0bYsSIEYiPjy/3AomIiIiIiqJ0mDUzM8PVq1chk8kQGRmJrl27AgBevHgBTU3Nci+QiIiIiKgoSofZ4cOHY8CAAWjWrBkkEgnc3d0BAGfPnkXjxo3LVMSqVatga2sLXV1duLm54dy5c6Xab/v27ZBIJPDy8irTeYmIiIhIvSm9NNe8efPQrFkz3Lt3D/3794dUKgUAaGpqYvr06UoXsGPHDgQEBGDt2rVwc3NDaGgoPDw8cOPGDdSuXbvI/e7evYtp06aJj9YlIiIiog/POy/N9a7c3Nzg6uqKlStXAgDkcjmsra0xceLEIsOxTCZD+/btMWLECJw8eRKpqamIiIgo1fm4NBcRERFR1VahS3MBwJ9//glPT080aNAADRo0QO/evXHy5Emlj5OTk4OLFy+KUxUAQENDA+7u7oiJiSlyv+DgYNSuXRsjR44s8RzZ2dlIT09XeBERERHR+0HpMLtlyxa4u7tDX18f/v7+8Pf3h56eHrp06YLw8HCljvX06VPIZDKYmZkptJuZmSE5ObnQfU6dOoX169dj3bp1pTpHSEgIjIyMxJe1tbVSNRIRERFR1aX0nNlvv/0WixYtwpQpU8Q2f39//Pjjj1iwYAEGDx5crgW+KSMjA8OGDcO6detQq1atUu0zY8YMBAQEiO/T09MZaImIiIjeE0qH2Tt37sDT07NAe+/evTFz5kyljlWrVi1oamoiJSVFoT0lJUVcy/ZNt2/fxt27dxXOL5fLAQBaWlq4ceMG7OzsFPaRSqXiTWpERERE9H5RepqBtbU1oqOjC7QfOXJE6RFPHR0dODs7KxxPLpcjOjoabdq0KdC/cePGiI+PR1xcnPjq3bs3OnXqhLi4OI64EhEREX1glB6ZnTp1Kvz9/REXF4e2bdsCAE6fPo2NGzdi2bJlShcQEBAAX19fuLi4oHXr1ggNDUVWVhaGDx8OAPDx8YGVlRVCQkKgq6uLZs2aKexfo0YNACjQTkRERETvP6XD7Lhx42Bubo4ffvgBO3fuBAA4ODhgx44d6NOnj9IFDBw4EE+ePEFQUBCSk5PRokULREZGijeFJSUlQUOjTIsuEBEREdF7Tql1ZvPy8rBw4UKMGDECderUqci6KgzXmSUiIiKq2ipsnVktLS0sWrQIeXl571QgEREREVF5UPr39126dMGff/5ZEbUQERERESlF6Tmz3bt3x/Tp0xEfHw9nZ2dUq1ZNYXvv3r3LrTgiIiIiouIoNWcWQLE3Y0kkEshksncuqiJxziwRERFR1aZMXlN6ZDb/IQVERERERKrGNa+IiIiISG2VOswePXoUTZo0QXp6eoFtaWlpaNq0KU6cOFGuxRERERERFafUYTY0NBSjR48udN6CkZERvvjiCyxdurRciyMiIiIiKk6pw+zly5fRrVu3Ird/+umnuHjxYrkURURERERUGqUOsykpKdDW1i5yu5aWFp48eVIuRRERERERlUapw6yVlRWuXLlS5Pa///4bFhYW5VIUEREREVFplDrM9ujRA3PmzMGrV68KbHv58iXmzp2LXr16lWtxRERERETFKfVDE1JSUtCqVStoampiwoQJaNSoEQDg+vXrWLVqFWQyGWJjY2FmZlahBb8rPjSBiIiIqGqrkIcmmJmZ4cyZMxg3bhxmzJiB/AwskUjg4eGBVatWVfkgS0RERETvF6WeAGZjY4MDBw7gv//+w61btyAIAuzt7WFsbFxR9RERERERFUnpx9kCgLGxMVxdXcu7FiIiIiIipfBxtkRERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqi2GWiIiIiNQWwywRERERqS2GWSIiIiJSWwyzRERERKS2GGaJiIiISG0xzBIRERGR2mKYJSIiIiK1xTBLRERERGqLYZaIiIiI1BbDLBERERGpLYZZIiIiIlJbDLNEREREpLYYZomIiIhIbTHMEhEREZHaYpglIiIiIrXFMEtEREREaothloiIiIjUFsMsEREREakthlkiIiIiUlsMs0RERESkthhmiYiIiEhtMcwSERERkdpimCUiIiIitcUwS0RERERqq0qE2VWrVsHW1ha6urpwc3PDuXPniuy7bt06tGvXDsbGxjA2Noa7u3ux/YmIiIjo/aXyMLtjxw4EBARg7ty5iI2NhZOTEzw8PPD48eNC+x8/fhze3t44duwYYmJiYG1tjU8//RQPHjyo5MqJiIiISNUkgiAIqizAzc0Nrq6uWLlyJQBALpfD2toaEydOxPTp00vcXyaTwdjYGCtXroSPj0+J/dPT02FkZIS0tDQYGhq+c/1EREREVL6UyWsqHZnNycnBxYsX4e7uLrZpaGjA3d0dMTExpTrGixcvkJubi5o1axa6PTs7G+np6QovIiIiIno/qDTMPn36FDKZDGZmZgrtZmZmSE5OLtUxAgMDYWlpqRCI3xQSEgIjIyPxZW1t/c51ExEREVHVoPI5s+/iu+++w/bt27F3717o6uoW2mfGjBlIS0sTX/fu3avkKomIiIioomip8uS1atWCpqYmUlJSFNpTUlJgbm5e7L5LlizBd999hyNHjqB58+ZF9pNKpZBKpeVSLxERERFVLSodmdXR0YGzszOio6PFNrlcjujoaLRp06bI/RYtWoQFCxYgMjISLi4ulVEqEREREVVBKh2ZBYCAgAD4+vrCxcUFrVu3RmhoKLKysjB8+HAAgI+PD6ysrBASEgIA+P777xEUFITw8HDY2tqKc2sNDAxgYGCgsusgIiIiosqn8jA7cOBAPHnyBEFBQUhOTkaLFi0QGRkp3hSWlJQEDY3/G0Bes2YNcnJy8PnnnyscZ+7cuZg3b15llk5EREREKqbydWYrG9eZJSIiIqra1GadWaL/197dB0Vx33Ec/yB4BwzBU1FAA2pGxSfEBxRRUycjrU2ZtHY6lTqkMTFtamJaE63xKZE0TouT1k5rYjTpQ2imrVTTapNITIgKaSxqJBBBKWK0IZMJYoIgPhSV+/YPx20ukqS1nufi+zVzM8fu925/+4VlP67L7wAAAP4fhFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBahFkAAAC4FmEWAAAArkWYBQAAgGsRZgEAAOBa10SYXbNmjfr376/IyEhlZGRoz549n1m/ceNGDRkyRJGRkUpNTVVRUdFVGikAAACuJSEPs3/60580f/585eXl6a233lJaWpqmTZumxsbGDuv//ve/a+bMmbr77rtVUVGh6dOna/r06aqurr7KIwcAAECohZmZhXIAGRkZGjdunJ588klJkt/vV1JSkr7//e9r8eLFl9Tn5OTo1KlTeumll5xlEyZM0KhRo7Ru3brP3d6JEyfUrVs3tbS0KDY29srtCAAAAK6I/yWvRVylMXXo7NmzKi8v15IlS5xlXbp0UVZWlsrKyjp8TVlZmebPnx+wbNq0adq8eXOH9W1tbWpra3O+bmlpkXShSQAAALj2XMxp/80115CG2Q8//FDt7e2Kj48PWB4fH69//OMfHb6moaGhw/qGhoYO6/Pz8/WjH/3okuVJSUmXOWoAAABcDa2trerWrdtn1oQ0zF4NS5YsCbiS6/f71dTUpJ49eyosLCzo2z9x4oSSkpL03nvvcVvDVUTfQ4O+hwZ9Dw36Hhr0PTSudt/NTK2trerTp8/n1oY0zMbFxSk8PFxHjx4NWH706FElJCR0+JqEhIT/qd7r9crr9QYs8/l8lz/oyxQbG8tBFwL0PTToe2jQ99Cg76FB30Pjavb9867IXhTS2Qw8Ho/Gjh2rbdu2Ocv8fr+2bdumzMzMDl+TmZkZUC9JxcXFn1oPAACAzivktxnMnz9fs2bNUnp6usaPH69f/OIXOnXqlO666y5J0h133KG+ffsqPz9fkjRv3jxNmTJFq1atUnZ2tgoLC7V3714988wzodwNAAAAhEDIw2xOTo6OHTum5cuXq6GhQaNGjdLWrVudP/Kqr69Xly7/uYA8ceJE/fGPf9TDDz+spUuXatCgQdq8ebNGjBgRql34TF6vV3l5eZfc6oDgou+hQd9Dg76HBn0PDfoeGtdy30M+zywAAABwuUL+CWAAAADA5SLMAgAAwLUIswAAAHAtwiwAAABcizAbZGvWrFH//v0VGRmpjIwM7dmzJ9RDuma9/vrruu2229SnTx+FhYVp8+bNAevNTMuXL1diYqKioqKUlZWlurq6gJqmpibl5uYqNjZWPp9Pd999t06ePBlQs2/fPt18882KjIxUUlKSHn/88UvGsnHjRg0ZMkSRkZFKTU1VUVHRFd/fa0V+fr7GjRunG264Qb1799b06dNVW1sbUPOvf/1Lc+fOVc+ePRUTE6NvfOMbl3x4SX19vbKzsxUdHa3evXtr4cKFOn/+fEBNSUmJxowZI6/Xq4EDB6qgoOCS8Vwvx8zatWs1cuRIZwLyzMxMvfzyy856eh58K1euVFhYmB544AFnGX2/8h599FGFhYUFPIYMGeKsp+fB8/777+v2229Xz549FRUVpdTUVO3du9dZ32nOq4agKSwsNI/HY7/97W9t//799t3vftd8Pp8dPXo01EO7JhUVFdmyZcvsL3/5i0myTZs2BaxfuXKldevWzTZv3mxvv/22ffWrX7UBAwbYmTNnnJovf/nLlpaWZrt27bK//e1vNnDgQJs5c6azvqWlxeLj4y03N9eqq6tt/fr1FhUVZU8//bRTs3PnTgsPD7fHH3/cDhw4YA8//LB17drVqqqqgt6DUJg2bZo9++yzVl1dbZWVlfaVr3zFkpOT7eTJk07NnDlzLCkpybZt22Z79+61CRMm2MSJE53158+ftxEjRlhWVpZVVFRYUVGRxcXF2ZIlS5yaw4cPW3R0tM2fP98OHDhgTzzxhIWHh9vWrVudmuvpmHnhhRdsy5YtdvDgQautrbWlS5da165drbq62szoebDt2bPH+vfvbyNHjrR58+Y5y+n7lZeXl2fDhw+3Dz74wHkcO3bMWU/Pg6Opqcn69etnd955p+3evdsOHz5sr7zyih06dMip6SznVcJsEI0fP97mzp3rfN3e3m59+vSx/Pz8EI7KHT4ZZv1+vyUkJNhPf/pTZ1lzc7N5vV5bv369mZkdOHDAJNmbb77p1Lz88ssWFhZm77//vpmZPfXUU9a9e3dra2tzahYtWmQpKSnO1zNmzLDs7OyA8WRkZNj3vve9K7qP16rGxkaTZKWlpWZ2oc9du3a1jRs3OjU1NTUmycrKyszswj9EunTpYg0NDU7N2rVrLTY21un1Qw89ZMOHDw/YVk5Ojk2bNs35+no/Zrp3726//vWv6XmQtba22qBBg6y4uNimTJnihFn6Hhx5eXmWlpbW4Tp6HjyLFi2yyZMnf+r6znRe5TaDIDl79qzKy8uVlZXlLOvSpYuysrJUVlYWwpG505EjR9TQ0BDQz27duikjI8PpZ1lZmXw+n9LT052arKwsdenSRbt373ZqvvCFL8jj8Tg106ZNU21trY4fP+7UfHw7F2uul+9bS0uLJKlHjx6SpPLycp07dy6gJ0OGDFFycnJA71NTU50PO5Eu9OzEiRPav3+/U/NZfb2ej5n29nYVFhbq1KlTyszMpOdBNnfuXGVnZ1/SG/oePHV1derTp49uuukm5ebmqr6+XhI9D6YXXnhB6enp+uY3v6nevXtr9OjR+tWvfuWs70znVcJskHz44Ydqb28POPgkKT4+Xg0NDSEalXtd7Nln9bOhoUG9e/cOWB8REaEePXoE1HT0Hh/fxqfVXA/fN7/frwceeECTJk1yPlWvoaFBHo9HPp8voPaTvb/cvp44cUJnzpy5Lo+ZqqoqxcTEyOv1as6cOdq0aZOGDRtGz4OosLBQb731lvMR6R9H34MjIyNDBQUF2rp1q9auXasjR47o5ptvVmtrKz0PosOHD2vt2rUaNGiQXnnlFd177736wQ9+oN/97neSOtd5NeQfZwvg2jF37lxVV1frjTfeCPVQrgspKSmqrKxUS0uLnn/+ec2aNUulpaWhHlan9d5772nevHkqLi5WZGRkqIdz3bj11lud5yNHjlRGRob69eunDRs2KCoqKoQj69z8fr/S09P1k5/8RJI0evRoVVdXa926dZo1a1aIR3dlcWU2SOLi4hQeHn7JX2QePXpUCQkJIRqVe13s2Wf1MyEhQY2NjQHrz58/r6ampoCajt7j49v4tJrO/n27//779dJLL2nHjh268cYbneUJCQk6e/asmpubA+o/2fvL7WtsbKyioqKuy2PG4/Fo4MCBGjt2rPLz85WWlqZf/vKX9DxIysvL1djYqDFjxigiIkIREREqLS3V6tWrFRERofj4ePp+Ffh8Pg0ePFiHDh3iZz2IEhMTNWzYsIBlQ4cOdW7x6EznVcJskHg8Ho0dO1bbtm1zlvn9fm3btk2ZmZkhHJk7DRgwQAkJCQH9PHHihHbv3u30MzMzU83NzSovL3dqtm/fLr/fr4yMDKfm9ddf17lz55ya4uJipaSkqHv37k7Nx7dzsaazft/MTPfff782bdqk7du3a8CAAQHrx44dq65duwb0pLa2VvX19QG9r6qqCvilV1xcrNjYWOeX6ef1lWPmwv62tbXR8yCZOnWqqqqqVFlZ6TzS09OVm5vrPKfvwXfy5Em98847SkxM5Gc9iCZNmnTJNIsHDx5Uv379JHWy8+oV+TMydKiwsNC8Xq8VFBTYgQMH7J577jGfzxfwF5n4j9bWVquoqLCKigqTZD//+c+toqLC3n33XTO7MIWIz+ezv/71r7Zv3z772te+1uEUIqNHj7bdu3fbG2+8YYMGDQqYQqS5udni4+Pt29/+tlVXV1thYaFFR0dfMoVIRESE/exnP7OamhrLy8vr1FNz3XvvvdatWzcrKSkJmDrn9OnTTs2cOXMsOTnZtm/fbnv37rXMzEzLzMx01l+cOudLX/qSVVZW2tatW61Xr14dTp2zcOFCq6mpsTVr1nQ4dc71cswsXrzYSktL7ciRI7Zv3z5bvHixhYWF2auvvmpm9Pxq+fhsBmb0PRgWLFhgJSUlduTIEdu5c6dlZWVZXFycNTY2mhk9D5Y9e/ZYRESE/fjHP7a6ujr7wx/+YNHR0fb73//eqeks51XCbJA98cQTlpycbB6Px8aPH2+7du0K9ZCuWTt27DBJlzxmzZplZhemEXnkkUcsPj7evF6vTZ061WprawPe46OPPrKZM2daTEyMxcbG2l133WWtra0BNW+//bZNnjzZvF6v9e3b11auXHnJWDZs2GCDBw82j8djw4cPty1btgRtv0Oto55LsmeffdapOXPmjN13333WvXt3i46Otq9//ev2wQcfBLzPP//5T7v11lstKirK4uLibMGCBXbu3LmAmh07dtioUaPM4/HYTTfdFLCNi66XY2b27NnWr18/83g81qtXL5s6daoTZM3o+dXyyTBL36+8nJwcS0xMNI/HY3379rWcnJyAuU7pefC8+OKLNmLECPN6vTZkyBB75plnAtZ3lvNqmJnZlbnGCwAAAFxd3DMLAAAA1yLMAgAAwLUIswAAAHAtwiwAAABcizALAAAA1yLMAgAAwLUIswAAAHAtwiwAAABcizALANepkpIShYWFqbm5OdRDAYDLRpgFAACAaxFmAQAA4FqEWQAIEb/fr/z8fA0YMEBRUVFKS0vT888/L+k/twBs2bJFI0eOVGRkpCZMmKDq6uqA9/jzn/+s4cOHy+v1qn///lq1alXA+ra2Ni1atEhJSUnyer0aOHCgfvOb3wTUlJeXKz09XdHR0Zo4caJqa2uDu+MAcAURZgEgRPLz8/Xcc89p3bp12r9/vx588EHdfvvtKi0tdWoWLlyoVatW6c0331SvXr1022236dy5c5IuhNAZM2boW9/6lqqqqvToo4/qkUceUUFBgfP6O+64Q+vXr9fq1atVU1Ojp59+WjExMQHjWLZsmVatWqW9e/cqIiJCs2fPvir7DwBXQpiZWagHAQDXm7a2NvXo0UOvvfaaMjMzneXf+c53dPr0ad1zzz265ZZbVFhYqJycHElSU1OTbrzxRhUUFGjGjBnKzc3VsWPH9Oqrrzqvf+ihh7Rlyxbt379fBw8eVEpKioqLi5WVlXXJGEpKSnTLLbfotdde09SpUyVJRUVFys7O1pkzZxQZGRnkLgDA/48rswAQAocOHdLp06f1xS9+UTExMc7jueee0zvvvOPUfTzo9ujRQykpKaqpqZEk1dTUaNKkSQHvO2nSJNXV1am9vV2VlZUKDw/XlClTPnMsI0eOdJ4nJiZKkhobG//vfQSAqyEi1AMAgOvRyZMnJUlbtmxR3759A9Z5vd6AQHu5oqKi/qu6rl27Os/DwsIkXbifFwDcgCuzABACw4YNk9frVX19vQYOHBjwSEpKcup27drlPD9+/LgOHjyooUOHSpKGDh2qnTt3Brzvzp07NXjwYIWHhys1NVV+vz/gHlwA6Gy4MgsAIXDDDTfohz/8oR588EH5/X5NnjxZLS0t2rlzp2JjY9WvXz9J0mOPPaaePXsqPj5ey5YtU1xcnKZPny5JWrBggcaNG6cVK1YoJydHZWVlevLJJ/XUU09Jkvr3769Zs2Zp9uzZWr16tdLS0vTuu++qsbFRM2bMCNWuA8AVRZgFgBBZsWKFevXqpfz8fB0+fFg+n09jxozR0qVLnf/mX7lypebNm6e6ujqNGjVKL774ojwejyRpzJgx2rBhg5YvX64VK1YoMTFRjz32mO68805nG2vXrtXSpUt133336aOPPlJycrKWLl0ait0FgKBgNgMAuAZdnGng+PHj8vl8oR4OAFyzuGcWAAAArkWYBQAAgGtxmwEAAABciyuzAAAAcC3CLAAAAFyLMAsAAADXIswCAADAtQizAAAAcC3CLAAAAFyLMAsAAADXIswCAADAtf4NGm298cNFQVwAAAAASUVORK5CYII=","text/plain":["<Figure size 800x800 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import argparse\n","import logging\n","import numpy as np\n","import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import os\n","from itertools import product\n","\n","# argparse를 사용하여 스크립트의 인자(argument)를 설정\n","parser = argparse.ArgumentParser(description='SchoolLog-bot based on KoGPT-2')\n","\n","# 학습된 모델의 저장 경로\n","parser.add_argument('--model_params',\n","                    type=str,\n","                    default='model_chp/model_-last.ckpt',\n","                    help='model binary for starting chat')\n","# 학습을 실행할지 여부를 나타내는 인자\n","parser.add_argument('--train',\n","                    action='store_true',\n","                    default=False,\n","                    help='for training')\n","# 로그 출력\n","logger = logging.getLogger()\n","logger.setLevel(logging.INFO)\n","\n","# 토크나이저와 특수 토큰들을 초기화\n","U_TKN = '<usr>'\n","S_TKN = '<sys>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","PAD = '<pad>'\n","SENT = '<unused1>'\n","\n","TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK)\n","\n","\n","# 데이터셋을 처리하고 모델에 입력으로 제공하기 위한 기능을 제공\n","class CharDataset(Dataset):\n","    def __init__(self, chats, max_len=361):\n","        self._data = chats\n","        self.first = True\n","        self.q_token = U_TKN\n","        self.a_token = S_TKN\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.pad = PAD\n","        self.sent_token = SENT\n","        self.max_len = max_len\n","        self.tokenizer = TOKENIZER\n","\n","    def __len__(self):\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):\n","        turn = self._data.iloc[idx]\n","        sent = turn['sentiment']\n","        q = turn['user']\n","        a = turn['system']\n","        q_toked = self.tokenizer.tokenize(self.q_token + q )\n","        q_len = len(q_toked)\n","        a_toked = self.tokenizer.tokenize(self.sent_token + sent + self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len\n","            if a_len <= 0:\n","                q_toked = q_toked[-(int(self.max_len/2)):]\n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len\n","                assert a_len > 0\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","            assert a_len == len(a_toked), f'{a_len} ==? {len(a_toked)}'\n","        # [mask, mask, ...., mask, ..., <bos>,..A.. <eos>, <pad>....]\n","        labels = [\n","            self.mask,\n","        ] * q_len + a_toked[1:]\n","        if self.first:\n","            logging.info(\"contexts : {}\".format(q))\n","            logging.info(\"toked ctx: {}\".format(q_toked))\n","            logging.info(\"response : {}\".format(a))\n","            logging.info(\"toked response : {}\".format(a_toked))\n","            logging.info('labels {}'.format(labels))\n","            self.first = False\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        self.max_len\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","        return(token_ids, np.array(mask),\n","               labels_ids)\n","\n","# 모델의 구조와 학습 및 예측 과정을 정의\n","class KoGPT2Chat(LightningModule):\n","    def __init__(self, hparams, **kwargs):\n","        super(KoGPT2Chat, self).__init__()\n","        self.hparams = hparams\n","        self.neg = -1e18\n","        self.kogpt2 = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n","        self.loss_function = torch.nn.CrossEntropyLoss(reduction='none')\n","        # 학습 곡선 데이터\n","        self.train_loss_values = []\n","        self.val_loss_values = []\n","        self.train_acc_values = []\n","        self.val_acc_values = []\n","\n","    @staticmethod\n","    def add_model_specific_args(parent_parser):     # 모델 특정 인자들을 추가\n","        # add model specific args\n","        parser = argparse.ArgumentParser(parents=[parent_parser], add_help=False)\n","        parser.add_argument('--max-len',\n","                            type=int,\n","                            default=32,\n","                            help='max sentence length on input (default: 32)')\n","\n","        parser.add_argument('--batch-size',\n","                            type=int,\n","                            default=32,   # 96\n","                            help='batch size for training')\n","        parser.add_argument('--lr',\n","                            type=float,\n","                            default=1e-5,   # 5e-5\n","                            help='The initial learning rate')\n","        parser.add_argument('--warmup_ratio',\n","                            type=float,\n","                            default=0.1,\n","                            help='warmup ratio')\n","        return parser\n","\n","    def forward(self, inputs):\n","        # (batch, seq_len, hiddens)\n","        output = self.kogpt2(inputs, return_dict=True)\n","        return output.logits\n","\n","    def training_step(self, batch, batch_idx):\n","        token_ids, mask, label = batch\n","        out = self(token_ids)\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, self.neg * torch.ones_like(out))\n","        loss = self.loss_function(mask_out.transpose(2, 1), label)\n","        loss_avg = loss.sum() / mask.sum()\n","        self.log('train_loss', loss_avg)\n","        self.train_loss_values.append(loss_avg.item())  # 학습 손실 기록\n","        return loss_avg\n","\n","    def validation_step(self, batch, batch_idx):\n","        token_ids, mask, label = batch\n","        out = self(token_ids)\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, self.neg * torch.ones_like(out))\n","        loss = self.loss_function(mask_out.transpose(2, 1), label)\n","        loss_avg = loss.sum() / mask.sum()\n","        self.val_loss_values.append(loss_avg.item())  # 검증 손실 기록\n","\n","        # 정확도 계산\n","        preds = torch.argmax(out, dim=-1)\n","        correct = torch.eq(preds, label)\n","        accuracy = torch.mean(correct.float())\n","        self.val_acc_values.append(accuracy.item())  # 검증 정확도 기록\n","\n","        self.log('val_loss', loss_avg, prog_bar=True)\n","        self.log('val_accuracy', accuracy, prog_bar=True)\n","\n","    def configure_optimizers(self):     # 옵티마이저와 스케줄러를 설정\n","        # Prepare optimizer\n","        param_optimizer = list(self.named_parameters())\n","        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","        optimizer_grouped_parameters = [\n","            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","        optimizer = AdamW(optimizer_grouped_parameters,\n","                          lr=self.hparams.lr, correct_bias=False)\n","        # warm up lr\n","        num_train_steps = len(self.train_dataloader()) * self.hparams.max_epochs\n","        num_warmup_steps = int(num_train_steps * self.hparams.warmup_ratio)\n","        scheduler = get_cosine_schedule_with_warmup(\n","            optimizer,\n","            num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n","        lr_scheduler = {'scheduler': scheduler, 'name': 'cosine_schedule_with_warmup',\n","                        'monitor': 'loss', 'interval': 'step',\n","                        'frequency': 1}\n","        return [optimizer], [lr_scheduler]\n","\n","    def _collate_fn(self, batch):\n","        data = [item[0] for item in batch]\n","        mask = [item[1] for item in batch]\n","        label = [item[2] for item in batch]\n","        return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","\n","    # 학습할 데이터를 로딩하고 데이터 로더를 생성한다\n","    def train_dataloader(self):\n","        data = pd.read_csv('/content/drive/MyDrive/KoGPT2/data/2 wellness+chitchat_dataset.csv')   # Chit-chat + Wellness dataset\n","        self.train_set = CharDataset(data, max_len=self.hparams.max_len)\n","        train_dataloader = DataLoader(\n","            self.train_set, batch_size=self.hparams.batch_size, num_workers=4,\n","            shuffle=True, collate_fn=self._collate_fn)\n","        return train_dataloader\n","\n","    '''\n","    # GridSearch: 적절한 하이퍼파리미터 값 탐색\n","    def grid_search(self, batch_sizes, learning_rates, warmup_ratios):\n","        best_loss = float('inf')\n","        best_params = None\n","        for batch_size, lr, warmup_ratio in product(batch_sizes, learning_rates, warmup_ratios):\n","            args.batch_size = batch_size\n","            args.lr = lr\n","            args.warmup_ratio = warmup_ratio\n","            model = KoGPT2Chat(args)\n","            trainer = Trainer(\n","                gpus=args.gpus,\n","                max_epochs=args.max_epochs,\n","                accelerator='dp',\n","                checkpoint_callback=checkpoint_callback,\n","                logger=False\n","            )\n","            trainer.fit(model)\n","            avg_val_loss = np.mean(model.val_loss_values[-5:])  # 마지막 5개의 검증 손실 평균 계산\n","            if avg_val_loss < best_loss:\n","                best_loss = avg_val_loss\n","                best_params = (batch_size, lr, warmup_ratio)\n","        return best_params\n","        '''\n","\n","# 인자 파싱\n","parser = KoGPT2Chat.add_model_specific_args(parser)\n","parser = Trainer.add_argparse_args(parser)\n","# args = parser.parse_args()\n","args = parser.parse_args('')  # or args=[]\n","logging.info(args)\n","\n","if __name__ == \"__main__\":\n","    # python train_torch.py --train --gpus 1 --max_epochs 10 코드 변환\n","    # train 모드 & gpu 개수 & 학습횟수 epoch 지정\n","    args_str = '--train --gpus 1 --max_epochs 23'\n","    args = parser.parse_args(args_str.split())\n","\n","    if args.train:\n","        # train_loss 손실값이 낮을수록 더 우수한 모델로 간주하여 최적의 체크포인트 모델 저장\n","        checkpoint_callback = ModelCheckpoint(\n","            dirpath='/content/drive/MyDrive/KoGPT2/checkpoint/3rd learning',\n","            filename='{epoch:02d}-{train_loss:.2f}',\n","            verbose=True,\n","            save_last=True,\n","            monitor='train_loss',\n","            mode='min',\n","            prefix='model_'\n","        )\n","\n","        # 최신의 체크포인트 모델을 불러와서 이어서 학습\n","        checkpoint_path = \"/content/drive/MyDrive/KoGPT2/checkpoint/2nd learning/model_-epoch=18-train_loss=8.95.ckpt\"\n","        if os.path.exists(checkpoint_path):\n","            args.resume_from_checkpoint = checkpoint_path\n","        # trained_model = KoGPT2Chat.load_from_checkpoint(checkpoint_path, hparams=args)\n","        '''\n","        # Grid Search를 위한 하이퍼파라미터 범위 설정\n","        batch_sizes = [16, 32, 64]\n","        learning_rates = [1e-3, 1e-4, 1e-5]\n","        warmup_ratios = [0.1, 0.2, 0.3]\n","        '''\n","        # Trainer를 사용하여 학습을 수행\n","        model = KoGPT2Chat(args)\n","        '''\n","        # Grid Search로 최적의 하이퍼파라미터 탐색, 출력\n","        best_batch_size, best_lr, best_warmup_ratio = model.grid_search(batch_sizes, learning_rates, warmup_ratios)\n","        print(\"Best Hyperparameters:\")\n","        print(\"Batch Size:\", best_batch_size)\n","        print(\"Learning Rate:\", best_lr)\n","        print(\"Warmup Ratio:\", best_warmup_ratio)\n","        '''\n","        # Trainer를 사용하여 학습을 수행\n","        model = KoGPT2Chat(args)\n","        model.train()                 # 모델의 학습 모드 설정\n","        trainer = Trainer.from_argparse_args(\n","            args, accelerator=\"dp\", # only for multi gpus\n","            checkpoint_callback=checkpoint_callback, gradient_clip_val=1.0\n","        )\n","        trainer.fit(model)    # 전체 학습 프로세스 시작\n","\n","        # 학습 과정에서 최적의 모델을 저장\n","        logging.info('best model path {}'.format(checkpoint_callback.best_model_path))\n","        # 학습 완료 후 best_model_path\n","        trained_model = KoGPT2Chat.load_from_checkpoint(checkpoint_callback.best_model_path)\n","        '''\n","        # 이미 생성된 체크포인트 파일 직접 지정\n","        checkpoint_file = '/content/drive/MyDrive/KoGPT2/checkpoint/model_-epoch=24-train_loss=9.49.ckpt'\n","        trained_model = KoGPT2Chat.load_from_checkpoint(str(checkpoint_file), hparams=args)\n","        '''\n","        # 최종 학습 완료 후, 학습된 최적 모델을 로드하여 저장 (finetuned_model)\n","        trained_model.kogpt2.save_pretrained('/content/drive/MyDrive/KoGPT2/model')\n","\n","        # 학습 곡선 learning curve 그리기\n","        # 학습 과정에서 기록한 손실과 정확도 값들을 가져옴\n","        train_loss_values = model.train_loss_values\n","        val_loss_values = model.val_loss_values\n","        train_acc_values = model.train_acc_values\n","        val_acc_values = model.val_acc_values\n","\n","        # 학습 과정 시각화\n","        plt.figure(figsize=(8, 8))\n","        plt.subplot(2, 1, 1)\n","        plt.plot(train_acc_values, label='Training Accuracy')\n","        plt.plot(val_acc_values, label='Validation Accuracy')\n","        plt.legend(loc='lower right')\n","        plt.ylabel('Accuracy')\n","        plt.ylim([min(plt.ylim()), 1])\n","        plt.title('Training and Validation Accuracy')\n","\n","        plt.subplot(2, 1, 2)\n","        plt.plot(train_loss_values, label='Training Loss')\n","        plt.plot(val_loss_values, label='Validation Loss')\n","        plt.legend(loc='upper right')\n","        plt.ylabel('Cross Entropy')\n","        plt.ylim([0, 1.0])\n","        plt.title('Training and Validation Loss')\n","        plt.xlabel('epoch')\n","        plt.show()"]},{"cell_type":"markdown","metadata":{"id":"88Y_GvQCXlxE"},"source":["# CHAT 대화"]},{"cell_type":"markdown","metadata":{"id":"plmOeNgv1HWG"},"source":["chat.py 채팅"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128203,"status":"ok","timestamp":1690097164139,"user":{"displayName":"스쿨로그","userId":"16152972257809265222"},"user_tz":-540},"id":"wVm8YPVK1MId","outputId":"5faf325b-85d3-401a-dacf-1e47df9bd6ed"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"name":"stdout","output_type":"stream","text":["챗봇 > 안녕하세요! 요즘에 무슨 일이 있었나요?\n","사용자 > 넌 누구야?\n","챗봇 > 저는 위로봇입니다.\n","사용자 > 너는 어디 살아?\n","챗봇 > 나를 관찰하고 음식 자체에 집중하세요.\n","사용자 > 음식 뭐 좋아해?\n","챗봇 > 맛있는 거 드세요.\n","사용자 > 그러면 어떻게 하고 싶어?\n","챗봇 > 어떻게 하면 상대방과의 신뢰를 쌓을 수 있을까요?\n","사용자 > 사람들은 왜 남들을 힘들게 할까?\n","챗봇 > 인간관계에 회의감이 드시는군요. 어떤 일이 있으셨나요?\n","사용자 > 그냥 아무것도 하기 싫어.\n","챗봇 > 무기력하고 힘이 안 나시는군요. 많이 지치신 거 같아 안타까워요.\n","사용자 > 너도 그래?\n","챗봇 > 저는 위로봇입니다.\n","사용자 > 나는 에이미야.\n","챗봇 > 그렇게 생각하시는 이유가 있나요?\n","사용자 > 그게 내 이름이야.\n","챗봇 > 의사는 건강에 대해 뭐라고 하나요?\n","사용자 > 난 건강해.\n","챗봇 > 몸이 건강하셔서 기분이 좋으시겠어요.\n","사용자 > 글쎄, 마음은 그렇지 않아.\n","챗봇 > 누군가에게 속마음을 털어놓는 것이 조심스러우신 것 같네요.\n","사용자 > 응.\n","챗봇 > 마음이 아주 무거우시겠어요. 힘내세요.\n","사용자 > 종료하기\n"]}],"source":["''' 학습된 KoGPT-2 모델을 사용하여 사용자와 대화 수행 '''\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n","import torch\n","import argparse\n","\n","# 학습된 모델 로드\n","model = GPT2LMHeadModel.from_pretrained('/content/drive/MyDrive/KoGPT2/model/2nd last update model')\n","\n","# 챗봇 대화를 위한 특수 토큰들 설정\n","U_TKN = '<usr>'\n","S_TKN = '<sys>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","PAD = '<pad>'\n","SENT = '<unused1>'\n","\n","# 토크나이저 초기화\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK)\n","\n","# argparse를 사용하여 스크립트의 인자(argument)를 설정\n","parser = argparse.ArgumentParser(description='SchoolLog-bot based on KoGPT-2')\n","# chat은 챗봇의 대화 기능을 실행할지 여부를 나타내는 인자\n","parser.add_argument('--chat',\n","                    action='store_true',\n","                    default=False,\n","                    help='response generation on given user input')\n","\n","args = parser.parse_args('')\n","\n","# 사용자와 챗봇 간의 대화\n","def chat():\n","    with torch.no_grad():   # 모델의 연산 그래프 추적을 비활성화\n","        qs=[]\n","        user_name = input('사용자 이름을 입력하세요: ')  # 사용자 이름 입력 받기\n","        print(f\"챗봇 > 안녕하세요, {user_name}님! 요즘에 무슨 일이 있었나요?\")\n","        while 1:\n","            q = input('사용자 > ').strip()\n","            qs.append(q) # history 저장\n","\n","            if q == '종료하기':\n","                break\n","\n","            a=''\n","            user = U_TKN + q + SENT + a\n","            encoded = tokenizer.encode(user)\n","            input_ids = torch.LongTensor(encoded).unsqueeze(dim=0)\n","            output = model.generate(input_ids,max_length=50,\n","                                         num_beams=10, do_sample=False,\n","                                         top_k=50, no_repeat_ngram_size=2,\n","                                        temperature=0.85)\n","            # a=tokenizer.decode(output[0])\n","            a = tokenizer.decode(output[0], skip_special_tokens=True)\n","            idx = torch.where(output[0] == tokenizer.encode('<sys>')[0])\n","            # chatbot = tokenizer.decode(output[0][int(idx[0])+1:], skip_special_tokens=True)\n","            chatbot = tokenizer.decode(output[0][idx[0].item() + 1:], skip_special_tokens=True)\n","\n","            # 응답에서 '00'을 사용자 이름으로 대체\n","            chatbot = chatbot.replace('00', user_name)\n","\n","            if '답변' in a: # 응, 아니 등이 input으로 들어왔을 때 ('긍정답변', '부정답변')\n","                a_new = ''\n","                user = U_TKN + ''.join(qs[-2:]) + SENT + a_new    # 직전 사용자 발화 history 가지고 와서 sentiment 고려해주기\n","                encoded = tokenizer.encode(user)\n","                input_ids = torch.LongTensor(encoded).unsqueeze(dim=0)\n","                output = model.generate(input_ids,max_length=50,\n","                                         num_beams=10, do_sample=False,\n","                                         top_k=50, no_repeat_ngram_size=2,\n","                                        temperature=0.85)\n","                a_new = tokenizer.decode(output[0], skip_special_tokens=True)\n","                idx = torch.where(output[0]==tokenizer.encode('<sys>')[0])\n","                # chatbot = tokenizer.decode(output[0][int(idx[0])+1:], skip_special_tokens=True)\n","                chatbot = tokenizer.decode(output[0][idx[0].item() + 1:], skip_special_tokens=True)\n","                chatbot = chatbot.replace('00', user_name)    # 응답에서 '00'을 사용자 이름으로 대체\n","\n","                print(\"챗봇 > {}\".format(chatbot.strip()))\n","\n","            else:\n","                print(\"챗봇 > {}\".format(chatbot.strip()))\n","\n","\n","# 대화 기능이 활성화되었을 때에만 chat 함수를 실행\n","if __name__ == \"__main__\":\n","    # python chat.py --chat 명령어를 코드로 변환\n","    args_str = '--chat'\n","    args = parser.parse_args(args_str.split())\n","\n","    if args.chat:\n","        chat()\n"]},{"cell_type":"markdown","metadata":{"id":"BRdmmOhYsL3x"},"source":["# 2) Haven-jeon Chatbot train_torch.py 학습"]},{"cell_type":"markdown","metadata":{"id":"2k3Gwg35zlUL"},"source":["명령행 인자 수정 (chat, train 분리 필요)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phLUhKGUsR8y"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["rqhJYEIkIp7_","RghJc6cJzxqb","beSuZrRZXbZz","Ib8hpaB550ho","88Y_GvQCXlxE"],"gpuType":"V100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0408af5e23a54a0594097ce453655ce9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aa4f1877f7141a3a6fdaefeaa028056":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"227b3acc2bd04daabbf9ccbb988e37e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"240887452dc84524bee91744fd1b0b1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6df427c71e2d4bac9bfa048ba8b5ca9f","placeholder":"​","style":"IPY_MODEL_bd2aa8a58ce54426946ce2a309777864","value":" 2.83M/2.83M [00:00&lt;00:00, 5.85MB/s]"}},"3119e5cc2e4342d4b009f85d74a133cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33ca76cf42094d6d83bbecb6f8d613c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f7215719bba645b1a1fa6b69516a05f5","IPY_MODEL_ec10fa5a187d49b2889bafefb67d466a","IPY_MODEL_240887452dc84524bee91744fd1b0b1a"],"layout":"IPY_MODEL_4e5676d71b304d6aae9f6016de6031d3"}},"357af97e849f444c9a5930e7c9a8307b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":"2","flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e1605bd3be141e39c6ed3b638a7c10d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_894e9fcfd3c44de782ec77386895de1e","placeholder":"​","style":"IPY_MODEL_bd35beee89084453b0830b941058b076","value":" 513M/513M [00:01&lt;00:00, 464MB/s]"}},"4e5676d71b304d6aae9f6016de6031d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"524d27edee144257b38a74e4236be9c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a550e0f26d6f42b6b4f0315585b38a0c","IPY_MODEL_9351dd2874554abc920f6e1633d8e3e0","IPY_MODEL_3e1605bd3be141e39c6ed3b638a7c10d"],"layout":"IPY_MODEL_c9d91c14e523405c9397252a45de1dcc"}},"554bfc53ec47421d8543fbaab95cd09b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bb203c64a1e432ea015b58358195eb2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6df427c71e2d4bac9bfa048ba8b5ca9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e20523e7b2143808213840c3d256a12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"768d1fb1123d4c7f966e7e30e0f56a53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82427492d0104facad6de89a1e6bbcc9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b32c4a60184dc4851eaca205ebb84a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87351221e75b4dd1b2929203e353188e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"894e9fcfd3c44de782ec77386895de1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a2d72d3193745c0a50db992971178a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0408af5e23a54a0594097ce453655ce9","placeholder":"​","style":"IPY_MODEL_1aa4f1877f7141a3a6fdaefeaa028056","value":"Epoch 19:   3%"}},"8caaa340862c465db4b63bf81d711cfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91ab0536d5bb4192b0968c77895466cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3119e5cc2e4342d4b009f85d74a133cd","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_227b3acc2bd04daabbf9ccbb988e37e5","value":1000}},"9351dd2874554abc920f6e1633d8e3e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a08ddca549cc41dda588eb220b8f0847","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_949ef68ddc3a4554ac69e87cb8e40b85","value":513302779}},"944d27c0706144a681500e199e01c0b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f64c5f1070b3438582a5aee9a6b9f459","placeholder":"​","style":"IPY_MODEL_554bfc53ec47421d8543fbaab95cd09b","value":" 320/10435 [00:39&lt;20:43,  8.13it/s, loss=8.99, v_num=0]"}},"949ef68ddc3a4554ac69e87cb8e40b85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d4b9772e7494d71892779e009558b62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a2d72d3193745c0a50db992971178a7","IPY_MODEL_fb1fe6756a5d4282a06c0dce344fc0fb","IPY_MODEL_944d27c0706144a681500e199e01c0b3"],"layout":"IPY_MODEL_af39bcb61f544a7fa53edf27128121b0"}},"a08ddca549cc41dda588eb220b8f0847":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a550e0f26d6f42b6b4f0315585b38a0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_84b32c4a60184dc4851eaca205ebb84a","placeholder":"​","style":"IPY_MODEL_b7863fe3bf144d9baf96337d55d3371b","value":"Downloading pytorch_model.bin: 100%"}},"af39bcb61f544a7fa53edf27128121b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":"inline-flex","flex":null,"flex_flow":"row wrap","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"100%"}},"b40657f855c6455dbdba8970f80c2eed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be25574bc3bb48c3bee680fe6921ea69","IPY_MODEL_91ab0536d5bb4192b0968c77895466cc","IPY_MODEL_bfbc7a74ed3147428a095e39416af8eb"],"layout":"IPY_MODEL_82427492d0104facad6de89a1e6bbcc9"}},"b7863fe3bf144d9baf96337d55d3371b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd2aa8a58ce54426946ce2a309777864":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd35beee89084453b0830b941058b076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be25574bc3bb48c3bee680fe6921ea69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dafea77c6b874b52a02d222e1a72c445","placeholder":"​","style":"IPY_MODEL_e8350fca4c3849989777bd0fbffed223","value":"Downloading (…)lve/main/config.json: 100%"}},"bfbc7a74ed3147428a095e39416af8eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e20523e7b2143808213840c3d256a12","placeholder":"​","style":"IPY_MODEL_768d1fb1123d4c7f966e7e30e0f56a53","value":" 1.00k/1.00k [00:00&lt;00:00, 86.8kB/s]"}},"c23eec33a8f144a3a3cac0f2d321de51":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9d91c14e523405c9397252a45de1dcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4f6c7f0a72a471680ff11484953428d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dafea77c6b874b52a02d222e1a72c445":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8350fca4c3849989777bd0fbffed223":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec10fa5a187d49b2889bafefb67d466a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87351221e75b4dd1b2929203e353188e","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8caaa340862c465db4b63bf81d711cfd","value":2825034}},"f64c5f1070b3438582a5aee9a6b9f459":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7215719bba645b1a1fa6b69516a05f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bb203c64a1e432ea015b58358195eb2","placeholder":"​","style":"IPY_MODEL_c23eec33a8f144a3a3cac0f2d321de51","value":"Downloading (…)/main/tokenizer.json: 100%"}},"fb1fe6756a5d4282a06c0dce344fc0fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_357af97e849f444c9a5930e7c9a8307b","max":10435,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4f6c7f0a72a471680ff11484953428d","value":340}}}}},"nbformat":4,"nbformat_minor":0}
